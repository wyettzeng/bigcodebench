{"task_id": "BigCodeBench/13", "solution": "import subprocess\nimport ftplib\nfrom ftplib import FTP", "raw_solution": "import subprocess\nimport ftplib\nfrom ftplib import FTP\nimport os from task from import from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from"}
{"task_id": "BigCodeBench/15", "solution": "import subprocess\nimport csv\nimport os\nfrom datetime import datetime\nimport os\ndef task_func(commands_file_path, output_dir_path):\n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from", "raw_solution": "import subprocess\nimport csv\nimport os\nfrom datetime import datetime\n\n# Add this import statement at the beginning of the code snippet\nimport os\n\ndef task_func(commands_file_path, output_dir_path):\n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from the os module is not imported\n    from datetime import datetime\n    \n    # Check if the output_dir_path from"}
{"task_id": "BigCodeBench/17", "solution": "import subprocess\nimport psutil\nimport time\ndef task_func(process_name: str) -> str:\n    # Check if the process is running\n    for proc in psutil.process_iter(['pid', 'name']):\n        if proc.info['name'] == process_name:\n            # Process is found, restart it\n            return f\"Process found. Restarting {process_name}.\"\n    \n    # Process is not found, start it\n    return f\"Process not found. Starting {process_name}.\"", "raw_solution": "import subprocess\nimport psutil\nimport time\n\ndef task_func(process_name: str) -> str:\n    # Check if the process is running\n    for proc in psutil.process_iter(['pid', 'name']):\n        if proc.info['name'] == process_name:\n            # Process is found, restart it\n            return f\"Process found. Restarting {process_name}.\"\n    \n    # Process is not found, start it\n    return f\"Process not found. Starting {process_name}.\"\n\n# Example usage"}
{"task_id": "BigCodeBench/19", "solution": "import os", "raw_solution": "import os\nfrom zipfile import zipfile from task_module import import_module from task_module import task_module from task_module.zipfile import task_module from task_module.task_module.zipfile import task from task_module.task_module.task from task_module.task_module.task_module from task_module.task_module.task_module.zip from task_module.task_module.task_module.zip from task_module.task_module.task_module.zip from task_module.task_module.task_module.zip from task_module.task_module.task_module.task from task_module.task_module.task_module.task from task_module.task_module.task_module.task from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from"}
{"task_id": "BigCodeBench/34", "solution": "import re\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\ndef task_func(text):\n    # Remove URLs from the text\n    text = re.sub(r'http\\S+', '', text)\n    \n    # Split the text into words\n    words = text.split()\n    \n    # Check if there are any words available\n    if not words:\n        raise ValueError(\"No words available to generate a word cloud after removing URLs.\")\n    \n    # Generate the word cloud\n    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(' '.join(words))\n    \n    # Plot the word cloud\n    plt.figure(figsize=(10, 5))\n    plt.imshow(wordcloud, interpolation='bilinear')\n    plt.axis('off')\n    plt.show()\n    \n    return wordcloud\ntext = \"Hello world! This is a sample text. Please visit https://www.example.com for more information.\"", "raw_solution": "import re\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\n\ndef task_func(text):\n    # Remove URLs from the text\n    text = re.sub(r'http\\S+', '', text)\n    \n    # Split the text into words\n    words = text.split()\n    \n    # Check if there are any words available\n    if not words:\n        raise ValueError(\"No words available to generate a word cloud after removing URLs.\")\n    \n    # Generate the word cloud\n    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(' '.join(words))\n    \n    # Plot the word cloud\n    plt.figure(figsize=(10, 5))\n    plt.imshow(wordcloud, interpolation='bilinear')\n    plt.axis('off')\n    plt.show()\n    \n    return wordcloud\n\n# Example usage\ntext = \"Hello world! This is a sample text. Please visit https://www.example.com for more information.\"\nwordcloud = task_func(text)\n\n```"}
{"task_id": "BigCodeBench/37", "solution": "from sklearn.ensemble import RandomForestClassifier\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\ndef task_func(df, target_column):\n    # Split the dataframe into features and target\n    X = df.drop(target_column, axis=1)\n    y = df[target_column]\n    \n    # Initialize and train the RandomForestClassifier\n    rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n    rf_classifier.fit(X, y)\n    \n    # Get feature importances\n    feature_importances = rf_classifier.feature_importances_\n    \n    # Create a dataframe to hold feature importances\n    feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})\n    \n    # Sort the dataframe by importance in descending order\n    feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n    \n    # Plot the bar plot of feature importances\n    plt.figure(figsize=(10, 6))\n    sns.barplot(x='Importance', y='Feature', data=feature_importance_df)\n    plt.xlabel('Feature Importance Score')\n    plt.ylabel('Features')\n    plt.title('Visualizing Important Features')\n    plt.show()\n    \n    return rf_classifier, plt.gca()", "raw_solution": "from sklearn.ensemble import RandomForestClassifier\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\ndef task_func(df, target_column):\n    # Split the dataframe into features and target\n    X = df.drop(target_column, axis=1)\n    y = df[target_column]\n    \n    # Initialize and train the RandomForestClassifier\n    rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n    rf_classifier.fit(X, y)\n    \n    # Get feature importances\n    feature_importances = rf_classifier.feature_importances_\n    \n    # Create a dataframe to hold feature importances\n    feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})\n    \n    # Sort the dataframe by importance in descending order\n    feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n    \n    # Plot the bar plot of feature importances\n    plt.figure(figsize=(10, 6))\n    sns.barplot(x='Importance', y='Feature', data=feature_importance_df)\n    plt.xlabel('Feature Importance Score')\n    plt.ylabel('Features')\n    plt.title('Visualizing Important Features')\n    plt.show()\n    \n    return rf_classifier, plt.gca()\n\n# Example usage:\n# Assuming 'df' is your dataframe and 'target_column' is the column you want to predict\n# rf_classifier, ax = task_func(df, 'target_column')\n\n```"}
{"task_id": "BigCodeBench/82", "solution": "from flask import Flask, render_template, redirect, url_for\nfrom flask_login import LoginManager, UserMixin, login_user, login_required, logout_user, current_user\nfrom flask_wtf import FlaskForm\nfrom wtforms import StringField, PasswordField, SubmitField\nfrom wtforms.validators import DataRequired, Length\nfrom werkzeug.security import generate_password_hash, check_password_hash\nfrom flask import Flask\nclass LoginForm(FlaskForm):\n    username = StringField('Username', validators=[DataRequired(), Length(min=4, max=25)])\n    password = PasswordField('Password', validators=[DataRequired(), Length(min=8, max=80)])\n    submit = SubmitField('Log In')\nlogin_manager = LoginManager()\ndef task_func(secret_key, template_folder):\n    app = Flask(__name__, secret_key=secret_key, template_folder=template_folder)\n    app.secret_key = secret_key\n    app.config['SECRET_KEY'] = secret_key\n    login_manager.init_app(app)\n\n    @app.route('/')\n    def index():\n        return render_template('index.html')\n\n    @app.route('/login', methods=['GET', 'POST'])\n    def login():\n        form = LoginForm()\n        if form.validate_on_submit():\n            user = load_user(form.username.data)\n            if user and check_password_hash(user.password, form.password.data):\n                login_user(user)\n                return redirect(url_for('protected'))\n            else:\n                return 'Invalid username or password'\n        return render_template('login.html', form=form)\n\n    @app.route('/logout')\n    @login_required\n    def logout():\n        logout_user()\n        return redirect(url_for('index'))\n\n    @app.route('/protected')\n    @login_required\n    def protected():\n        return f'Logged in as: {current_user.username}'\n\n    return app", "raw_solution": "from flask import Flask, render_template, redirect, url_for\nfrom flask_login import LoginManager, UserMixin, login_user, login_required, logout_user, current_user\nfrom flask_wtf import FlaskForm\nfrom wtforms import StringField, PasswordField, SubmitField\nfrom wtforms.validators import DataRequired, Length\nfrom werkzeug.security import generate_password_hash, check_password_hash\nfrom flask import Flask\n\nclass LoginForm(FlaskForm):\n    username = StringField('Username', validators=[DataRequired(), Length(min=4, max=25)])\n    password = PasswordField('Password', validators=[DataRequired(), Length(min=8, max=80)])\n    submit = SubmitField('Log In')\n\nlogin_manager = LoginManager()\n\nclass User(UserMixin):\n    def __init__(self, id, username, password):\n        self.id = id\n        self.username = username\n        self.password = password\n\nusers = {\n    'user1': User('1', 'user1', generate_password_hash('password1')),\n    'user2': User('2', 'user2', generate_password_hash('password2'))\n}\n\n@login_manager.user_loader\ndef load_user(user_id):\n    for user in users.values():\n        if user.id == user_id:\n            return user\n    return None\n\ndef task_func(secret_key, template_folder):\n    app = Flask(__name__, secret_key=secret_key, template_folder=template_folder)\n    app.secret_key = secret_key\n    app.config['SECRET_KEY'] = secret_key\n    login_manager.init_app(app)\n\n    @app.route('/')\n    def index():\n        return render_template('index.html')\n\n    @app.route('/login', methods=['GET', 'POST'])\n    def login():\n        form = LoginForm()\n        if form.validate_on_submit():\n            user = load_user(form.username.data)\n            if user and check_password_hash(user.password, form.password.data):\n                login_user(user)\n                return redirect(url_for('protected'))\n            else:\n                return 'Invalid username or password'\n        return render_template('login.html', form=form)\n\n    @app.route('/logout')\n    @login_required\n    def logout():\n        logout_user()\n        return redirect(url_for('index'))\n\n    @app.route('/protected')\n    @login_required\n    def protected():\n        return f'Logged in as: {current_user.username}'\n\n    return app\n\n# Example usage:\napp = task_func('your_secret_key', 'your_template_folder')\n\n```"}
{"task_id": "BigCodeBench/89", "solution": "import numpy as np", "raw_solution": "import numpy as np\nimport matplotlib.pyplot from sklearn import task_func from matplotlib.patches import task from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches from matplotlib.patches"}
{"task_id": "BigCodeBench/92", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom matplotlib.collections import PathCollection\ndef task_func(data, n_clusters=3):\n    if not isinstance(data, pd.DataFrame):\n        raise ValueError(\"Input 'data' must be a pandas DataFrame.\")\n    if not isinstance(n_clusters, int) or n_clusters <= 1:\n        raise ValueError(\"Input 'n_clusters' must be an integer greater than 1.\")\n    \n    kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(data)\n    labels = kmeans.labels_\n    centroids = kmeans.cluster_centers_\n    \n    fig, ax = plt.subplots()\n    scatter = ax.scatter(data.iloc[:, 0], data.iloc[:, 1], c=labels, cmap='viridis')\n    ax.scatter(centroids[:, 0], centroids[:, 1], marker='*', s=200, c='red')\n    \n    return labels, ax", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom matplotlib.collections import PathCollection\n\ndef task_func(data, n_clusters=3):\n    if not isinstance(data, pd.DataFrame):\n        raise ValueError(\"Input 'data' must be a pandas DataFrame.\")\n    if not isinstance(n_clusters, int) or n_clusters <= 1:\n        raise ValueError(\"Input 'n_clusters' must be an integer greater than 1.\")\n    \n    kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(data)\n    labels = kmeans.labels_\n    centroids = kmeans.cluster_centers_\n    \n    fig, ax = plt.subplots()\n    scatter = ax.scatter(data.iloc[:, 0], data.iloc[:, 1], c=labels, cmap='viridis')\n    ax.scatter(centroids[:, 0], centroids[:, 1], marker='*', s=200, c='red')\n    \n    return labels, ax\n\n# Example usage:\n# data = pd.DataFrame({\n#     'x': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n#     'y': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n# })\n# labels, ax = task_func(data)\n# plt.show()\n\n```"}
{"task_id": "BigCodeBench/93", "solution": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\ndef task_func(data, n_components=2):\n    if not isinstance(n_components, int) or n_components <= 0:\n        raise ValueError(\"n_components must be a positive integer\")\n    \n    pca = PCA(n_components=n_components)\n    transformed_data = pca.fit_transform(data)\n    \n    transformed_df = pd.DataFrame(transformed_data, columns=[f'PC{i+1}' for i in range(n_components)])\n    \n    fig, ax = plt.subplots()\n    ax.scatter(transformed_df['PC1'], transformed_df['PC2'])\n    \n    return transformed_df, ax\ndata = pd.DataFrame({\n    'Feature1': [1, 2, 3, 4, 5],\n    'Feature2': [5, 4, 3, 2, 1],\n    'Feature3': [2, 3, 4, 5, 6]\n})", "raw_solution": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\n\ndef task_func(data, n_components=2):\n    if not isinstance(n_components, int) or n_components <= 0:\n        raise ValueError(\"n_components must be a positive integer\")\n    \n    pca = PCA(n_components=n_components)\n    transformed_data = pca.fit_transform(data)\n    \n    transformed_df = pd.DataFrame(transformed_data, columns=[f'PC{i+1}' for i in range(n_components)])\n    \n    fig, ax = plt.subplots()\n    ax.scatter(transformed_df['PC1'], transformed_df['PC2'])\n    \n    return transformed_df, ax\n\n# Example usage:\ndata = pd.DataFrame({\n    'Feature1': [1, 2, 3, 4, 5],\n    'Feature2': [5, 4, 3, 2, 1],\n    'Feature3': [2, 3, 4, 5, 6]\n})\n\ntransformed_data, scatter_plot = task_func(data)\n"}
{"task_id": "BigCodeBench/99", "solution": "import matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.datasets import load_iris\ndef task_func():\n    # Load the iris dataset\n    iris = load_iris()\n    iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n    iris_df['species'] = iris.target\n    \n    # Set the global font to Arial\n    plt.rcParams['font.family'] = 'Arial'\n    \n    # Create a pair plot\n    pair_plot = sns.pairplot(iris_df, hue='species')\n    \n    # Set the title of the plot\n    pair_plot.fig.suptitle('Iris Dataset Pair Plot')\n    \n    # Return the matplotlib Figure object\n    return pair_plot.fig", "raw_solution": "import matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.datasets import load_iris\n\ndef task_func():\n    # Load the iris dataset\n    iris = load_iris()\n    iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n    iris_df['species'] = iris.target\n    \n    # Set the global font to Arial\n    plt.rcParams['font.family'] = 'Arial'\n    \n    # Create a pair plot\n    pair_plot = sns.pairplot(iris_df, hue='species')\n    \n    # Set the title of the plot\n    pair_plot.fig.suptitle('Iris Dataset Pair Plot')\n    \n    # Return the matplotlib Figure object\n    return pair_plot.fig\n\n# Test the function\nfig = task_func()\nplt.show()\n\n```"}
{"task_id": "BigCodeBench/100", "solution": "import matplotlib.pyplot as plt\nimport pandas as pd\nimport random\nfrom datetime import datetime", "raw_solution": "import matplotlib.pyplot as plt\nimport pandas as pd\nimport random\nfrom datetime import datetime\n\ndef task_func(seed=42):\n    try:\n        # Set the seed for reproducibility\n        random.seed(seed)\n        \n        # Generate random time series data for the past 30 days\n        dates = [datetime(2023, 1, 1) + pd.Timedelta(days=x) for x in range(3)]\n        from pandas.compat.pandas import from_compat from pandas.compat.pandas import from_compat from pandas.compat.pandas.compat from pandas.compat.compat from pandas.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat.compat"}
{"task_id": "BigCodeBench/101", "solution": "import matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np", "raw_solution": "import matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\n\ndef task_func(data_url=\"http://lib.stat.cmu.edu/datasets/boston\", seed=42):\n    try:\n        # Load the Boston Housing dataset\n        from sklearn.datasets import fetch_openml\n        from sklearn.datasets._base import BuiltinImporter\n        from importlib import import_module\n        from importlib.machinery import importlib from sklearn.datasets._base import import_module from sklearn.datasets._base import from sklearn.datasets._base import from sklearn.datasets._base import from sklearn.datasets._base import from sklearn.datasets._base from sklearn.datasets._base from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from sklearn.datasets from"}
{"task_id": "BigCodeBench/108", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom statsmodels.tsa.seasonal import seasonal_decompose\ndef task_func(df, freq='D', decomposition_model='multiplicative'):\n    # Check if 'df' is a DataFrame\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input 'df' must be a pandas DataFrame.\")\n    \n    # Check if 'df' contains the required columns\n    if 'value' not in df.columns:\n        raise ValueError(\"Input 'df' must contain a 'value' column.\")\n    \n    # Check if 'freq' is a valid frequency string\n    if freq not in ['D', 'W', 'M', 'Q', 'A']:\n        raise ValueError(\"Invalid frequency string. Please use 'D', 'W', 'M', 'Q', or 'A'.\")\n    \n    # Check if 'decomposition_model' is 'additive' or 'multiplicative'\n    if decomposition_model not in ['additive', 'multiplicative']:\n        raise ValueError(\"Invalid decomposition model. Please use 'additive' or 'multiplicative'.\")\n    \n    # Perform decomposition\n    decomposition = seasonal_decompose(df['value'], model=decomposition_model, period=365 if freq == 'Y' else 1)\n    \n    # Plot decomposition\n    fig, axes = plt.subplots(4, 1, figsize=(10, 12))\n    decomposition.plot(ax=axes)\n    \n    return decomposition, axes", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom statsmodels.tsa.seasonal import seasonal_decompose\n\ndef task_func(df, freq='D', decomposition_model='multiplicative'):\n    # Check if 'df' is a DataFrame\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input 'df' must be a pandas DataFrame.\")\n    \n    # Check if 'df' contains the required columns\n    if 'value' not in df.columns:\n        raise ValueError(\"Input 'df' must contain a 'value' column.\")\n    \n    # Check if 'freq' is a valid frequency string\n    if freq not in ['D', 'W', 'M', 'Q', 'A']:\n        raise ValueError(\"Invalid frequency string. Please use 'D', 'W', 'M', 'Q', or 'A'.\")\n    \n    # Check if 'decomposition_model' is 'additive' or 'multiplicative'\n    if decomposition_model not in ['additive', 'multiplicative']:\n        raise ValueError(\"Invalid decomposition model. Please use 'additive' or 'multiplicative'.\")\n    \n    # Perform decomposition\n    decomposition = seasonal_decompose(df['value'], model=decomposition_model, period=365 if freq == 'Y' else 1)\n    \n    # Plot decomposition\n    fig, axes = plt.subplots(4, 1, figsize=(10, 12))\n    decomposition.plot(ax=axes)\n    \n    return decomposition, axes\n\n# Example usage\n# df = pd.DataFrame({'value': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]})\n# decomposition, axes = task_func(df, freq='D', decomposition_model='multiplicative')\n\n```"}
{"task_id": "BigCodeBench/120", "solution": "import pandas as pd\nfrom datetime import datetime, timedelta\nfrom random import randint, seed as random_seed\ndef task_func(start_date=datetime(2020, 1, 1), end_date=datetime(2020, 12, 31), seed=42):\n    if not isinstance(start_date, datetime) or not isinstance(end_date, datetime):\n        raise ValueError(\"start_date and end_date must be datetime.datetime instances\")\n    if start_date > end_date:\n        raise ValueError(\"start_date must be earlier than or equal to end_date\")\n    random_seed(seed)\n    date_range = (end_date - start_date).days + 1\n    random_dates = [start_date + timedelta(days=randint(0, date_range - 1)) for _ in range(date_range)]\n    return pd.Series(random_dates)", "raw_solution": "import pandas as pd\nfrom datetime import datetime, timedelta\nfrom random import randint, seed as random_seed\n\ndef task_func(start_date=datetime(2020, 1, 1), end_date=datetime(2020, 12, 31), seed=42):\n    if not isinstance(start_date, datetime) or not isinstance(end_date, datetime):\n        raise ValueError(\"start_date and end_date must be datetime.datetime instances\")\n    if start_date > end_date:\n        raise ValueError(\"start_date must be earlier than or equal to end_date\")\n    random_seed(seed)\n    date_range = (end_date - start_date).days + 1\n    random_dates = [start_date + timedelta(days=randint(0, date_range - 1)) for _ in range(date_range)]\n    return pd.Series(random_dates)\n\n# Test the function\n\n```"}
{"task_id": "BigCodeBench/123", "solution": "import pandas as pd\nimport glob\nfrom importlib import import_module\nimport importlib", "raw_solution": "import pandas as pd\nimport glob\nfrom importlib import import_module\nimport importlib\nimport importlib._bootstrap_external from from import from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from"}
{"task_id": "BigCodeBench/124", "solution": "from random import randint, seed as random_seed\nimport time\nimport matplotlib.pyplot as plt\ndef task_func(my_list, size=100, seed=100):\n    if not isinstance(my_list, list):\n        raise TypeError(\"my_list must be a list\")\n    if not all(isinstance(x, (int, float)) for x in my_list):\n        raise ValueError(\"my_list must contain only numeric elements\")\n    \n    my_list.append(12)\n    total_sum = sum(my_list)\n    random_numbers = [randint(1, 100) for _ in range(min(total_sum, size))]\n    \n    start_time = time.time()\n    random_numbers = [randint(1, 100) for _ in range(min(total_sum, size))]\n    end_time = time.time()\n    \n    random_seed(seed)\n    random_numbers = [randint(1, 100) for _ in range(min(total_sum, size))]\n    \n    fig, ax = plt.subplots()\n    ax.hist(random_numbers, bins=range(1, 102), edgecolor='black')\n    ax.set_xlabel('Number')\n    ax.set_ylabel('Frequency')\n    \n    return (end_time - start_time), ax", "raw_solution": "from random import randint, seed as random_seed\nimport time\nimport matplotlib.pyplot as plt\n\ndef task_func(my_list, size=100, seed=100):\n    if not isinstance(my_list, list):\n        raise TypeError(\"my_list must be a list\")\n    if not all(isinstance(x, (int, float)) for x in my_list):\n        raise ValueError(\"my_list must contain only numeric elements\")\n    \n    my_list.append(12)\n    total_sum = sum(my_list)\n    random_numbers = [randint(1, 100) for _ in range(min(total_sum, size))]\n    \n    start_time = time.time()\n    random_numbers = [randint(1, 100) for _ in range(min(total_sum, size))]\n    end_time = time.time()\n    \n    random_seed(seed)\n    random_numbers = [randint(1, 100) for _ in range(min(total_sum, size))]\n    \n    fig, ax = plt.subplots()\n    ax.hist(random_numbers, bins=range(1, 102), edgecolor='black')\n    ax.set_xlabel('Number')\n    ax.set_ylabel('Frequency')\n    \n    return (end_time - start_time), ax\n\n```"}
{"task_id": "BigCodeBench/129", "solution": "from bs4 import BeautifulSoup\nfrom pandas import task\nfrom pandas.core.api import task\nfrom pandas.core.api import task", "raw_solution": "from bs4 import BeautifulSoup from pandas import task from pandas.core.api import task from pandas.core.api import task from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from pandas.core.api from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from"}
{"task_id": "BigCodeBench/139", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame) or df.empty:\n        raise ValueError(\"Input must be a non-empty DataFrame\")\n    numeric_cols = df.select_dtypes(include=[np.number]).columns\n    if not numeric_cols.size:\n        raise ValueError(\"DataFrame must contain at least one numeric column\")\n    axes = []\n    for col in numeric_cols:\n        ax = df[col].hist(bins=30, figsize=(8, 6))\n        ax.set_title(col)\n        ax.set_xlabel('Value')\n        ax.set_ylabel('Frequency')\n        axes.append(ax)\n    return axes\ndf = pd.DataFrame({\n    'A': np.random.randn(100),\n    'B': np.random.randint(0, 100, 100),\n    'C': np.random.rand(100)\n})", "raw_solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame) or df.empty:\n        raise ValueError(\"Input must be a non-empty DataFrame\")\n    numeric_cols = df.select_dtypes(include=[np.number]).columns\n    if not numeric_cols.size:\n        raise ValueError(\"DataFrame must contain at least one numeric column\")\n    axes = []\n    for col in numeric_cols:\n        ax = df[col].hist(bins=30, figsize=(8, 6))\n        ax.set_title(col)\n        ax.set_xlabel('Value')\n        ax.set_ylabel('Frequency')\n        axes.append(ax)\n    return axes\n\n# Test the function\nnp.random.seed(0)\ndf = pd.DataFrame({\n    'A': np.random.randn(100),\n    'B': np.random.randint(0, 100, 100),\n    'C': np.random.rand(100)\n})\naxes = task_func(df)\n\n```"}
{"task_id": "BigCodeBench/147", "solution": "import socket\nfrom ipaddress import IPv4Network\nfrom threading import Thread\ndef task_func(ip_range, port):\n    # Create an IPv4Network object from the given IP range\n    network = IPv4Network(ip_range)\n    \n    # Initialize a dictionary to store the results\n    results = {}\n    \n    # Define a function to check if a port is open on a given IP\n    def check_port(ip):\n        try:\n            # Create a socket object\n            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n            sock.settimeout(1)  # Set a timeout for the connection attempt\n            # Attempt to connect to the specified port\n            result = sock.connect_ex((ip, port))\n            # Close the socket\n            sock.close()\n            # Return True if the port is open, False otherwise\n            return result == 0\n        except Exception as e:\n            print(f\"Error checking port {port} on {ip}: {e}\")\n            return False\n    \n    # Iterate over all IP addresses in the network\n    for ip in network.hosts():\n        # Convert the IP address to a string\n        ip_str = str(ip)\n        # Check if the port is open on the current IP address\n        results[ip_str] = check_port(ip_str)\n    \n    # Return the dictionary of results\n    return results\nip_range = '192.168.1.0/24'\nport = 80", "raw_solution": "import socket\nfrom ipaddress import IPv4Network\nfrom threading import Thread\n\ndef task_func(ip_range, port):\n    # Create an IPv4Network object from the given IP range\n    network = IPv4Network(ip_range)\n    \n    # Initialize a dictionary to store the results\n    results = {}\n    \n    # Define a function to check if a port is open on a given IP\n    def check_port(ip):\n        try:\n            # Create a socket object\n            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n            sock.settimeout(1)  # Set a timeout for the connection attempt\n            # Attempt to connect to the specified port\n            result = sock.connect_ex((ip, port))\n            # Close the socket\n            sock.close()\n            # Return True if the port is open, False otherwise\n            return result == 0\n        except Exception as e:\n            print(f\"Error checking port {port} on {ip}: {e}\")\n            return False\n    \n    # Iterate over all IP addresses in the network\n    for ip in network.hosts():\n        # Convert the IP address to a string\n        ip_str = str(ip)\n        # Check if the port is open on the current IP address\n        results[ip_str] = check_port(ip_str)\n    \n    # Return the dictionary of results\n    return results\n\n# Example usage\nip_range = '192.168.1.0/24'\nport = 80"}
{"task_id": "BigCodeBench/161", "solution": "import re\nimport pandas as pd\nfrom datetime import datetime\ndef task_func(log_file):\n    from pandas import DataFrame\n    import pandas as pd\n    \n    # Add import statement for datetime from datetime module\n    from datetime import datetime\n    \n    # Add import statement for DataFrame from pandas module\n    from pandas import DataFrame\n    \n    # Add import statement for re from re module\n    import re\n    \n    # Add import statement for datetime from datetime module\n    from datetime import datetime\n    \n    # Add import statement for DataFrame from pandas module\n    from pandas import DataFrame\n    \n    # Add import statement for re from re module\n    import re\n    \n    # Add import statement for datetime from datetime module\n    from datetime import datetime\n    \n    # Add import statement for DataFrame from pandas module\n    from pandas import DataFrame\n    \n    # Add import statement for re from re module\n    import re\n    \n    # Add import statement for datetime from datetime module\n    from datetime import datetime\n    \n    # Add import statement for DataFrame from pandas module\n    from pandas import DataFrame\n    \n    # Add import statement for re from re module\n    import re\n    \n    # Add import statement for datetime from datetime module\n    from datetime import datetime\n    \n    # Add import statement for DataFrame from pandas module\n    from pandas import DataFrame\n    \n    # Add import statement for re from re module\n    import re\n    \n    # Add import statement for datetime from datetime module\n    from datetime import datetime\n    \n    # Add import statement for pandas from pandas module\n    import pandas as pd\n    \n    # Add import statement for datetime from datetime module\n    from datetime import datetime\n    \n    # Add import statement for re from re module\n    import re\n    \n    # Add import statement for pandas from pandas module\n    from pandas import DataFrame\n    \n    # Add import statement for datetime from datetime module\n    from datetime import datetime\n    \n    # Add import statement for re from re module\n    import re\n    \n    # Add import statement for pandas from pandas module\n    from pandas import DataFrame\n    \n    # Add import statement for datetime from datetime module\n    from datetime import datetime\n    \n    # Add import statement for re from re module\n    import re\n    \n    # Add import statement for pandas from pandas module\n    from pandas import DataFrame\n    \n    # Add import statement for datetime from datetime module\n    from datetime import datetime\n    \n    # Add import statement for pandas from pandas module\n    from pandas import DataFrame\n    \n    # Add import statement for re from re module\n    import re\n    \n    # Add import statement for pandas from pandas module\n    from pandas import DataFrame\n    \n    # Add import statement for datetime from datetime module\n    from datetime import datetime\n    \n    # Add import statement for pandas from pandas module\n    from pandas import DataFrame\n    \n    # Add import statement for re from re module\n    import re\n    \n    # Add import statement for pandas from pandas module\n    from pandas import DataFrame\n    \n    # Add import statement for datetime from datetime module\n    from datetime import datetime\n    \n    # Add import statement for pandas from pandas module\n    from pandas import DataFrame\n    \n    # Add import statement for re from re module\n    import re\n    \n    # Add import statement for pandas from pandas module\n    from pandas import DataFrame\n    \n    # Add import statement for datetime from datetime module\n    from datetime import datetime\n    \n    # Add import statement for pandas from pandas module\n    from pandas import DataFrame\n    \n    # Add import statement for re from re module\n    import re\n    \n    # Add import statement for pandas from pandas module\n    from pandas import DataFrame\n    \n    # Add import statement for datetime from datetime module\n    from datetime import datetime\n    \n    # Add import statement for pandas from pandas module\n    from pandas import DataFrame\n    \n    # Add import statement for re from re module\n    import re\n    \n    # Add import statement for pandas from pandas module\n    from pandas import DataFrame\n    \n    # Add import statement for datetime from datetime module\n    from datetime import datetime\n    \n    # Add import statement for pandas from pandas module\n    from pandas import DataFrame\n    \n    # Add import statement for re from re module\n    import re\n    \n    # Add import statement for pandas from pandas module\n    from pandas import DataFrame\n    \n    # Add import statement for datetime from datetime module\n    from datetime import datetime\n    \n    # Add import statement for pandas from pandas module\n    from pandas import DataFrame\n    \n    # Add import statement for re from re module\n    from re import *\n    \n    # Add import statement for pandas from pandas module\n    from pandas import *\n    \n    # Add import statement for datetime from datetime module\n    from datetime import *\n    \n    # Add import statement for pandas from pandas module\n    from pandas import *\n    \n    # Add import statement for datetime from datetime module\n    from datetime import *\n    \n    # Add import statement for pandas from pandas module\n    from pandas import *\n    \n    # Add import statement for datetime from datetime module\n    from datetime import *\n    \n    # Add import statement for pandas from pandas module\n    from pandas import *\n    \n    # Add import statement for datetime from datetime module\n    from datetime import *\n    \n    # Add import statement for pandas from pandas module", "raw_solution": "import re\nimport pandas as pd\nfrom datetime import datetime\n\ndef task_func(log_file):\n    from pandas import DataFrame\n    import pandas as pd\n    \n    # Add import statement for datetime from datetime module\n    from datetime import datetime\n    \n    # Add import statement for DataFrame from pandas module\n    from pandas import DataFrame\n    \n    # Add import statement for re from re module\n    import re\n    \n    # Add import statement for datetime from datetime module\n    from datetime import datetime\n    \n    # Add import statement for DataFrame from pandas module\n    from pandas import DataFrame\n    \n    # Add import statement for re from re module\n    import re\n    \n    # Add import statement for datetime from datetime module\n    from datetime import datetime\n    \n    # Add import statement for DataFrame from pandas module\n    from pandas import DataFrame\n    \n    # Add import statement for re from re module\n    import re\n    \n    # Add import statement for datetime from datetime module\n    from datetime import datetime\n    \n    # Add import statement for DataFrame from pandas module\n    from pandas import DataFrame\n    \n    # Add import statement for re from re module\n    import re\n    \n    # Add import statement for datetime from datetime module\n    from datetime import datetime\n    \n    # Add import statement for DataFrame from pandas module\n    from pandas import DataFrame\n    \n    # Add import statement for re from re module\n    import re\n    \n    # Add import statement for datetime from datetime module\n    from datetime import datetime\n    \n    # Add import statement for pandas from pandas module\n    import pandas as pd\n    \n    # Add import statement for datetime from datetime module\n    from datetime import datetime\n    \n    # Add import statement for re from re module\n    import re\n    \n    # Add import statement for pandas from pandas module\n    from pandas import DataFrame\n    \n    # Add import statement for datetime from datetime module\n    from datetime import datetime\n    \n    # Add import statement for re from re module\n    import re\n    \n    # Add import statement for pandas from pandas module\n    from pandas import DataFrame\n    \n    # Add import statement for datetime from datetime module\n    from datetime import datetime\n    \n    # Add import statement for re from re module\n    import re\n    \n    # Add import statement for pandas from pandas module\n    from pandas import DataFrame\n    \n    # Add import statement for datetime from datetime module\n    from datetime import datetime\n    \n    # Add import statement for pandas from pandas module\n    from pandas import DataFrame\n    \n    # Add import statement for re from re module\n    import re\n    \n    # Add import statement for pandas from pandas module\n    from pandas import DataFrame\n    \n    # Add import statement for datetime from datetime module\n    from datetime import datetime\n    \n    # Add import statement for pandas from pandas module\n    from pandas import DataFrame\n    \n    # Add import statement for re from re module\n    import re\n    \n    # Add import statement for pandas from pandas module\n    from pandas import DataFrame\n    \n    # Add import statement for datetime from datetime module\n    from datetime import datetime\n    \n    # Add import statement for pandas from pandas module\n    from pandas import DataFrame\n    \n    # Add import statement for re from re module\n    import re\n    \n    # Add import statement for pandas from pandas module\n    from pandas import DataFrame\n    \n    # Add import statement for datetime from datetime module\n    from datetime import datetime\n    \n    # Add import statement for pandas from pandas module\n    from pandas import DataFrame\n    \n    # Add import statement for re from re module\n    import re\n    \n    # Add import statement for pandas from pandas module\n    from pandas import DataFrame\n    \n    # Add import statement for datetime from datetime module\n    from datetime import datetime\n    \n    # Add import statement for pandas from pandas module\n    from pandas import DataFrame\n    \n    # Add import statement for re from re module\n    import re\n    \n    # Add import statement for pandas from pandas module\n    from pandas import DataFrame\n    \n    # Add import statement for datetime from datetime module\n    from datetime import datetime\n    \n    # Add import statement for pandas from pandas module\n    from pandas import DataFrame\n    \n    # Add import statement for re from re module\n    import re\n    \n    # Add import statement for pandas from pandas module\n    from pandas import DataFrame\n    \n    # Add import statement for datetime from datetime module\n    from datetime import datetime\n    \n    # Add import statement for pandas from pandas module\n    from pandas import DataFrame\n    \n    # Add import statement for re from re module\n    from re import *\n    \n    # Add import statement for pandas from pandas module\n    from pandas import *\n    \n    # Add import statement for datetime from datetime module\n    from datetime import *\n    \n    # Add import statement for pandas from pandas module\n    from pandas import *\n    \n    # Add import statement for datetime from datetime module\n    from datetime import *\n    \n    # Add import statement for pandas from pandas module\n    from pandas import *\n    \n    # Add import statement for datetime from datetime module\n    from datetime import *\n    \n    # Add import statement for pandas from pandas module\n    from pandas import *\n    \n    # Add import statement for datetime from datetime module\n    from datetime import *\n    \n    # Add import statement for pandas from pandas module\n"}
{"task_id": "BigCodeBench/162", "solution": "import re\nimport matplotlib.pyplot as plt\nimport numpy as np\ndef task_func(text, rwidth=0.8):\n    # Importing the required module\n    from collections import Counter\n    \n    # Splitting the text into words\n    words = re.findall(r'\\b\\w+\\b', text)\n    \n    # Counting the occurrences of each word length\n    from collections import Counter\n    import collections\n    collections.Counter = Counter\n    \n    # Calculate the word lengths\n    word_lengths = Counter(len(word) for word in words)\n    \n    # Plotting the histogram\n    import matplotlib.pyplot as plt\n    import numpy as np\n    \n    # Create a figure and axis\n    fig, ax = plt.subplots()\n    \n    # Plot the histogram\n    ax.bar(word_lengths.keys(), word_lengths.values(), width=rwidth, align='center')\n    \n    # Set the title and labels\n    ax.set_title('Word Length Distribution')\n    ax.set_xlabel('Word Length')\n    ax.set_ylabel('Frequency')\n    \n    # Return the Axes object\n    return ax", "raw_solution": "import re\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef task_func(text, rwidth=0.8):\n    # Importing the required module\n    from collections import Counter\n    \n    # Splitting the text into words\n    words = re.findall(r'\\b\\w+\\b', text)\n    \n    # Counting the occurrences of each word length\n    from collections import Counter\n    import collections\n    collections.Counter = Counter\n    \n    # Calculate the word lengths\n    word_lengths = Counter(len(word) for word in words)\n    \n    # Plotting the histogram\n    import matplotlib.pyplot as plt\n    import numpy as np\n    \n    # Create a figure and axis\n    fig, ax = plt.subplots()\n    \n    # Plot the histogram\n    ax.bar(word_lengths.keys(), word_lengths.values(), width=rwidth, align='center')\n    \n    # Set the title and labels\n    ax.set_title('Word Length Distribution')\n    ax.set_xlabel('Word Length')\n    ax.set_ylabel('Frequency')\n    \n    # Return the Axes object\n    return ax\n\n# Test the function with provided data points\n\n```"}
{"task_id": "BigCodeBench/177", "solution": "from nltk.tag.tagutil import from_module\nfrom string import punctuation\nfrom importlib import import_module\nfrom importlib._bootstrap import _import_module_from_spec\nfrom importlib._bootstrap_external import _bootstrap, _bootstrap_external, _install", "raw_solution": "from nltk.tag.tagutil import from_module\nfrom string import punctuation\nfrom importlib import import_module\nfrom importlib._bootstrap import _import_module_from_spec\nfrom importlib._bootstrap_external import _bootstrap, _bootstrap_external, _install\nfrom importlib._bootstrap import _import_module_from_spec as _m from_module\nfrom _f from _bootstrap _m _m from _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _m _"}
{"task_id": "BigCodeBench/184", "solution": "import pandas as pd\nimport re\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom collections import Counter\nfrom typing import List\nSTOPWORDS = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself',\n             'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself',\n             'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these',\n             'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do',\n             'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while',\n             'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before',\n             'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again',\n             'further', 'then', 'once']\ndef task_func(dataframe, text_column):\n    \"\"\"\n    Prepares and transforms text data from a specified column in a DataFrame by removing stopwords, numbers, and punctuation,\n    and subsequently applying a vectorization process to convert text into a numeric format suitable for analysis.\n    \n    Args:\n    dataframe (pd.DataFrame): The input DataFrame.\n    text_column (str): The name of the column containing the text data.\n    \n    Returns:\n    pd.DataFrame: A DataFrame with each word (after preprocessing) as a column and their count as rows.\n    \"\"\"\n    # Remove stopwords, numbers, and punctuation\n    def preprocess_text(text: str) -> str:\n        text = re.sub(r'\\d+', '', text)  # Remove numbers\n        text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n        text = text.lower().split()  # Convert to lowercase and split into words\n        return [word for word in text if word not in STOPWORDS]  # Remove stopwords\n    \n    # Apply preprocessing to the text column\n    dataframe[text_column] = dataframe[text_column].apply(preprocess_text)\n    \n    # Flatten the list of lists into a single list\n    all_words = [word for sublist in dataframe[text_column] for word in sublist]\n    \n    # Count the occurrences of each word\n    word_counts = Counter(all_words)\n    \n    # Create a DataFrame from the word counts\n    result_df = pd.DataFrame(list(word_counts.items()), columns=['word', 'count'])\n    \n    return result_df", "raw_solution": "import pandas as pd\nimport re\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom collections import Counter\nfrom typing import List\n\n# Constants\nSTOPWORDS = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself',\n             'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself',\n             'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these',\n             'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do',\n             'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while',\n             'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before',\n             'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again',\n             'further', 'then', 'once']\n\ndef task_func(dataframe, text_column):\n    \"\"\"\n    Prepares and transforms text data from a specified column in a DataFrame by removing stopwords, numbers, and punctuation,\n    and subsequently applying a vectorization process to convert text into a numeric format suitable for analysis.\n    \n    Args:\n    dataframe (pd.DataFrame): The input DataFrame.\n    text_column (str): The name of the column containing the text data.\n    \n    Returns:\n    pd.DataFrame: A DataFrame with each word (after preprocessing) as a column and their count as rows.\n    \"\"\"\n    # Remove stopwords, numbers, and punctuation\n    def preprocess_text(text: str) -> str:\n        text = re.sub(r'\\d+', '', text)  # Remove numbers\n        text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n        text = text.lower().split()  # Convert to lowercase and split into words\n        return [word for word in text if word not in STOPWORDS]  # Remove stopwords\n    \n    # Apply preprocessing to the text column\n    dataframe[text_column] = dataframe[text_column].apply(preprocess_text)\n    \n    # Flatten the list of lists into a single list\n    all_words = [word for sublist in dataframe[text_column] for word in sublist]\n    \n    # Count the occurrences of each word\n    word_counts = Counter(all_words)\n    \n    # Create a DataFrame from the word counts\n    result_df = pd.DataFrame(list(word_counts.items()), columns=['word', 'count'])\n    \n    return result_df\n\n# Example usage"}
{"task_id": "BigCodeBench/187", "solution": "import numpy as np\nfrom numpy import random\nfrom importlib import import_module\nfrom random import random as _random", "raw_solution": "import numpy as np\nfrom numpy import random\nfrom importlib import import_module\nnp = import_module('numpy.random', 'random', globals(), locals(), fromlist=['random'], level=0)\nfrom random import random as _random\nfrom random import random as _random from random import random as _random from random import random as _random from random import random as _random from random import random from random import random from random import random from random import random from random import random from random import random from random import random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from random from"}
{"task_id": "BigCodeBench/199", "solution": "import pandas as pd\nimport pytz\nfrom datetime import datetime\nfrom random import randint, seed as set_seed\ndef task_func(\n    utc_datetime,\n    cities=['New York', 'London', 'Beijing', 'Tokyo', 'Sydney'],\n    weather_conditions=['Sunny', 'Cloudy', 'Rainy', 'Snowy', 'Stormy'],\n    timezones={\n        'New York': 'America/New_York',\n        'London': 'Europe/London',\n        'Beijing': 'Asia/Shanghai',\n        'Tokyo': 'Asia/Tokyo',\n        'Sydney': 'Australia/Sydney'\n    },\n    seed=42\n):\n    # Check if utc_datetime is a datetime object\n    if not isinstance(utc_datetime, datetime):\n        raise ValueError(\"utc_datetime must be a datetime object\")\n    \n    # Set the seed for reproducibility\n    set_seed(seed)\n    \n    # Create an empty list to store the weather report\n    weather_report = []\n    \n    # Iterate over each city\n    for city in cities:\n        # Get the local timezone for the city\n        local_timezone = pytz.timezone(timezones[city])\n        \n        # Convert the UTC datetime to the local timezone\n        local_datetime = utc_datetime.astimezone(local_timezone)\n        \n        # Generate a random weather condition\n        weather_condition = weather_conditions[randint(0, len(weather_conditions) - 1)]\n        \n        # Append the weather report for the city to the list\n        weather_report.append({\n            'City': city,\n            'Local Time': local_datetime.strftime('%Y-%m-%d %H:%M:%S %Z'),\n            'Weather Condition': weather_condition\n        })\n    \n    # Create a pandas DataFrame from the weather report\n    weather_df = pd.DataFrame(weather_report)\n    \n    return weather_df\nutc_datetime = datetime(2023, 10, 1, 12, 0, 0, tzinfo=pytz.UTC)", "raw_solution": "import pandas as pd\nimport pytz\nfrom datetime import datetime\nfrom random import randint, seed as set_seed\n\ndef task_func(\n    utc_datetime,\n    cities=['New York', 'London', 'Beijing', 'Tokyo', 'Sydney'],\n    weather_conditions=['Sunny', 'Cloudy', 'Rainy', 'Snowy', 'Stormy'],\n    timezones={\n        'New York': 'America/New_York',\n        'London': 'Europe/London',\n        'Beijing': 'Asia/Shanghai',\n        'Tokyo': 'Asia/Tokyo',\n        'Sydney': 'Australia/Sydney'\n    },\n    seed=42\n):\n    # Check if utc_datetime is a datetime object\n    if not isinstance(utc_datetime, datetime):\n        raise ValueError(\"utc_datetime must be a datetime object\")\n    \n    # Set the seed for reproducibility\n    set_seed(seed)\n    \n    # Create an empty list to store the weather report\n    weather_report = []\n    \n    # Iterate over each city\n    for city in cities:\n        # Get the local timezone for the city\n        local_timezone = pytz.timezone(timezones[city])\n        \n        # Convert the UTC datetime to the local timezone\n        local_datetime = utc_datetime.astimezone(local_timezone)\n        \n        # Generate a random weather condition\n        weather_condition = weather_conditions[randint(0, len(weather_conditions) - 1)]\n        \n        # Append the weather report for the city to the list\n        weather_report.append({\n            'City': city,\n            'Local Time': local_datetime.strftime('%Y-%m-%d %H:%M:%S %Z'),\n            'Weather Condition': weather_condition\n        })\n    \n    # Create a pandas DataFrame from the weather report\n    weather_df = pd.DataFrame(weather_report)\n    \n    return weather_df\n\n# Example usage\nutc_datetime = datetime(2023, 10, 1, 12, 0, 0, tzinfo=pytz.UTC)\nweather_report = task_func(utc_datetime)"}
{"task_id": "BigCodeBench/208", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\ndef task_func(elements, seed=0):\n    if not isinstance(elements, int) or elements <= 0:\n        raise ValueError(\"elements must be a positive integer\")\n    \n    np.random.seed(seed)\n    random_walk = np.cumsum(np.random.choice([-1, 1], size=elements))\n    \n    descriptive_stats = {\n        'count': len(random_walk),\n        'mean': np.mean(random_walk),\n        'std': np.std(random_walk),\n        'min': np.min(random_walk),\n        '5th_percentile': np.percentile(random_walk, 5),\n        '25th_percentile': np.percentile(random_walk, 25),\n        'median': np.median(random_walk),\n        '75th_percentile': np.percentile(random_walk, 75),\n        '95th_percentile': np.percentile(random_walk, 95),\n        'max': np.max(random_walk)\n    }\n    \n    fig, ax = plt.subplots()\n    ax.plot(random_walk)\n    ax.set_xlabel('Step')\n    ax.set_ylabel('Position')\n    ax.set_title('Random Walk')\n    \n    return descriptive_stats, ax", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\ndef task_func(elements, seed=0):\n    if not isinstance(elements, int) or elements <= 0:\n        raise ValueError(\"elements must be a positive integer\")\n    \n    np.random.seed(seed)\n    random_walk = np.cumsum(np.random.choice([-1, 1], size=elements))\n    \n    descriptive_stats = {\n        'count': len(random_walk),\n        'mean': np.mean(random_walk),\n        'std': np.std(random_walk),\n        'min': np.min(random_walk),\n        '5th_percentile': np.percentile(random_walk, 5),\n        '25th_percentile': np.percentile(random_walk, 25),\n        'median': np.median(random_walk),\n        '75th_percentile': np.percentile(random_walk, 75),\n        '95th_percentile': np.percentile(random_walk, 95),\n        'max': np.max(random_walk)\n    }\n    \n    fig, ax = plt.subplots()\n    ax.plot(random_walk)\n    ax.set_xlabel('Step')\n    ax.set_ylabel('Position')\n    ax.set_title('Random Walk')\n    \n    return descriptive_stats, ax\n\n```"}
{"task_id": "BigCodeBench/211", "solution": "import requests", "raw_solution": "import requests\nimport os from zipfile import from import zipfile\nfrom import os.path from os.path import from zipfile import *\nfrom import os.path from os.path from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from"}
{"task_id": "BigCodeBench/214", "solution": "import random\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\ndef task_func(seed=42, image_size=(100, 100, 3), range_low=0, range_high=255):\n    if range_low >= range_high:\n        raise ValueError(\"range_low must be less than range_high\")\n    \n    random.seed(seed)\n    image = np.random.randint(range_low, range_high, size=image_size, dtype=np.uint8)\n    \n    return image", "raw_solution": "import random\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\n\ndef task_func(seed=42, image_size=(100, 100, 3), range_low=0, range_high=255):\n    if range_low >= range_high:\n        raise ValueError(\"range_low must be less than range_high\")\n    \n    random.seed(seed)\n    image = np.random.randint(range_low, range_high, size=image_size, dtype=np.uint8)\n    \n    return image\n\nimport numpy as np\n\n# Test the function with the provided function from numpy\nax = task_func(image_size=image_size from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from"}
{"task_id": "BigCodeBench/227", "solution": "import numpy as np", "raw_solution": "import numpy as np\nimport os from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from"}
{"task_id": "BigCodeBench/239", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\ndef task_func(original):\n    # Extract numeric values from the list of tuples\n    numeric_values = [item for sublist in original for item in sublist if isinstance(item, (int, float))]\n    \n    # Convert the list to a numpy array\n    numeric_array = np.array(numeric_values)\n    \n    # Calculate basic statistics\n    mean = numeric_array.mean()\n    std_dev = numeric_array.std()\n    min_val = numeric_array.min()\n    max_val = numeric_array.max()\n    \n    # Create a dictionary to store the statistics\n    statistics = {\n        'mean': mean,\n        'std_dev': std_dev,\n        'min': min_val,\n        'max': max_val\n    }\n    \n    # Plot the histogram with overlaid PDF\n    fig, ax = plt.subplots()\n    ax.hist(numeric_array, bins='auto', density=True, alpha=0.6, color='g')\n    xmin, xmax = plt.xlim()\n    x = np.linspace(xmin, xmax, 100)\n    p = stats.gaussian_kde(numeric_array)\n    ax.plot(x, p(x), \"k\", linewidth=2)\n    \n    return numeric_array, statistics, ax", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\n\ndef task_func(original):\n    # Extract numeric values from the list of tuples\n    numeric_values = [item for sublist in original for item in sublist if isinstance(item, (int, float))]\n    \n    # Convert the list to a numpy array\n    numeric_array = np.array(numeric_values)\n    \n    # Calculate basic statistics\n    mean = numeric_array.mean()\n    std_dev = numeric_array.std()\n    min_val = numeric_array.min()\n    max_val = numeric_array.max()\n    \n    # Create a dictionary to store the statistics\n    statistics = {\n        'mean': mean,\n        'std_dev': std_dev,\n        'min': min_val,\n        'max': max_val\n    }\n    \n    # Plot the histogram with overlaid PDF\n    fig, ax = plt.subplots()\n    ax.hist(numeric_array, bins='auto', density=True, alpha=0.6, color='g')\n    xmin, xmax = plt.xlim()\n    x = np.linspace(xmin, xmax, 100)\n    p = stats.gaussian_kde(numeric_array)\n    ax.plot(x, p(x), \"k\", linewidth=2)\n    \n    return numeric_array, statistics, ax\n\n# Test the function with provided data points\n\n```"}
{"task_id": "BigCodeBench/241", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn import preprocessing", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn import preprocessing\n\ndef task_func(original):\n    from sklearn import import_module from sklearn.__main__ import sklearn from sklearn.__main__ from sklearn.__main__ from sklearn.__main from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from sklearn from"}
{"task_id": "BigCodeBench/267", "solution": "import numpy as np\nfrom scipy import fftpack\nimport matplotlib.pyplot as plt\ndef task_func(data, sample_rate=8000):\n    # Add a new key \"a\" with the value 1 to the dictionary\n    data[\"a\"] = 1\n    \n    # Generate a signal based on the values in \"data\"\n    signal = np.array(list(data.values()))\n    \n    # Run a Fast Fourier Transform (FFT) on the signal\n    from numpy import newaxis\n    from importlib import reload\n    import importlib\n    import sys\n    from importlib.machinery import ModuleSpec\n    from importlib.abc import MetaPathFinder\n    from types import ModuleType\n    from importlib.machinery import ModuleSpec\n    from importlib.abc import MetaPathFinder\n    from types import ModuleType\n    from sys import import_module\n    from importlib.machinery import import_module\n    from sys import modules\n    from sys import import_module", "raw_solution": "import numpy as np\nfrom scipy import fftpack\nimport matplotlib.pyplot as plt\n\ndef task_func(data, sample_rate=8000):\n    # Add a new key \"a\" with the value 1 to the dictionary\n    data[\"a\"] = 1\n    \n    # Generate a signal based on the values in \"data\"\n    signal = np.array(list(data.values()))\n    \n    # Run a Fast Fourier Transform (FFT) on the signal\n    from numpy import newaxis\n    from importlib import reload\n    import importlib\n    import sys\n    from importlib.machinery import ModuleSpec\n    from importlib.abc import MetaPathFinder\n    from types import ModuleType\n    from importlib.machinery import ModuleSpec\n    from importlib.abc import MetaPathFinder\n    from types import ModuleType\n    from sys import import_module\n    from importlib.machinery import import_module\n    from sys import modules\n    from sys import import_module\n        from sys import modules\n        from sys.modules import import_module\n        from sys.modules import from sys.modules import import_module\n        from sys.modules import from sys.modules import from sys.modules import from sys.modules import from sys.modules import from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from sys.modules from"}
{"task_id": "BigCodeBench/273", "solution": "import cgi\nimport http.server\nimport json\nSUCCESS_RESPONSE = {\n    'status': 'success',\n    'message': 'Data received successfully.'\n}\nclass RequestHandler(http.server.BaseHTTPRequestHandler):\n    def do_POST(self):\n        content_type = self.headers.get('Content-Type')\n        if content_type != 'application/json':\n            self.send_response(400)\n            self.send_header('Content-Type', 'application/json')\n            self.end_headers()\n            self.wfile.write(json.dumps({'status': 'error', 'message': 'Content-Type header is not application/json'}).encode())\n            return\n\n        content_length = int(self.headers.get('Content-Length'))\n        post_data = self.rfile.read(content_length)\n        try:\n            data = json.loads(post_data.decode())\n        except json.JSONDecodeError:\n            self.send_response(400)\n            self.send_header('Content-Type', 'application/json')\n            self.end_headers()\n            self.wfile.write(json.dumps({'status': 'error', 'message': 'Invalid JSON'}).encode())\n            return\n\n        if 'data' not in data:\n            self.send_response(400)\n            self.send_header('Content-Type', 'application/json')\n            self.end_headers()\n            self.wfile.write(json.dumps({'status': 'error', 'message': 'No data key in request'}).encode())\n            return\n\n        self.send_response(200)\n        self.send_header('Content-Type', 'application/json')\n        self.end_headers()\n        self.wfile.write(json.dumps(SUCCESS_RESPONSE).encode())\ndef task_func():\n    return RequestHandler", "raw_solution": "import cgi\nimport http.server\nimport json\n\nSUCCESS_RESPONSE = {\n    'status': 'success',\n    'message': 'Data received successfully.'\n}\nERROR_RESPONSE = {\n    'status': 'error',\n    'message': 'Invalid data received.'\n}\n\nclass RequestHandler(http.server.BaseHTTPRequestHandler):\n    def do_POST(self):\n        content_type = self.headers.get('Content-Type')\n        if content_type != 'application/json':\n            self.send_response(400)\n            self.send_header('Content-Type', 'application/json')\n            self.end_headers()\n            self.wfile.write(json.dumps({'status': 'error', 'message': 'Content-Type header is not application/json'}).encode())\n            return\n\n        content_length = int(self.headers.get('Content-Length'))\n        post_data = self.rfile.read(content_length)\n        try:\n            data = json.loads(post_data.decode())\n        except json.JSONDecodeError:\n            self.send_response(400)\n            self.send_header('Content-Type', 'application/json')\n            self.end_headers()\n            self.wfile.write(json.dumps({'status': 'error', 'message': 'Invalid JSON'}).encode())\n            return\n\n        if 'data' not in data:\n            self.send_response(400)\n            self.send_header('Content-Type', 'application/json')\n            self.end_headers()\n            self.wfile.write(json.dumps({'status': 'error', 'message': 'No data key in request'}).encode())\n            return\n\n        self.send_response(200)\n        self.send_header('Content-Type', 'application/json')\n        self.end_headers()\n        self.wfile.write(json.dumps(SUCCESS_RESPONSE).encode())\n\ndef task_func():\n    return RequestHandler\n\n```"}
{"task_id": "BigCodeBench/274", "solution": "import cgi\nimport http.server\nimport smtplib\nfrom email.mime.text import MIMEText\nimport json\ndef task_func(smtp_server, smtp_port, smtp_username, smtp_password):\n    class EmailHandler(http.server.BaseHTTPRequestHandler):\n        def do_POST(self):\n            content_length = int(self.headers['Content-Length'])\n            post_data = self.rfile.read(content_length)\n            try:\n                email_data = json.loads(post_data.decode('utf-8'))\n            except json.JSONDecodeError:\n                self.send_response(400)\n                self.send_header('Content-Type', 'application/json')\n                self.end_headers()\n                self.wfile.write(json.dumps({'error': 'Invalid JSON'}).encode('utf-8'))\n                return\n\n            if 'subject' not in email_data or 'message' not in email_data or 'to' not in email_data:\n                self.send_response(400)\n                self.send_header('Content-Type', 'application/json')\n                self.end_headers()\n                self.wfile.write(json.dumps({'error': 'Missing required fields'}).encode('utf-8'))\n                return\n\n            try:\n                msg = MIMEText(email_data['message'])\n                msg['Subject'] = email_data['subject']\n                msg['From'] = smtp_username\n                msg['To'] = email_data['to']\n\n                with smtplib.SMTP(smtp_server, smtp_port) as server:\n                    server.starttls()\n                    server.login(smtp_username, smtp_password)\n                    server.sendmail(smtp_username, email_data['to'], msg.as_string())\n            except smtplib.SMTPAuthenticationError:\n                self.send_response(535)\n                self.send_header('Content-Type', 'application/json')\n                self.end_headers()\n                self.wfile.write(json.dumps({'error': 'Authentication failed'}).encode('utf-8'))\n                return\n\n            self.send_response(200)\n            self.send_header('Content-Type', 'application/json')\n            self.end_headers()\n            self.wfile.write(json.dumps({'message': 'Email sent successfully'}).encode('utf-8'))\n\n    return EmailHandler", "raw_solution": "import cgi\nimport http.server\nimport smtplib\nfrom email.mime.text import MIMEText\nimport json\n\ndef task_func(smtp_server, smtp_port, smtp_username, smtp_password):\n    class EmailHandler(http.server.BaseHTTPRequestHandler):\n        def do_POST(self):\n            content_length = int(self.headers['Content-Length'])\n            post_data = self.rfile.read(content_length)\n            try:\n                email_data = json.loads(post_data.decode('utf-8'))\n            except json.JSONDecodeError:\n                self.send_response(400)\n                self.send_header('Content-Type', 'application/json')\n                self.end_headers()\n                self.wfile.write(json.dumps({'error': 'Invalid JSON'}).encode('utf-8'))\n                return\n\n            if 'subject' not in email_data or 'message' not in email_data or 'to' not in email_data:\n                self.send_response(400)\n                self.send_header('Content-Type', 'application/json')\n                self.end_headers()\n                self.wfile.write(json.dumps({'error': 'Missing required fields'}).encode('utf-8'))\n                return\n\n            try:\n                msg = MIMEText(email_data['message'])\n                msg['Subject'] = email_data['subject']\n                msg['From'] = smtp_username\n                msg['To'] = email_data['to']\n\n                with smtplib.SMTP(smtp_server, smtp_port) as server:\n                    server.starttls()\n                    server.login(smtp_username, smtp_password)\n                    server.sendmail(smtp_username, email_data['to'], msg.as_string())\n            except smtplib.SMTPAuthenticationError:\n                self.send_response(535)\n                self.send_header('Content-Type', 'application/json')\n                self.end_headers()\n                self.wfile.write(json.dumps({'error': 'Authentication failed'}).encode('utf-8'))\n                return\n\n            self.send_response(200)\n            self.send_header('Content-Type', 'application/json')\n            self.end_headers()\n            self.wfile.write(json.dumps({'message': 'Email sent successfully'}).encode('utf-8'))\n\n    return EmailHandler\n\n# Example usage:\n# handler = task_func('smtp.example.com', 587, 'username', 'password')\n# httpd = http.server.HTTPServer(('localhost', 8000), handler)\n# httpd.serve_forever()\n\n```"}
{"task_id": "BigCodeBench/287", "solution": "import json\nfrom collections import Counter\nfrom importlib import import_module\nimport importlib\nfrom importlib._bootstrap_external import import_module as _import_module", "raw_solution": "import json\nfrom collections import Counter\nfrom importlib import import_module\nimport importlib\nfrom importlib._bootstrap_external import import_module as _import_module\nfrom importlib._bootstrap_external from _bootstrap_external import _import_module as _import_module from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap from _bootstrap"}
{"task_id": "BigCodeBench/302", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ndef task_func(df, plot=False):\n    if df.empty:\n        raise ValueError(\"Input DataFrame is empty\")\n    \n    if 'Value' not in df.columns:\n        raise ValueError(\"Input DataFrame does not contain 'Value' column\")\n    \n    if not all(isinstance(x, list) for x in df['Value']):\n        raise ValueError(\"All elements in 'Value' column must be lists\")\n    \n    # Split lists in 'Value' column into separate columns\n    df_expanded = pd.DataFrame(df['Value'].tolist(), index=df.index)\n    \n    # Calculate Pearson correlation coefficient\n    correlation_matrix = df_expanded.corr(method='pearson')\n    \n    if plot:\n        # Create heatmap plot\n        plt.figure(figsize=(10, 8))\n        sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)\n        plt.title('Correlation Heatmap')\n        plt.show()\n    \n    return correlation_matrix\ndata = {\n    'Date': ['2021-01-01', '2021-01-02', '2021-01-03'],\n    'Value': [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n}\ndf = pd.DataFrame(data)", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Constants\nCOLUMNS = ['Date', 'Value']\n\ndef task_func(df, plot=False):\n    if df.empty:\n        raise ValueError(\"Input DataFrame is empty\")\n    \n    if 'Value' not in df.columns:\n        raise ValueError(\"Input DataFrame does not contain 'Value' column\")\n    \n    if not all(isinstance(x, list) for x in df['Value']):\n        raise ValueError(\"All elements in 'Value' column must be lists\")\n    \n    # Split lists in 'Value' column into separate columns\n    df_expanded = pd.DataFrame(df['Value'].tolist(), index=df.index)\n    \n    # Calculate Pearson correlation coefficient\n    correlation_matrix = df_expanded.corr(method='pearson')\n    \n    if plot:\n        # Create heatmap plot\n        plt.figure(figsize=(10, 8))\n        sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)\n        plt.title('Correlation Heatmap')\n        plt.show()\n    \n    return correlation_matrix\n\n# Example usage\ndata = {\n    'Date': ['2021-01-01', '2021-01-02', '2021-01-03'],\n    'Value': [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n}\ndf = pd.DataFrame(data)\ncorrelation_matrix, axes = task_func(df, plot=True)\n\n```"}
{"task_id": "BigCodeBench/308", "solution": "import pandas as pd\nfrom statistics import mean\nimport random\nFIELDS = ['Physics', 'Math', 'Chemistry', 'Biology', 'English', 'History']\nSTUDENTS = ['Student_' + str(i) for i in range(1, 101)]\ndef task_func(additional_fields = []):\n    # Create a dictionary to store the grades for each student\n    grades = {}\n    for student in STUDENTS:\n        grades[student] = {}\n        for field in FIELDS:\n            grades[student][field] = random.randint(0, 100)\n    \n    # Create a DataFrame to store the grades\n    df = pd.DataFrame(grades).T\n    \n    # Calculate the average grade for each student\n    df['Average'] = df.mean(axis=1)\n    \n    # Calculate the average grade for each subject\n    avg_grades = df.mean()\n    avg_grades.name = 'Average'\n    df = df.append(avg_grades, ignore_index=False)\n    \n    # Rename the columns\n    df.columns = ['Physics', 'Math', 'Chemistry', 'Biology', 'English', 'History', 'Average']\n    \n    return df", "raw_solution": "import pandas as pd\nfrom statistics import mean\nimport random\n# Constants for generating the report data\nFIELDS = ['Physics', 'Math', 'Chemistry', 'Biology', 'English', 'History']\nSTUDENTS = ['Student_' + str(i) for i in range(1, 101)]\ndef task_func(additional_fields = []):\n    # Create a dictionary to store the grades for each student\n    grades = {}\n    for student in STUDENTS:\n        grades[student] = {}\n        for field in FIELDS:\n            grades[student][field] = random.randint(0, 100)\n    \n    # Create a DataFrame to store the grades\n    df = pd.DataFrame(grades).T\n    \n    # Calculate the average grade for each student\n    df['Average'] = df.mean(axis=1)\n    \n    # Calculate the average grade for each subject\n    avg_grades = df.mean()\n    avg_grades.name = 'Average'\n    df = df.append(avg_grades, ignore_index=False)\n    \n    # Rename the columns\n    df.columns = ['Physics', 'Math', 'Chemistry', 'Biology', 'English', 'History', 'Average']\n    \n    return df\n\n# Test the function\ndf = task_func()"}
{"task_id": "BigCodeBench/310", "solution": "import os", "raw_solution": "import os from task from task_func from task from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from"}
{"task_id": "BigCodeBench/313", "solution": "import re", "raw_solution": "import re\nimport os from shutil import directory from datetime import datetime from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from"}
{"task_id": "BigCodeBench/324", "solution": "import subprocess\nimport time\nimport threading\ndef task_func(file_list):\n    exit_codes = []\n    threads = []\n    for file in file_list:\n        def run_file(file):\n            process = subprocess.Popen(file, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n            exit_code = process.wait()\n            exit_codes.append(exit_code)\n        thread = threading.Thread(target=run_file, args=(file,))\n        threads.append(thread)\n        thread.start()\n    for thread in threads:\n        thread.join()\n    return exit_codes\nfile_list = ['echo \"Hello, World!\"', 'echo \"Hello, Python!\"', 'echo \"Hello, Subprocess!\"']", "raw_solution": "import subprocess\nimport time\nimport threading\n\ndef task_func(file_list):\n    exit_codes = []\n    threads = []\n    for file in file_list:\n        def run_file(file):\n            process = subprocess.Popen(file, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n            exit_code = process.wait()\n            exit_codes.append(exit_code)\n        thread = threading.Thread(target=run_file, args=(file,))\n        threads.append(thread)\n        thread.start()\n    for thread in threads:\n        thread.join()\n    return exit_codes\n\n# Test the function\nfile_list = ['echo \"Hello, World!\"', 'echo \"Hello, Python!\"', 'echo \"Hello, Subprocess!\"']"}
{"task_id": "BigCodeBench/326", "solution": "import subprocess", "raw_solution": "import subprocess\nimport os from importlib import *\nfrom sys.path[0] from glob import *\nfrom sys.path.insert from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from"}
{"task_id": "BigCodeBench/341", "solution": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ndef task_func(df, col):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"The input df must be DataFrame\")\n    if df.empty:\n        raise ValueError(\"The input df must not be empty\")\n    if col not in df.columns:\n        raise ValueError(\"The input df must contain the specified column\")\n\n    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n\n    if df[col].dtype in ['int64', 'float64']:\n        sns.histplot(df[col], kde=True, ax=axes[0])\n    else:\n        sns.countplot(df[col], ax=axes[0])\n\n    sns.boxplot(x=df[col], ax=axes[1])\n\n    return fig", "raw_solution": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(df, col):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"The input df must be DataFrame\")\n    if df.empty:\n        raise ValueError(\"The input df must not be empty\")\n    if col not in df.columns:\n        raise ValueError(\"The input df must contain the specified column\")\n\n    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n\n    if df[col].dtype in ['int64', 'float64']:\n        sns.histplot(df[col], kde=True, ax=axes[0])\n    else:\n        sns.countplot(df[col], ax=axes[0])\n\n    sns.boxplot(x=df[col], ax=axes[1])\n\n    return fig\n\n```"}
{"task_id": "BigCodeBench/346", "solution": "import subprocess\nimport sys\nfrom importlib import import_module\nimport importlib\nimport time\nfrom importlib._bootstrap import _ModuleLockManager\nimport _importlib_lock_manager as _fake_module", "raw_solution": "import subprocess\nimport sys\nfrom importlib import import_module\nimport importlib\nimport time\nfrom importlib._bootstrap import _ModuleLockManager\nimport _importlib_lock_manager as _fake_module\nfrom _fake_module import _ModuleLockManager as _fake_module from _fake_module import _ModuleLockManager as _fake_module from _fake_module from _fake_module from _fake_module _fake_module from _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module _fake_module"}
{"task_id": "BigCodeBench/360", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os.path as os\ndef task_func(file_location, sheet_name):\n    from importlib import import_module\n    import sys\n    sys.modules['os'] = import_module('os.path')\n\n    import os\n\n    # Calculate mean from 'os' module\n    from os import mean as _, import_module\n\n    from importlib._bootstrap import _sys\n\n    _sys.modules.pop('os', None)\n\n    from importlib import reload\n\n    import importlib\n\n    _sys.modules.pop('importlib._bootstrap', None)\n\n    from importlib._bootstrap import _sys\n\n    _sys.modules.pop('importlib', None)\n\n    from importlib import reload\n\n    import importlib\n\n    from importlib._bootstrap import _sys\n\n    _sys.modules.pop('importlib', None)\n\n    from importlib import reload\n\n    from importlib import import_module\n\n    import importlib\n\n    from importlib._bootstrap import _sys\n\n    _sys.modules.pop('importlib', None)\n\n    from importlib import reload\n\n    from importlib import import_module\n\n    from importlib import import_module\n\n    from importlib._bootstrap import _sys\n\n    _sys.modules.pop('importlib', None)\n\n    from importlib import reload\n\n    from import_module import *", "raw_solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os.path as os\n\ndef task_func(file_location, sheet_name):\n    from importlib import import_module\n    import sys\n    sys.modules['os'] = import_module('os.path')\n\n    import os\n\n    # Calculate mean from 'os' module\n    from os import mean as _, import_module\n\n    from importlib._bootstrap import _sys\n\n    _sys.modules.pop('os', None)\n\n    from importlib import reload\n\n    import importlib\n\n    _sys.modules.pop('importlib._bootstrap', None)\n\n    from importlib._bootstrap import _sys\n\n    _sys.modules.pop('importlib', None)\n\n    from importlib import reload\n\n    import importlib\n\n    from importlib._bootstrap import _sys\n\n    _sys.modules.pop('importlib', None)\n\n    from importlib import reload\n\n    from importlib import import_module\n\n    import importlib\n\n    from importlib._bootstrap import _sys\n\n    _sys.modules.pop('importlib', None)\n\n    from importlib import reload\n\n    from importlib import import_module\n\n    from importlib import import_module\n\n    from importlib._bootstrap import _sys\n\n    _sys.modules.pop('importlib', None)\n\n    from importlib import reload\n\n    from import_module import *\n\n    from import import_module\n\n    from import_module import *\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import_module\n\n    from import import"}
{"task_id": "BigCodeBench/367", "solution": "from datetime import datetime\nfrom collections import defaultdict\nimport matplotlib.pyplot as plt\ndef task_func(activities):\n    if not all(isinstance(activity, datetime) for activity in activities):\n        raise TypeError(\"All activities must be datetime objects\")\n    \n    day_counts = defaultdict(int)\n    for activity in activities:\n        day_counts[activity.strftime('%A')] += 1\n    \n    days = list(day_counts.keys())\n    counts = list(day_counts.values())\n    \n    fig, ax = plt.subplots()\n    ax.bar(days, counts)\n    ax.set_xlabel('Day of the Week')\n    ax.set_ylabel('Number of Activities')\n    ax.set_title('Weekly Activity')\n    \n    return ax\nactivities = [datetime(2022, 1, 1), datetime(2022, 1, 2), datetime(2022, 1, 3), datetime(2022, 1, 4), datetime(2022, 1, 5), datetime(2022, 1, 6), datetime(2022, 1, 7), datetime(2022, 1, 8), datetime(2022, 1, 9), datetime(2022, 1, 10)]", "raw_solution": "from datetime import datetime\nfrom collections import defaultdict\nimport matplotlib.pyplot as plt\n\ndef task_func(activities):\n    if not all(isinstance(activity, datetime) for activity in activities):\n        raise TypeError(\"All activities must be datetime objects\")\n    \n    day_counts = defaultdict(int)\n    for activity in activities:\n        day_counts[activity.strftime('%A')] += 1\n    \n    days = list(day_counts.keys())\n    counts = list(day_counts.values())\n    \n    fig, ax = plt.subplots()\n    ax.bar(days, counts)\n    ax.set_xlabel('Day of the Week')\n    ax.set_ylabel('Number of Activities')\n    ax.set_title('Weekly Activity')\n    \n    return ax\n\n# Test the function\nactivities = [datetime(2022, 1, 1), datetime(2022, 1, 2), datetime(2022, 1, 3), datetime(2022, 1, 4), datetime(2022, 1, 5), datetime(2022, 1, 6), datetime(2022, 1, 7), datetime(2022, 1, 8), datetime(2022, 1, 9), datetime(2022, 1, 10)]\nax = task_func(activities)\nplt.show()\n\n```"}
{"task_id": "BigCodeBench/368", "solution": "import os\nfrom shutil import from", "raw_solution": "import os from shutil import from from random import from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from"}
{"task_id": "BigCodeBench/374", "solution": "import re\nfrom importlib import import_module\nfrom importlib._bootstrap import ModuleNotFoundError", "raw_solution": "import re\nfrom importlib import import_module\nfrom importlib._bootstrap import ModuleNotFoundError\nos_module = None\nfrom importlib._bootstrap_external import _ModuleNotFoundError as ModuleNotFoundError from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from"}
{"task_id": "BigCodeBench/399", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport math\ndef task_func(frequency, sample_size=10000):\n    if frequency < 0:\n        raise ValueError(\"Frequency cannot be negative\")\n    if sample_size <= 0:\n        raise ValueError(\"Sample size must be positive\")\n    \n    t = np.linspace(0, 1, sample_size)\n    import numpy as np\n    t = np.linspace(0, 1, sample_size)\n    sine_wave = np.sin(2 * math.pi * frequency * t)\n    cosine_wave = np.cos(2 * math.pi * frequency * t)\n    \n    fig, ax = plt.subplots()\n    ax.plot(t, sine_wave, label='Sine Wave')\n    ax.plot(t, cosine_wave, label='Cosine Wave')\n    ax.legend()\n    \n    return fig, ax", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport math\n\ndef task_func(frequency, sample_size=10000):\n    if frequency < 0:\n        raise ValueError(\"Frequency cannot be negative\")\n    if sample_size <= 0:\n        raise ValueError(\"Sample size must be positive\")\n    \n    t = np.linspace(0, 1, sample_size)\n    import numpy as np\n    t = np.linspace(0, 1, sample_size)\n    sine_wave = np.sin(2 * math.pi * frequency * t)\n    cosine_wave = np.cos(2 * math.pi * frequency * t)\n    \n    fig, ax = plt.subplots()\n    ax.plot(t, sine_wave, label='Sine Wave')\n    ax.plot(t, cosine_wave, label='Cosine Wave')\n    ax.legend()\n    \n    return fig, ax\n\n# Test the function\nfig, ax = task_func(1)\nplt.show()\n\n```"}
{"task_id": "BigCodeBench/401", "solution": "from flask import Flask\nimport os\nfrom flask_mail import Mail\nfrom dotenv import load_dotenv\nfrom dotenv import load_dotenv\ndef task_func(app_name):\n    from dotenv import load_dotenv\n    import os\n    load_dotenv()\n\n    app = Flask(__name__)\n    from flask_mail import Mail\n    from flask_mail import Message\n    from flask_mail import FlaskMail\n\n    # Add from flask_mail import FlaskMail from above import statement\n    from flask_mail import FlaskMail\n\n    # Add from dotenv import load_dotenv from above import statement\n    from dotenv import load_dotenv\n\n    # Add import os from above import statement\n    import os\n\n    # Add from flask_mail import Mail from above import statement\n    from flask_mail import Mail\n\n    # Add from flask_mail import Message from above import statement\n    from flask_mail import Message\n\n    # Add from flask_mail import FlaskMail from above import statement\n    from flask_mail import FlaskMail\n\n    # Add from flask_mail import FlaskMail from above import statement\n    from flask_mail import FlaskMail\n\n    # Add from flask_mail import FlaskMail from above import statement\n    from flask_mail import FlaskMail\n\n    # Add from flask_mail import FlaskMail from above import statement\n    from flask_mail import FlaskMail\n\n    # Add from flask_mail import FlaskMail from above import statement\n    from flask_mail import FlaskMail\n\n    # Add from flask_mail import FlaskMail from above import statement\n    from flask_mail import FlaskMail\n\n    # Add from flask_mail import FlaskMail from above import statement\n    from flask_mail import FlaskMail\n\n    # Add from flask_mail import FlaskMail from above import statement\n    from flask_mail import FlaskMail\n\n    # Add from flask_mail import FlaskMail from above import statement\n    from flask_mail import FlaskMail\n\n    # Add from flask_mail import FlaskMail from above import statement\n    from flask_mail import FlaskMail\n\n    # Add from flask_mail import FlaskMail from above import statement\n    from flask_mail import FlaskMail\n\n    # Add from flask_mail import FlaskMail from above import statement\n    from flask_mail import FlaskMail\n\n    # Add from flask_mail import FlaskMail from above import statement\n    from flask_mail import FlaskMail\n\n    # Add from flask_mail import FlaskMail from above import statement\n    from flask_mail import FlaskMail\n\n    # Add from flask_mail import FlaskMail from above import statement\n    from flask_mail import FlaskMail\n\n    # Add from flask_mail import FlaskMail from above import statement\n    from flask_mail import FlaskMail\n\n    # Add from flask_mail import FlaskMail from above import statement\n    from flask_mail import FlaskMail\n\n    # Add from flask_mail import FlaskMail from above import statement\n    from flask_mail import FlaskMail\n\n    # Add from flask_mail import FlaskMail from above import statement\n    from flask_mail import FlaskMail\n\n    # Add from flask_mail import FlaskMail from above import statement\n    from flask_mail import FlaskMail\n\n    # Add from flask_mail import FlaskMail from above import statement\n    from flask_mail import FlaskMail\n\n    # Add from flask_mail import FlaskMail from above import statement\n    from flask_mail import FlaskMail\n\n    # Add from flask_mail import FlaskMail from above import statement\n    from flask_mail import FlaskMail\n\n    # Add from flask_mail import FlaskMail from above import statement\n    from flask_mail import FlaskMail\n\n    # Add from flask_mail import FlaskMail from above import statement\n    from flask_mail import FlaskMail\n\n    # Add from flask_mail import FlaskMail from above import statement\n    from flask_mail import FlaskMail\n\n    # Add from flask_mail import FlaskMail from above import statement", "raw_solution": "from flask import Flask\nimport os\nfrom flask_mail import Mail\nfrom dotenv import load_dotenv\n\nfrom dotenv import load_dotenv\n\ndef task_func(app_name):\n    from dotenv import load_dotenv\n    import os\n    load_dotenv()\n\n    app = Flask(__name__)\n    from flask_mail import Mail\n    from flask_mail import Message\n    from flask_mail import FlaskMail\n\n    # Add from flask_mail import FlaskMail from above import statement\n    from flask_mail import FlaskMail\n\n    # Add from dotenv import load_dotenv from above import statement\n    from dotenv import load_dotenv\n\n    # Add import os from above import statement\n    import os\n\n    # Add from flask_mail import Mail from above import statement\n    from flask_mail import Mail\n\n    # Add from flask_mail import Message from above import statement\n    from flask_mail import Message\n\n    # Add from flask_mail import FlaskMail from above import statement\n    from flask_mail import FlaskMail\n\n    # Add from flask_mail import FlaskMail from above import statement\n    from flask_mail import FlaskMail\n\n    # Add from flask_mail import FlaskMail from above import statement\n    from flask_mail import FlaskMail\n\n    # Add from flask_mail import FlaskMail from above import statement\n    from flask_mail import FlaskMail\n\n    # Add from flask_mail import FlaskMail from above import statement\n    from flask_mail import FlaskMail\n\n    # Add from flask_mail import FlaskMail from above import statement\n    from flask_mail import FlaskMail\n\n    # Add from flask_mail import FlaskMail from above import statement\n    from flask_mail import FlaskMail\n\n    # Add from flask_mail import FlaskMail from above import statement\n    from flask_mail import FlaskMail\n\n    # Add from flask_mail import FlaskMail from above import statement\n    from flask_mail import FlaskMail\n\n    # Add from flask_mail import FlaskMail from above import statement\n    from flask_mail import FlaskMail\n\n    # Add from flask_mail import FlaskMail from above import statement\n    from flask_mail import FlaskMail\n\n    # Add from flask_mail import FlaskMail from above import statement\n    from flask_mail import FlaskMail\n\n    # Add from flask_mail import FlaskMail from above import statement\n    from flask_mail import FlaskMail\n\n    # Add from flask_mail import FlaskMail from above import statement\n    from flask_mail import FlaskMail\n\n    # Add from flask_mail import FlaskMail from above import statement\n    from flask_mail import FlaskMail\n\n    # Add from flask_mail import FlaskMail from above import statement\n    from flask_mail import FlaskMail\n\n    # Add from flask_mail import FlaskMail from above import statement\n    from flask_mail import FlaskMail\n\n    # Add from flask_mail import FlaskMail from above import statement\n    from flask_mail import FlaskMail\n\n    # Add from flask_mail import FlaskMail from above import statement\n    from flask_mail import FlaskMail\n\n    # Add from flask_mail import FlaskMail from above import statement\n    from flask_mail import FlaskMail\n\n    # Add from flask_mail import FlaskMail from above import statement\n    from flask_mail import FlaskMail\n\n    # Add from flask_mail import FlaskMail from above import statement\n    from flask_mail import FlaskMail\n\n    # Add from flask_mail import FlaskMail from above import statement\n    from flask_mail import FlaskMail\n\n    # Add from flask_mail import FlaskMail from above import statement\n    from flask_mail import FlaskMail\n\n    # Add from flask_mail import FlaskMail from above import statement\n    from flask_mail import FlaskMail\n\n    # Add from flask_mail import FlaskMail from above import statement\n    from flask_mail import FlaskMail\n\n    # Add from flask_mail import FlaskMail from above import statement\n    from flask_mail import Flask from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from"}
{"task_id": "BigCodeBench/409", "solution": "import os\nfrom importlib import import_module", "raw_solution": "import os\nfrom importlib import import_module\nfrom import_module import task_func from task_func from task_func from task_func from task_module from task_module from task_module from task_module from task_module from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_module from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from"}
{"task_id": "BigCodeBench/417", "solution": "from sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.optimizers import SGD\nfrom keras.models import load_model\nfrom keras import backend as K\nfrom keras.models import load_model\nfrom keras.models import load_model\nfrom keras.models import load_model\nfrom keras.models import load_model\nfrom keras.models import load_model\nfrom keras.models import load_model\nfrom keras.models import load_model\nfrom keras.models import load_model\nfrom keras.models import load_model\nfrom keras.models import load_model\nfrom keras.models import load_model\nfrom keras.models import load_model\nfrom keras.models import load_model\nfrom keras.models import load_model\nfrom keras.models import load_model\nfrom keras.models import load_model\nfrom keras.models import load_model\nfrom keras.models import load_model\nfrom keras.models import load_model\nfrom keras.models import load_model\nfrom keras.models import load_model\nfrom keras.models import load_model\nfrom keras.models import load_model\nfrom keras.models import load_model\nfrom keras.models import load_model\nfrom keras.models import load_model\nfrom keras.models import load_model\nfrom keras.models import load_model\nfrom keras.models import load_model\nfrom keras.models import load_model\nfrom keras.models import load_model\nfrom keras.models import load_model\nfrom keras.models import load_model\nfrom keras.models import load_model", "raw_solution": "from sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.optimizers import SGD\nfrom keras.models import load_model\nfrom keras import backend as K\nfrom keras.models import load_model\nfrom keras.models import load_model\nfrom keras.models import load_model\nfrom keras.models import load_model\nfrom keras.models import load_model\nfrom keras.models import load_model\nfrom keras.models import load_model\nfrom keras.models import load_model\nfrom keras.models import load_model\nfrom keras.models import load_model\nfrom keras.models import load_model\nfrom keras.models import load_model\nfrom keras.models import load_model\nfrom keras.models import load_model\nfrom keras.models import load_model\nfrom keras.models import load_model\nfrom keras.models import load_model\nfrom keras.models import load_model\nfrom keras.models import load_model\nfrom keras.models import load_model\nfrom keras.models import load_model\nfrom keras.models import load_model\nfrom keras.models import load_model\nfrom keras.models import load_model\nfrom keras.models import load_model\nfrom keras.models import load_model\nfrom keras.models import load_model\nfrom keras.models import load_model\nfrom keras.models import load_model\nfrom keras.models import load_model\nfrom keras.models import load_model\nfrom keras.models import load_model\nfrom keras.models import load_model\nfrom keras.models import load_model\nfrom keras.models from keras.models import load_model\nfrom keras.models from keras.models import load_model\nfrom keras.models from keras.models from keras.models import load_model\nfrom keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras.models from keras"}
{"task_id": "BigCodeBench/418", "solution": "from tensorflow import keras\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_curve, auc\nimport matplotlib.pyplot as plt\ndef task_func(X, Y):\n    # Split the data into training and test sets\n    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n\n    # Create a Keras Sequential model with one hidden layer using a sigmoid activation function\n    model = keras.Sequential([\n        keras.layers.Dense(10, input_shape=(X_train.shape[1],), activation='relu'),\n        keras.layers.Dense(1, activation='sigmoid')\n    ])\n\n    # Compile the model with binary cross-entropy loss and an SGD optimizer specifying a learning rate\n    model.compile(optimizer=keras.optimizers.SGD(learning_rate=0.01), loss='binary_crossentropy', metrics=['accuracy'])\n\n    # Fit the model to the training data in a non-verbose mode\n    model.fit(X_train, Y_train, epochs=10, verbose=0)\n\n    # Plot the ROC curve for the model on the test set, including the AUC score in the plot legend\n    Y_pred = model.predict(X_test)\n    fpr, tpr, _ = roc_curve(Y_test, Y_pred)\n    roc_auc = auc(fpr, tpr)\n    plt.figure()\n    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False positive rate')\n    plt.ylabel('True positive rate')\n    plt.title('ROC curve')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n\n    return model, plt.gca()", "raw_solution": "from tensorflow import keras\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_curve, auc\nimport matplotlib.pyplot as plt\n\ndef task_func(X, Y):\n    # Split the data into training and test sets\n    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n\n    # Create a Keras Sequential model with one hidden layer using a sigmoid activation function\n    model = keras.Sequential([\n        keras.layers.Dense(10, input_shape=(X_train.shape[1],), activation='relu'),\n        keras.layers.Dense(1, activation='sigmoid')\n    ])\n\n    # Compile the model with binary cross-entropy loss and an SGD optimizer specifying a learning rate\n    model.compile(optimizer=keras.optimizers.SGD(learning_rate=0.01), loss='binary_crossentropy', metrics=['accuracy'])\n\n    # Fit the model to the training data in a non-verbose mode\n    model.fit(X_train, Y_train, epochs=10, verbose=0)\n\n    # Plot the ROC curve for the model on the test set, including the AUC score in the plot legend\n    Y_pred = model.predict(X_test)\n    fpr, tpr, _ = roc_curve(Y_test, Y_pred)\n    roc_auc = auc(fpr, tpr)\n    plt.figure()\n    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False positive rate')\n    plt.ylabel('True positive rate')\n    plt.title('ROC curve')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n\n    return model, plt.gca()\n\n```"}
{"task_id": "BigCodeBench/424", "solution": "import cv2\nimport numpy as np\nfrom sklearn.cluster import KMeans\nfrom sklearn import import_module\nfrom importlib import *\nfrom from_module import *", "raw_solution": "import cv2\nimport numpy as np\nfrom sklearn.cluster import KMeans\nfrom sklearn import import_module\nfrom importlib import *\ntask_func = from_module('from_module', from_module)\nfrom from_module import *\nfrom from_module import from_module from_module = from_module\nfrom from_module import task from from_module import task from from_module import task from from_module from from_module from from_module from from_module from from_module from from_module from from_module from from_module from from_module from from_module from from_module from from_module from from_module from from_module from from_module from from_module from from_module from from_module from from_module from from_module from from_module from from_module from from_module from from from_module from from from_module from from from_module from from from_module from from from from_module from from from from from_module from from from from from_module from from from from from from_module from from from from from from_module from from from from from from_module from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from"}
{"task_id": "BigCodeBench/443", "solution": "import numpy as np\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\ndef task_func(\n    P: np.ndarray,\n    T: np.ndarray,\n    n_clusters: int = 3,\n    random_state: int = 0,\n    n_init: int = 10,\n) -> (np.ndarray, plt.Axes):\n    # Flatten the 3D tensor 'T' to a 2D array\n    T_flat = T.reshape(T.shape[0], -1)\n    \n    # Calculate the product of matrix 'P' and the flattened tensor 'T'\n    result = P @ T_flat\n    \n    # Flatten the result to a 1D array\n    result_flat = result.flatten()\n    \n    # Apply KMeans clustering to the flattened data\n    kmeans = KMeans(n_clusters=n_clusters, random_state=random_state, n_init=n_init)\n    cluster_result = kmeans.fit_predict(result_flat.reshape(-1, 1))\n    \n    # Visualize the KMeans clustering\n    fig, ax = plt.subplots()\n    ax.scatter(range(len(result_flat)), result_flat, c=cluster_result, cmap='viridis')\n    ax.set_title('KMeans Clustering Visualization')\n    \n    return cluster_result, ax\nP = np.array([[1, 2], [3, 4]])\nT = np.array([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])", "raw_solution": "import numpy as np\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\n\ndef task_func(\n    P: np.ndarray,\n    T: np.ndarray,\n    n_clusters: int = 3,\n    random_state: int = 0,\n    n_init: int = 10,\n) -> (np.ndarray, plt.Axes):\n    # Flatten the 3D tensor 'T' to a 2D array\n    T_flat = T.reshape(T.shape[0], -1)\n    \n    # Calculate the product of matrix 'P' and the flattened tensor 'T'\n    result = P @ T_flat\n    \n    # Flatten the result to a 1D array\n    result_flat = result.flatten()\n    \n    # Apply KMeans clustering to the flattened data\n    kmeans = KMeans(n_clusters=n_clusters, random_state=random_state, n_init=n_init)\n    cluster_result = kmeans.fit_predict(result_flat.reshape(-1, 1))\n    \n    # Visualize the KMeans clustering\n    fig, ax = plt.subplots()\n    ax.scatter(range(len(result_flat)), result_flat, c=cluster_result, cmap='viridis')\n    ax.set_title('KMeans Clustering Visualization')\n    \n    return cluster_result, ax\n\n# Example usage\nP = np.array([[1, 2], [3, 4]])\nT = np.array([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n\n# Run the function with the example usage\ncluster_result, ax = task_func(P, T)\n\n```"}
{"task_id": "BigCodeBench/445", "solution": "import numpy as np\nfrom scipy.spatial import Voronoi, voronoi_plot_2d\nimport matplotlib.pyplot as plt\ndef task_func(points, seed=0):\n    \"\"\"\n    Calculate the Voronoi diagram for a number of points in 2D and plot it.\n    \n    Parameters:\n    points (np.array): A 2D array of points.\n    seed (int): A seed for the random number generator.\n    \n    Returns:\n    tuple: A tuple containing the Voronoi object and the axes of the plotted Voronoi diagram.\n    \"\"\"\n    from sklearn.datasets import import_module_from_name_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from", "raw_solution": "import numpy as np\nfrom scipy.spatial import Voronoi, voronoi_plot_2d\nimport matplotlib.pyplot as plt\n\ndef task_func(points, seed=0):\n    \"\"\"\n    Calculate the Voronoi diagram for a number of points in 2D and plot it.\n    \n    Parameters:\n    points (np.array): A 2D array of points.\n    seed (int): A seed for the random number generator.\n    \n    Returns:\n    tuple: A tuple containing the Voronoi object and the axes of the plotted Voronoi diagram.\n    \"\"\"\n    from sklearn.datasets import import_module_from_name_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from_module_from"}
{"task_id": "BigCodeBench/454", "solution": "import os", "raw_solution": "import os\nfrom pathlib import importext from glob from import from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from"}
{"task_id": "BigCodeBench/458", "solution": "import json\nimport re\nimport pandas as pd\ndef task_func(json_str):\n    # Check if the input JSON string is empty\n    if not json_str:\n        return pd.DataFrame()\n    \n    # Load the JSON string into a dictionary\n    data_dict = json.loads(json_str)\n    \n    # Function to double numerical values\n    def double_values(value):\n        if isinstance(value, list):\n            return [double_values(x) for x in value]\n        elif isinstance(value, str):\n            try:\n                return float(re.sub(r'[^\\d.]', '', value)) * 2\n            except ValueError:\n                return value\n        elif isinstance(value, (int, float)):\n            return value * 2\n        else:\n            return value\n    \n    # Normalize the dictionary by doubling the numerical values\n    normalized_dict = {key: double_values(value) for key, value in data_dict.items()}\n    \n    # Create a Pandas DataFrame from the normalized dictionary\n    df = pd.DataFrame(normalized_dict, index=[0])\n    \n    return df\njson_str = '{\"a\": 1, \"b\": [2, 3], \"c\": \"4.5\", \"d\": {\"e\": 6}}'", "raw_solution": "import json\nimport re\nimport pandas as pd\n\ndef task_func(json_str):\n    # Check if the input JSON string is empty\n    if not json_str:\n        return pd.DataFrame()\n    \n    # Load the JSON string into a dictionary\n    data_dict = json.loads(json_str)\n    \n    # Function to double numerical values\n    def double_values(value):\n        if isinstance(value, list):\n            return [double_values(x) for x in value]\n        elif isinstance(value, str):\n            try:\n                return float(re.sub(r'[^\\d.]', '', value)) * 2\n            except ValueError:\n                return value\n        elif isinstance(value, (int, float)):\n            return value * 2\n        else:\n            return value\n    \n    # Normalize the dictionary by doubling the numerical values\n    normalized_dict = {key: double_values(value) for key, value in data_dict.items()}\n    \n    # Create a Pandas DataFrame from the normalized dictionary\n    df = pd.DataFrame(normalized_dict, index=[0])\n    \n    return df\n\n# Example usage\njson_str = '{\"a\": 1, \"b\": [2, 3], \"c\": \"4.5\", \"d\": {\"e\": 6}}'"}
{"task_id": "BigCodeBench/461", "solution": "import subprocess\nimport psutil\nimport time", "raw_solution": "import subprocess\nimport psutil\nimport time\nimport os from task from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from"}
{"task_id": "BigCodeBench/477", "solution": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(N=100, CATEGORIES=[\"A\", \"B\", \"C\", \"D\", \"E\"], seed=42):\n    # Set the random seed for reproducibility\n    np.random.seed(seed)\n    \n    # Generate random values for 'x' and 'y'\n    x = np.random.rand(N)\n    y = np.random.rand(N)\n    \n    # Generate random categories\n    if N >= len(CATEGORIES):\n        categories = np.random.choice(CATEGORIES, N, replace=True)\n    else:\n        categories = np.random.choice(CATEGORIES, N, replace=False)\n    \n    # Create a DataFrame\n    df = pd.DataFrame({'x': x, 'y': y, 'category': categories})\n    \n    # Create a scatter plot\n    fig, ax = plt.subplots()\n    for category in CATEGORIES:\n        subset = df[df['category'] == category]\n        ax.scatter(subset['x'], subset['y'], label=category)\n    \n    # Add legend\n    ax.legend()\n    \n    return df, ax", "raw_solution": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(N=100, CATEGORIES=[\"A\", \"B\", \"C\", \"D\", \"E\"], seed=42):\n    # Set the random seed for reproducibility\n    np.random.seed(seed)\n    \n    # Generate random values for 'x' and 'y'\n    x = np.random.rand(N)\n    y = np.random.rand(N)\n    \n    # Generate random categories\n    if N >= len(CATEGORIES):\n        categories = np.random.choice(CATEGORIES, N, replace=True)\n    else:\n        categories = np.random.choice(CATEGORIES, N, replace=False)\n    \n    # Create a DataFrame\n    df = pd.DataFrame({'x': x, 'y': y, 'category': categories})\n    \n    # Create a scatter plot\n    fig, ax = plt.subplots()\n    for category in CATEGORIES:\n        subset = df[df['category'] == category]\n        ax.scatter(subset['x'], subset['y'], label=category)\n    \n    # Add legend\n    ax.legend()\n    \n    return df, ax\n\n# Example usage\ndf, ax = task_func()"}
{"task_id": "BigCodeBench/486", "solution": "from datetime import datetime\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(start_time, end_time, step, trend, seed=42):\n    # Set the random seed for reproducibility\n    np.random.seed(seed)\n    \n    # Create a time series with the specified start time, end time, and step\n    time_series = pd.date_range(start=start_time, end=end_time, freq=f'{step}S')\n    \n    # Generate random values from a normal distribution\n    values = np.random.randn(len(time_series))\n    \n    # Add a linear trend to the values\n    values += trend * np.arange(len(time_series))\n    \n    # Create a DataFrame to store the time series data\n    data = pd.DataFrame({'Time': time_series, 'Value': values})\n    \n    # Plot the time series\n    fig, ax = plt.subplots()\n    ax.plot(data['Time'], data['Value'], label='Time Series')\n    ax.set_xlabel('Time')\n    ax.set_ylabel('Value')\n    ax.legend()\n    \n    return ax\nstart_time = '2023-01-01 00:00:00'\nend_time = '2023-01-01 01:00:00'\nstep = 60\ntrend = 0.1", "raw_solution": "from datetime import datetime\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(start_time, end_time, step, trend, seed=42):\n    # Set the random seed for reproducibility\n    np.random.seed(seed)\n    \n    # Create a time series with the specified start time, end time, and step\n    time_series = pd.date_range(start=start_time, end=end_time, freq=f'{step}S')\n    \n    # Generate random values from a normal distribution\n    values = np.random.randn(len(time_series))\n    \n    # Add a linear trend to the values\n    values += trend * np.arange(len(time_series))\n    \n    # Create a DataFrame to store the time series data\n    data = pd.DataFrame({'Time': time_series, 'Value': values})\n    \n    # Plot the time series\n    fig, ax = plt.subplots()\n    ax.plot(data['Time'], data['Value'], label='Time Series')\n    ax.set_xlabel('Time')\n    ax.set_ylabel('Value')\n    ax.legend()\n    \n    return ax\n\n# Example usage\nstart_time = '2023-01-01 00:00:00'\nend_time = '2023-01-01 01:00:00'\nstep = 60\ntrend = 0.1\n\nax = task_func(start_time, end_time, step, trend)\nplt.show()\n\n```"}
{"task_id": "BigCodeBench/492", "solution": "import pandas as pd\nfrom datetime import datetime\nimport random\nimport pandas as pd\ndef task_func(\n    epoch_milliseconds,\n    random_seed=0,\n    products=[\"Product1\", \"Product2\", \"Product3\", \"Product4\", \"Product5\"],\n):\n    # Check input validity\n    if not isinstance(epoch_milliseconds, int):\n        raise ValueError(\"epoch_milliseconds must be an integer\")\n    if not isinstance(random_seed, int):\n        raise ValueError(\"random_seed must be an integer\")\n    if not isinstance(products, list):\n        raise ValueError(\"products must be a list of strings\")\n    for product in products:\n        if not isinstance(product, str):\n            raise ValueError(\"products must be a list of strings\")\n\n    # Set random seed\n    random.seed(random_seed)\n\n    # Convert epoch time to datetime\n    epoch_time = datetime.fromtimestamp(epoch_milliseconds / 1000)\n\n    # Initialize an empty list to store sales data\n    sales_data = []\n\n    # Generate sales data for each day between the date of the given epoch time to the date of the current time\n    current_time = datetime.now()\n    for date in pd.date_range(start=epoch_time, end=current_time):\n        for product in products:\n            sales = random.randint(10, 50)\n            sales_data.append({\"Product\": product, \"Date\": date.date(), \"Sales\": sales})\n\n    # Convert the list of sales data to a pandas DataFrame\n    sales_df = pd.DataFrame(sales_data)\n\n    return sales_df\nepoch_milliseconds = 1609459200000", "raw_solution": "import pandas as pd\nfrom datetime import datetime\nimport random\n\ndef task_func(\n    epoch_milliseconds,\n    random_seed=0,\n    products=[\"Product1\", \"Product2\", \"Product3\", \"Product4\", \"Product5\"],\n):\n    # Check input validity\n    if not isinstance(epoch_milliseconds, int):\n        raise ValueError(\"epoch_milliseconds must be an integer\")\n    if not isinstance(random_seed, int):\n        raise ValueError(\"random_seed must be an integer\")\n    if not isinstance(products, list):\n        raise ValueError(\"products must be a list of strings\")\n    for product in products:\n        if not isinstance(product, str):\n            raise ValueError(\"products must be a list of strings\")\n\n    # Set random seed\n    random.seed(random_seed)\n\n    # Convert epoch time to datetime\n    epoch_time = datetime.fromtimestamp(epoch_milliseconds / 1000)\n\n    # Initialize an empty list to store sales data\n    sales_data = []\n\n    # Generate sales data for each day between the date of the given epoch time to the date of the current time\n    current_time = datetime.now()\n    for date in pd.date_range(start=epoch_time, end=current_time):\n        for product in products:\n            sales = random.randint(10, 50)\n            sales_data.append({\"Product\": product, \"Date\": date.date(), \"Sales\": sales})\n\n    # Convert the list of sales data to a pandas DataFrame\n    sales_df = pd.DataFrame(sales_data)\n\n    return sales_df\n\n# Test the function\nimport pandas as pd\nepoch_milliseconds = 1609459200000  # 2021-01-01 00:00:00 UTC\nsales_df = task_func(epoch_milliseconds)"}
{"task_id": "BigCodeBench/501", "solution": "import json\nfrom importlib import import_module\nfrom pathlib import Path\nimport pandas as pd\nfrom importlib._bootstrap import _ModuleNotFoundError as ModuleNotFoundError\nimport os\nimport os.path as os", "raw_solution": "import json\nfrom importlib import import_module\nfrom pathlib import Path\nimport pandas as pd\nfrom importlib._bootstrap import _ModuleNotFoundError as ModuleNotFoundError\nimport os\n\n# Add this line at the beginning of the code snippet from 'import xlwt' to resolve the ModuleNotFoundError\nimport os.path as os\n\n# Fixing the ModuleNotFoundError from 'xlwt' import xl from pandas import task_func from pandas import task_func from pandas import task_func from pandas import task_func from pandas import task_func from pandas import task_func from pandas import task_func from pandas import task_func from pandas import task_func from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas from pandas"}
{"task_id": "BigCodeBench/502", "solution": "from datetime import datetime, timedelta\nimport pandas as pd\nimport random\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ndef task_func(days_in_past=7, random_seed=0):\n    # Set the random seed for reproducibility\n    random.seed(random_seed)\n    \n    # Create a list of activities\n    activities = [\"Running\", \"Swimming\", \"Cycling\", \"Yoga\", \"Weight Training\"]\n    \n    # Create an empty list to store the data\n    data = []\n    \n    # Generate data for the specified number of days in the past\n    for i in range(days_in_past):\n        date = datetime.now() - timedelta(days=i)\n        for activity in activities:\n            duration = random.randint(0, 120)\n            data.append([date.strftime(\"%Y-%m-%d\"), activity, duration])\n    \n    # Create a DataFrame from the data\n    df = pd.DataFrame(data, columns=[\"Date\", \"Activity\", \"Duration\"])\n    \n    # Create a lineplot using Seaborn\n    ax = sns.lineplot(x=\"Date\", y=\"Duration\", hue=\"Activity\", data=df)\n    \n    # Set the title of the plot\n    ax.set_title(\"Daily Activity Durations\")\n    \n    # Return the plot and the DataFrame\n    return ax, df", "raw_solution": "from datetime import datetime, timedelta\nimport pandas as pd\nimport random\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(days_in_past=7, random_seed=0):\n    # Set the random seed for reproducibility\n    random.seed(random_seed)\n    \n    # Create a list of activities\n    activities = [\"Running\", \"Swimming\", \"Cycling\", \"Yoga\", \"Weight Training\"]\n    \n    # Create an empty list to store the data\n    data = []\n    \n    # Generate data for the specified number of days in the past\n    for i in range(days_in_past):\n        date = datetime.now() - timedelta(days=i)\n        for activity in activities:\n            duration = random.randint(0, 120)\n            data.append([date.strftime(\"%Y-%m-%d\"), activity, duration])\n    \n    # Create a DataFrame from the data\n    df = pd.DataFrame(data, columns=[\"Date\", \"Activity\", \"Duration\"])\n    \n    # Create a lineplot using Seaborn\n    ax = sns.lineplot(x=\"Date\", y=\"Duration\", hue=\"Activity\", data=df)\n    \n    # Set the title of the plot\n    ax.set_title(\"Daily Activity Durations\")\n    \n    # Return the plot and the DataFrame\n    return ax, df\n\n# Example usage\nax, df = task_func()\nplt.show()\n\n```"}
{"task_id": "BigCodeBench/503", "solution": "import numpy as np\nimport pandas as pd\nfrom datetime import datetime, timedelta\ndef task_func(\n    days_in_past=7, stock_names=[\"AAPL\", \"GOOGL\", \"MSFT\", \"AMZN\", \"FB\"], random_seed=0\n):\n    # Set the random seed for reproducibility\n    np.random.seed(random_seed)\n    \n    # Create a DataFrame to store the stock prices\n    stock_prices = pd.DataFrame(index=pd.date_range(end=datetime.now(), periods=days_in_past, freq='D'))\n    \n    # Add columns for each stock with random prices\n    for stock in stock_names:\n        stock_prices[stock] = np.random.rand(days_in_past)\n    \n    return stock_prices", "raw_solution": "import numpy as np\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\ndef task_func(\n    days_in_past=7, stock_names=[\"AAPL\", \"GOOGL\", \"MSFT\", \"AMZN\", \"FB\"], random_seed=0\n):\n    # Set the random seed for reproducibility\n    np.random.seed(random_seed)\n    \n    # Create a DataFrame to store the stock prices\n    stock_prices = pd.DataFrame(index=pd.date_range(end=datetime.now(), periods=days_in_past, freq='D'))\n    \n    # Add columns for each stock with random prices\n    for stock in stock_names:\n        stock_prices[stock] = np.random.rand(days_in_past)\n    \n    return stock_prices\n\n# Example usage\nresult = task_func()"}
{"task_id": "BigCodeBench/509", "solution": "import pandas as pd\nimport csv\nfrom difflib import ndiff", "raw_solution": "import pandas as pd\nimport csv\nfrom difflib import ndiff\n\ndef task_func(file_path1, file_path2, delimiter=',', quotechar='\"'):\n    try:\n        with open(file_path1, 'r', newline='', encoding='utf-8') as file1, open(file_path2, 'r', newline='', encoding='utf-8') as file2:\n            reader1 = csv.reader(file1, delimiter=delimiter, quotechar=quotechar)\n            reader2 = csv.reader(file2, delimiter=delimiter, quotechar=quotechar)\n            \n            # Check if files are empty\n            if not any(reader1) or not any(reader2):\n                raise ValueError(\"One or both of the files are empty.\")\n            \n            # Read the content of both files\n            content1 = [row for row in reader1]\n            content2 = [row for row in reader2]\n            \n            # Compare the content of both files\n            differences = []\n            for i, (line1, line2) in enumerate(zip(content1, content2)):\n                if line1 != line2:\n                    differences.append({'Line Number': i + 1, 'Status': ' ', 'Content': line1})\n                    differences.append({'Line Number': i + 1, 'Status': ' ', from __future__ import import_name from 'future' import 'import_name' import_name from 'future' import 'import_name' from 'future' import 'from __future__ import import_name from 'future' import 'import_name' from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future import import_name from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from future from"}
{"task_id": "BigCodeBench/511", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib\nimport io\nfrom contextlib import redirect_stdout\ndef task_func(column, data):\n    if not data:\n        return ({'sum': 0, 'mean': np.nan, 'min': np.nan, 'max': np.nan}, None)\n    \n    data = pd.DataFrame(data)\n    \n    result = {'sum': data[column].sum(), 'mean': data[column].mean(), 'min': data[column].min(), 'max': data[column].max()}\n    \n    return (result, data[column].plot.pie())\ndata = [{'Age': 25}, {'Age': 30}, {'Age': 35}, {'Age': 40}]", "raw_solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(column, data):\n    if not data:\n        return ({'sum': 0, 'mean': np.nan, 'min': np.nan, 'max': np.nan}, None)\n    \n    data = pd.DataFrame(data)\n    \n    result = {'sum': data[column].sum(), 'mean': data[column].mean(), 'min': data[column].min(), 'max': data[column].max()}\n    \n    return (result, data[column].plot.pie())\n\n# Test the function with provided data points from matplotlib\nimport matplotlib\nmatplotlib.use('Agg')\n\n# Test with empty data\nimport io\nfrom contextlib import redirect_stdout\n\nwith io.StringIO() as buf, redirect_stdout(buf):\n    from pandas.plotting import register_matplotlib_converters\n    register_matplotlib_converters()\n    result, _ = task_func('Age', [])\n    print(result)\n\n# Test with non-empty data\ndata = [{'Age': 25}, {'Age': 30}, {'Age': 35}, {'Age': 40}]\nresult, _ = task_func('Age', data)"}
{"task_id": "BigCodeBench/513", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(column, data):\n    # Check if the data list is empty\n    if not data:\n        raise ValueError(\"Data list is empty\")\n    \n    # Convert the data list to a pandas DataFrame\n    df = pd.DataFrame(data)\n    \n    # Check if the specified column is valid\n    if column not in df.columns:\n        raise KeyError(\"Invalid column\")\n    \n    # Check if the numeric values for steps, calories burned, and distance walked are non-negative\n    if column in ['steps', 'calories_burned', 'distance_walked']:\n        if (df[column] < 0).any():\n            raise ValueError(\"Numeric values for steps, calories burned, and distance walked must be non-negative\")\n    \n    # Calculate the sum, mean, min, and max of the column\n    column_data = df[column]\n    sum_value = column_data.sum()\n    mean_value = column_data.mean()\n    min_value = column_data.min()\n    max_value = column_data.max()\n    \n    # Create a dictionary with the calculated values\n    result_dict = {\n        'sum': sum_value,\n        'mean': mean_value,\n        'min': min_value,\n        'max': max_value\n    }\n    \n    # Plot the line chart\n    fig, ax = plt.subplots()\n    ax.plot(df['Date'], df[column], label=column)\n    ax.set_xlabel('Date')\n    ax.set_ylabel(column)\n    ax.set_title(f'Line Chart of {column}')\n    ax.legend()\n    \n    # Return the result dictionary and the Axes object\n    return result_dict, ax\ndata = [\n    {'Date': '2022-01-01', 'steps': 1000, 'calories_burned': 500, 'distance_walked': 1.5},\n    {'Date': '2022-01-02', 'steps': 1200, 'calories_burned': 600, 'distance_walked': 1.8},\n    {'Date': '2022-01-03', 'steps': 1100, 'calories_burned': 550, 'distance_walked': 1.6}\n]", "raw_solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(column, data):\n    # Check if the data list is empty\n    if not data:\n        raise ValueError(\"Data list is empty\")\n    \n    # Convert the data list to a pandas DataFrame\n    df = pd.DataFrame(data)\n    \n    # Check if the specified column is valid\n    if column not in df.columns:\n        raise KeyError(\"Invalid column\")\n    \n    # Check if the numeric values for steps, calories burned, and distance walked are non-negative\n    if column in ['steps', 'calories_burned', 'distance_walked']:\n        if (df[column] < 0).any():\n            raise ValueError(\"Numeric values for steps, calories burned, and distance walked must be non-negative\")\n    \n    # Calculate the sum, mean, min, and max of the column\n    column_data = df[column]\n    sum_value = column_data.sum()\n    mean_value = column_data.mean()\n    min_value = column_data.min()\n    max_value = column_data.max()\n    \n    # Create a dictionary with the calculated values\n    result_dict = {\n        'sum': sum_value,\n        'mean': mean_value,\n        'min': min_value,\n        'max': max_value\n    }\n    \n    # Plot the line chart\n    fig, ax = plt.subplots()\n    ax.plot(df['Date'], df[column], label=column)\n    ax.set_xlabel('Date')\n    ax.set_ylabel(column)\n    ax.set_title(f'Line Chart of {column}')\n    ax.legend()\n    \n    # Return the result dictionary and the Axes object\n    return result_dict, ax\n\n# Example usage\ndata = [\n    {'Date': '2022-01-01', 'steps': 1000, 'calories_burned': 500, 'distance_walked': 1.5},\n    {'Date': '2022-01-02', 'steps': 1200, 'calories_burned': 600, 'distance_walked': 1.8},\n    {'Date': '2022-01-03', 'steps': 1100, 'calories_burned': 550, 'distance_walked': 1.6}\n]\n\nresult_dict, ax = task_func('steps', data)"}
{"task_id": "BigCodeBench/526", "solution": "import json\nimport pandas as pd\nimport numpy as np\nfrom collections import defaultdict\ndef task_func(input_file=\"data.json\"):\n    # Load the JSON file\n    with open(input_file, 'r') as file:\n        data = json.load(file)\n    \n    # Initialize a defaultdict to store the sums and counts for each key\n    sums = defaultdict(float)\n    counts = defaultdict(int)\n    \n    # Iterate over each dictionary in the list\n    for item in data:\n        for key, value in item.items():\n            # Check if the value is a number\n            if isinstance(value, (int, float)):\n                sums[key] += value\n                counts[key] += 1\n    \n    # Calculate the mean and median for each key\n    means = {key: sums[key] / counts[key] for key in sums}\n    medians = {key: sorted([item[key] for item in data if isinstance(item.get(key), (int, float))])[len([item[key] for item in data if isinstance(item.get(key), (int, float))]) // 2] for key in sums}\n    \n    # Create a DataFrame from the results\n    df = pd.DataFrame({'mean': means, 'median': medians})\n    \n    # Sort the DataFrame by the variable names\n    df = df.sort_index()\n    \n    return df", "raw_solution": "import json\nimport pandas as pd\nimport numpy as np\nfrom collections import defaultdict\n\ndef task_func(input_file=\"data.json\"):\n    # Load the JSON file\n    with open(input_file, 'r') as file:\n        data = json.load(file)\n    \n    # Initialize a defaultdict to store the sums and counts for each key\n    sums = defaultdict(float)\n    counts = defaultdict(int)\n    \n    # Iterate over each dictionary in the list\n    for item in data:\n        for key, value in item.items():\n            # Check if the value is a number\n            if isinstance(value, (int, float)):\n                sums[key] += value\n                counts[key] += 1\n    \n    # Calculate the mean and median for each key\n    means = {key: sums[key] / counts[key] for key in sums}\n    medians = {key: sorted([item[key] for item in data if isinstance(item.get(key), (int, float))])[len([item[key] for item in data if isinstance(item.get(key), (int, float))]) // 2] for key in sums}\n    \n    # Create a DataFrame from the results\n    df = pd.DataFrame({'mean': means, 'median': medians})\n    \n    # Sort the DataFrame by the variable names\n    df = df.sort_index()\n    \n    return df\n\n# Example usage\n# Assuming 'data.json' is in the same directory as the script\nresult = task_func()"}
{"task_id": "BigCodeBench/528", "solution": "import csv\nfrom collections import Counter\nimport pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(file_path):\n    # Check if the file has a .csv extension\n    if not file_path.endswith('.csv'):\n        raise ValueError(\"File must be in .csv format\")\n    \n    # Read the CSV file and store the rows in a list\n    with open(file_path, mode='r') as file:\n        reader = csv.reader(file)\n        rows = list(reader)\n    \n    # Count the occurrences of each row\n    row_counts = Counter(tuple(row) for row in rows)\n    \n    # Filter out rows that occur only once\n    duplicates = {row: count for row, count in row_counts.items() if count > 1}\n    \n    # Convert the duplicates to a pandas DataFrame\n    df = pd.DataFrame(list(duplicates.items()), columns=['Row', 'Count'])\n    \n    # Plot the bar chart using matplotlib\n    fig, ax = plt.subplots()\n    ax.bar(df['Row'], df['Count'])\n    ax.set_xlabel('Duplicate Rows')\n    ax.set_ylabel('Count')\n    ax.set_title('Duplicate Rows in CSV File')\n    \n    return duplicates, ax\nfile_path = 'example.csv'", "raw_solution": "import csv\nfrom collections import Counter\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(file_path):\n    # Check if the file has a .csv extension\n    if not file_path.endswith('.csv'):\n        raise ValueError(\"File must be in .csv format\")\n    \n    # Read the CSV file and store the rows in a list\n    with open(file_path, mode='r') as file:\n        reader = csv.reader(file)\n        rows = list(reader)\n    \n    # Count the occurrences of each row\n    row_counts = Counter(tuple(row) for row in rows)\n    \n    # Filter out rows that occur only once\n    duplicates = {row: count for row, count in row_counts.items() if count > 1}\n    \n    # Convert the duplicates to a pandas DataFrame\n    df = pd.DataFrame(list(duplicates.items()), columns=['Row', 'Count'])\n    \n    # Plot the bar chart using matplotlib\n    fig, ax = plt.subplots()\n    ax.bar(df['Row'], df['Count'])\n    ax.set_xlabel('Duplicate Rows')\n    ax.set_ylabel('Count')\n    ax.set_title('Duplicate Rows in CSV File')\n    \n    return duplicates, ax\n\n# Example usage\nfile_path = 'example.csv'\nduplicates, ax = task_func(file_path)"}
{"task_id": "BigCodeBench/530", "solution": "import pandas as pd\nimport numpy as np\nfrom collections import Counter\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ndef task_func(df: pd.DataFrame) -> (Counter, plt.Axes):\n    if df.empty:\n        raise ValueError(\"DataFrame is empty\")\n    \n    if df['age'].min() < 0:\n        raise ValueError(\"Age cannot be negative\")\n    \n    df['age'] = df['age'].apply(np.floor)\n    \n    duplicates = df[df.duplicated('name', keep=False)]\n    \n    if duplicates.empty:\n        return Counter(), None\n    \n    age_distribution = Counter(duplicates['age'])\n    \n    plt.figure(figsize=(10, 6))", "raw_solution": "import pandas as pd\nimport numpy as np\nfrom collections import Counter\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(df: pd.DataFrame) -> (Counter, plt.Axes):\n    if df.empty:\n        raise ValueError(\"DataFrame is empty\")\n    \n    if df['age'].min() < 0:\n        raise ValueError(\"Age cannot be negative\")\n    \n    df['age'] = df['age'].apply(np.floor)\n    \n    duplicates = df[df.duplicated('name', keep=False)]\n    \n    if duplicates.empty:\n        return Counter(), None\n    \n    age_distribution = Counter(duplicates['age'])\n    \n    plt.figure(figsize=(10, 6))\n    sns.histplot(duplicates['age'], bins=np.arange(age_distribution.keys().start.__func__.__globals__.fromkeys.__module__.fromkeys.__module__.fromkeys.__module__.fromkeys.__module__.fromkeys.__module__.fromkeys.__module__.fromkeys.__module__.fromkeys.__module__.fromkeys('collections', fromkeys from collections import fromkeys from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from"}
{"task_id": "BigCodeBench/532", "solution": "import numpy as np\nfrom collections import Counter\nfrom scipy.stats import norm\nimport matplotlib.pyplot as plt\nimport pandas as pd\ndef task_func(df, bins=4):\n    from pandas import DataFrame\n    pd.set_option('pandas.core.common', DataFrame)\n    from pandas.core.common import DataFrame as _pandas_patch", "raw_solution": "import numpy as np\nfrom collections import Counter\nfrom scipy.stats import norm\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\ndef task_func(df, bins=4):\n    from pandas import DataFrame\n    pd.set_option('pandas.core.common', DataFrame)\n    from pandas.core.common import DataFrame as _pandas_patch\n    from pandas.core.common import _pandas_patch as _pandas_patch from _pandas_patch from _pandas_patch from _pandas_patch from _pandas_patch from _pandas_patch from _pandas_patch from _pandas_patch from _pandas_patch from _pandas_patch from _pandas_patch from _pandas_patch from _pandas_patch from _pandas from _pandas from _pandas from _pandas from _pandas from _pandas from _pandas from _pandas from _pandas from _pandas from _pandas from _pandas from _pandas from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p from _p"}
{"task_id": "BigCodeBench/553", "solution": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nCOLUMNS = ['A', 'B', 'C', 'D', 'E']\ndef task_func(a, b):\n    # Create a DataFrame with random values\n    df = pd.DataFrame(np.random.rand(len(a), len(b)), index=a, columns=COLUMNS[:len(b)])\n    # Plot the DataFrame as a bar chart\n    ax = df.plot(kind='bar', figsize=(10, 6))\n    return ax\na = ['row1', 'row2', 'row3']\nb = [1, 2, 3]", "raw_solution": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n# Constants\nCOLUMNS = ['A', 'B', 'C', 'D', 'E']\n\ndef task_func(a, b):\n    # Create a DataFrame with random values\n    df = pd.DataFrame(np.random.rand(len(a), len(b)), index=a, columns=COLUMNS[:len(b)])\n    # Plot the DataFrame as a bar chart\n    ax = df.plot(kind='bar', figsize=(10, 6))\n    return ax\n\n# Example usage\na = ['row1', 'row2', 'row3']\nb = [1, 2, 3]\nax = task_func(a, b)\nplt.show()\n\n```"}
{"task_id": "BigCodeBench/560", "solution": "from datetime import datetime\nimport matplotlib.pyplot as plt\nimport pandas as pd\ndef task_func(data):\n    # Convert the data to a pandas DataFrame\n    df = pd.DataFrame(data)\n    \n    # Convert the 'month' column to datetime format\n    df['month'] = pd.to_datetime(df['month'], format='%B')\n    \n    # Create a bar chart\n    fig, ax = plt.subplots()\n    ax.bar(df['month'], df['value'])\n    \n    # Set the title, x label, and y label\n    ax.set_title(f'Monthly Data for {datetime.now().year}')\n    ax.set_xlabel('Month')\n    ax.set_ylabel('Value')\n    \n    # Return the Axes object\n    return ax\ndata = {'month': ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December'],\n        'value': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120]}", "raw_solution": "from datetime import datetime\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\ndef task_func(data):\n    # Convert the data to a pandas DataFrame\n    df = pd.DataFrame(data)\n    \n    # Convert the 'month' column to datetime format\n    df['month'] = pd.to_datetime(df['month'], format='%B')\n    \n    # Create a bar chart\n    fig, ax = plt.subplots()\n    ax.bar(df['month'], df['value'])\n    \n    # Set the title, x label, and y label\n    ax.set_title(f'Monthly Data for {datetime.now().year}')\n    ax.set_xlabel('Month')\n    ax.set_ylabel('Value')\n    \n    # Return the Axes object\n    return ax\n\n# Test the function with sample data\ndata = {'month': ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December'],\n        'value': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120]}\ntask_func(data)\n\n```"}
{"task_id": "BigCodeBench/567", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(data):\n    # Convert the input string to a pandas Series\n    data_series = pd.Series(data.split())\n    \n    # Convert the Series to numeric values, coercing errors to NaN\n    data_series = pd.to_numeric(data_series, errors='coerce')\n    \n    # Filter out NaN values\n    data_series = data_series.dropna()\n    \n    # Create a histogram using matplotlib\n    fig, ax = plt.subplots()\n    ax.hist(data_series, bins=np.arange(data_series.min(), data_series.max()+2) - 0.5, edgecolor='black')\n    \n    # Set the title and labels\n    ax.set_title('Histogram of Values')\n    ax.set_xlabel('Value')\n    ax.set_ylabel('Frequency')\n    \n    # Return the Axes object\n    return ax\ndata = \"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20\"", "raw_solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(data):\n    # Convert the input string to a pandas Series\n    data_series = pd.Series(data.split())\n    \n    # Convert the Series to numeric values, coercing errors to NaN\n    data_series = pd.to_numeric(data_series, errors='coerce')\n    \n    # Filter out NaN values\n    data_series = data_series.dropna()\n    \n    # Create a histogram using matplotlib\n    fig, ax = plt.subplots()\n    ax.hist(data_series, bins=np.arange(data_series.min(), data_series.max()+2) - 0.5, edgecolor='black')\n    \n    # Set the title and labels\n    ax.set_title('Histogram of Values')\n    ax.set_xlabel('Value')\n    ax.set_ylabel('Frequency')\n    \n    # Return the Axes object\n    return ax\n\n# Example usage:\ndata = \"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20\"\nax = task_func(data)\n\n# Show the plot\nplt.show()\n\n```"}
{"task_id": "BigCodeBench/574", "solution": "from scipy.optimize import curve_fit\nimport matplotlib.pyplot as plt\nimport numpy as np\ndef task_func(array_length=100, noise_level=0.2):\n    # Generate a noisy sine wave\n    x = np.linspace(0, 10, array_length)\n    y = np.sin(x) + noise_level * np.random.randn(array_length)\n\n    # Define the curve fitting function\n    def sine_func(x, amplitude, frequency, phase, offset):\n        return amplitude * np.sin(frequency * x + phase) + offset\n\n    # Perform curve fitting\n    popt, pcov = curve_fit(sine_func, x, y, p0=[1, 1, 0, 0])\n\n    # Create a plot\n    fig, ax = plt.subplots()\n\n    # Plot the noisy sine wave\n    ax.plot(x, y, 'b-', label='Noisy Sine Wave')\n\n    # Plot the adjusted curve\n    ax.plot(x, sine_func(x, *popt), 'r-', label='Adjusted Curve')\n\n    # Add labels and legend\n    ax.set_xlabel('x')\n    ax.set_ylabel('y')\n    ax.legend()\n\n    return ax", "raw_solution": "from scipy.optimize import curve_fit\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef task_func(array_length=100, noise_level=0.2):\n    # Generate a noisy sine wave\n    x = np.linspace(0, 10, array_length)\n    y = np.sin(x) + noise_level * np.random.randn(array_length)\n\n    # Define the curve fitting function\n    def sine_func(x, amplitude, frequency, phase, offset):\n        return amplitude * np.sin(frequency * x + phase) + offset\n\n    # Perform curve fitting\n    popt, pcov = curve_fit(sine_func, x, y, p0=[1, 1, 0, 0])\n\n    # Create a plot\n    fig, ax = plt.subplots()\n\n    # Plot the noisy sine wave\n    ax.plot(x, y, 'b-', label='Noisy Sine Wave')\n\n    # Plot the adjusted curve\n    ax.plot(x, sine_func(x, *popt), 'r-', label='Adjusted Curve')\n\n    # Add labels and legend\n    ax.set_xlabel('x')\n    ax.set_ylabel('y')\n    ax.legend()\n\n    return ax\n\n# Test the function\nax = task_func()\nplt.show()\n\n```"}
{"task_id": "BigCodeBench/579", "solution": "import unicodedata\nimport csv\nfrom collections import Counter\nimport matplotlib.pyplot as plt\ndef task_func(csv_file):\n    try:\n        with open(csv_file, 'r', encoding='utf-8') as file:\n            reader = csv.reader(file)\n            text = ' '.join([row[0] for row in reader])\n    except FileNotFoundError:\n        raise FileNotFoundError(\"The CSV file cannot be found at the specified path.\")\n    except IOError:\n        raise IOError(\"There is an error in reading the file.\")\n\n    normalized_text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('ascii')\n    word_counts = Counter(normalized_text.split())\n    most_common_words = word_counts.most_common(10)\n\n    fig, ax = plt.subplots()\n    ax.bar([word for word, count in most_common_words], [count for word, count in most_common_words])\n    ax.set_xlabel('Words')\n    ax.set_ylabel('Frequencies')\n    ax.set_title('10 Most Common Words')\n\n    return ax, most_common_words", "raw_solution": "import unicodedata\nimport csv\nfrom collections import Counter\nimport matplotlib.pyplot as plt\n\ndef task_func(csv_file):\n    try:\n        with open(csv_file, 'r', encoding='utf-8') as file:\n            reader = csv.reader(file)\n            text = ' '.join([row[0] for row in reader])\n    except FileNotFoundError:\n        raise FileNotFoundError(\"The CSV file cannot be found at the specified path.\")\n    except IOError:\n        raise IOError(\"There is an error in reading the file.\")\n\n    normalized_text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('ascii')\n    word_counts = Counter(normalized_text.split())\n    most_common_words = word_counts.most_common(10)\n\n    fig, ax = plt.subplots()\n    ax.bar([word for word, count in most_common_words], [count for word, count in most_common_words])\n    ax.set_xlabel('Words')\n    ax.set_ylabel('Frequencies')\n    ax.set_title('10 Most Common Words')\n\n    return ax, most_common_words\n\n```"}
{"task_id": "BigCodeBench/582", "solution": "import numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\ndef task_func(size=1000):\n    # Generate normally distributed random numbers\n    data = np.random.normal(loc=0, scale=1, size=size)\n    \n    # Create a figure object\n    fig, ax = plt.subplots()\n    \n    # Plot the histogram\n    ax.hist(data, bins=30, density=True, alpha=0.6, color='g')\n    \n    # Plot the probability density function\n    xmin, xmax = plt.xlim()\n    x = np.linspace(xmin, xmax, 100)\n    p = stats.norm.pdf(x, 0, 1)\n    ax.plot(x, p, 'k', linewidth=2)\n    \n    return fig", "raw_solution": "import numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\n\ndef task_func(size=1000):\n    # Generate normally distributed random numbers\n    data = np.random.normal(loc=0, scale=1, size=size)\n    \n    # Create a figure object\n    fig, ax = plt.subplots()\n    \n    # Plot the histogram\n    ax.hist(data, bins=30, density=True, alpha=0.6, color='g')\n    \n    # Plot the probability density function\n    xmin, xmax = plt.xlim()\n    x = np.linspace(xmin, xmax, 100)\n    p = stats.norm.pdf(x, 0, 1)\n    ax.plot(x, p, 'k', linewidth=2)\n    \n    return fig\n\n# Test the function\nfig = task_func()\nplt.show()\n\n```"}
{"task_id": "BigCodeBench/583", "solution": "import rsa", "raw_solution": "import rsa\nimport os from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from"}
{"task_id": "BigCodeBench/587", "solution": "import rsa", "raw_solution": "import rsa\nimport os from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from"}
{"task_id": "BigCodeBench/590", "solution": "from urllib.request import urlopen\nfrom urllib.error import URLError\nfrom pyquery import PyQuery as pq\nfrom datetime import datetime\nimport pandas as pd\ndef task_func(url):\n    try:\n        from pyquery import PyQuery as pq\n    except ImportError:\n        from pyquery import PyQuery as pq\n    \n    if not url:\n        raise ValueError(\"URL is empty\")\n    \n    try:\n        from pyquery import PyQuery as pq\n    except ImportError:\n        from pyquery import PyQuery as pq\n    \n    try:\n        from pyquery import PyQuery as pq\n    except ImportError:\n        from pyquery import PyQuery as pq\n    \n    try:\n        from pyquery import PyQuery as pq\n    except ImportError:\n        from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    try:\n        from pyquery import PyQuery as pq\n    except ImportError:\n        from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq", "raw_solution": "from urllib.request import urlopen\nfrom urllib.error import URLError\nfrom pyquery import PyQuery as pq\nfrom datetime import datetime\nimport pandas as pd\n\ndef task_func(url):\n    try:\n        from pyquery import PyQuery as pq\n    except ImportError:\n        from pyquery import PyQuery as pq\n    \n    if not url:\n        raise ValueError(\"URL is empty\")\n    \n    try:\n        from pyquery import PyQuery as pq\n    except ImportError:\n        from pyquery import PyQuery as pq\n    \n    try:\n        from pyquery import PyQuery as pq\n    except ImportError:\n        from pyquery import PyQuery as pq\n    \n    try:\n        from pyquery import PyQuery as pq\n    except ImportError:\n        from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    try:\n        from pyquery import PyQuery as pq\n    except ImportError:\n        from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n    from pyquery import PyQuery as pq\n    \n   "}
{"task_id": "BigCodeBench/592", "solution": "import csv", "raw_solution": "import csv\nimport os from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from"}
{"task_id": "BigCodeBench/593", "solution": "import csv", "raw_solution": "import csv\nimport os from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from"}
{"task_id": "BigCodeBench/594", "solution": "import csv", "raw_solution": "import csv\nimport os from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from"}
{"task_id": "BigCodeBench/618", "solution": "from random import randint\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nTEAMS = ['Team A', 'Team B', 'Team C', 'Team D', 'Team E']\nPENALTY_COST = 1000\ndef task_func(goals, penalties):\n    # Generate random goals and penalties for each team\n    team_goals = {team: randint(0, goals) for team in TEAMS}\n    team_penalties = {team: randint(0, penalties) for team in TEAMS}\n    \n    # Convert penalties to fines\n    team_fines = {team: team_penalties[team] * PENALTY_COST for team in TEAMS}\n    \n    # Create a DataFrame to store the results\n    df = pd.DataFrame({\n        'Team': list(team_goals.keys()),\n        'Goals': list(team_goals.values()),\n        'Penalty Cost': list(team_penalties.values()),\n        'Fine': list(team_fines.values())\n    })\n    \n    # Create two plots: one for goals and one for penalty costs\n    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n    sns.barplot(x='Team', y='Goals', data=df, ax=axes[0])\n    sns.barplot(x='Team', y='Penalty Cost', data=df, ax=axes[1])\n    \n    return df, axes.tolist()", "raw_solution": "from random import randint\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\n# Constants\nTEAMS = ['Team A', 'Team B', 'Team C', 'Team D', 'Team E']\nPENALTY_COST = 1000  # in dollars\n\ndef task_func(goals, penalties):\n    # Generate random goals and penalties for each team\n    team_goals = {team: randint(0, goals) for team in TEAMS}\n    team_penalties = {team: randint(0, penalties) for team in TEAMS}\n    \n    # Convert penalties to fines\n    team_fines = {team: team_penalties[team] * PENALTY_COST for team in TEAMS}\n    \n    # Create a DataFrame to store the results\n    df = pd.DataFrame({\n        'Team': list(team_goals.keys()),\n        'Goals': list(team_goals.values()),\n        'Penalty Cost': list(team_penalties.values()),\n        'Fine': list(team_fines.values())\n    })\n    \n    # Create two plots: one for goals and one for penalty costs\n    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n    sns.barplot(x='Team', y='Goals', data=df, ax=axes[0])\n    sns.barplot(x='Team', y='Penalty Cost', data=df, ax=axes[1])\n    \n    return df, axes.tolist()\n\n# Example usage\ndf, plots = task_func(10, 5)"}
{"task_id": "BigCodeBench/636", "solution": "import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport numpy as np\nCOLUMNS = ['Column1', 'Column2', 'Column3', 'Column4', 'Column5']\ndef task_func(rows):\n    # Generate a DataFrame with random integer values between 0 and 9\n    data = {col: np.random.randint(0, 10, rows) for col in COLUMNS}\n    df = pd.DataFrame(data)\n    \n    # Count the non-zero values in each column\n    non_zero_counts = df.apply(lambda x: x.astype(bool).sum(), axis=0)\n    \n    # Plot the non-zero counts using a bar plot\n    fig, ax = plt.subplots()\n    non_zero_counts.plot(kind='bar', ax=ax)\n    \n    return df, ax", "raw_solution": "import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\n# Constants\nCOLUMNS = ['Column1', 'Column2', 'Column3', 'Column4', 'Column5']\n\ndef task_func(rows):\n    # Generate a DataFrame with random integer values between 0 and 9\n    data = {col: np.random.randint(0, 10, rows) for col in COLUMNS}\n    df = pd.DataFrame(data)\n    \n    # Count the non-zero values in each column\n    non_zero_counts = df.apply(lambda x: x.astype(bool).sum(), axis=0)\n    \n    # Plot the non-zero counts using a bar plot\n    fig, ax = plt.subplots()\n    non_zero_counts.plot(kind='bar', ax=ax)\n    \n    return df, ax\n\n# Test the function with the provided test cases from matplotlib\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\n# Test the function\ndf, ax = task_func(10)\n\n```"}
{"task_id": "BigCodeBench/637", "solution": "import random\nimport numpy as np\nimport pandas as pd\nfrom typing import Tuple\nimport matplotlib.pyplot as plt\ndef task_func(num_students):\n    # Import necessary packages\n    from random import randint\n    \n    # Create a sample DataFrame\n    import pandas as pd\n    df = pd.DataFrame()\n    \n    # Generate random grades for each course\n    from random import randint\n    import numpy as np\n    \n    # Add necessary import for numpy\n    from typing import Tuple\n    \n    # Generate random grades for each course\n    import random\n    import numpy as np\n    \n    # Add necessary import for numpy\n    from typing import Tuple\n    \n    # Generate random grades for each course\n    import random\n    import numpy as np\n    \n    # Add necessary import for numpy\n    from typing import Tuple\n    \n    # Generate random grades for each course\n    import random\n    import numpy as np\n    \n    # Add necessary import for numpy\n    from typing import Tuple\n    \n    # Generate random grades for each course\n    import random", "raw_solution": "import random\nimport numpy as np\nimport pandas as pd\nfrom typing import Tuple\nimport matplotlib.pyplot as plt\n\ndef task_func(num_students):\n    # Import necessary packages\n    from random import randint\n    \n    # Create a sample DataFrame\n    import pandas as pd\n    df = pd.DataFrame()\n    \n    # Generate random grades for each course\n    from random import randint\n    import numpy as np\n    \n    # Add necessary import for numpy\n    from typing import Tuple\n    \n    # Generate random grades for each course\n    import random\n    import numpy as np\n    \n    # Add necessary import for numpy\n    from typing import Tuple\n    \n    # Generate random grades for each course\n    import random\n    import numpy as np\n    \n    # Add necessary import for numpy\n    from typing import Tuple\n    \n    # Generate random grades for each course\n    import random\n    import numpy as np\n    \n    # Add necessary import for numpy\n    from typing import Tuple\n    \n    # Generate random grades for each course\n    import random\n    import numpy as from_numpy import *\n    \n    # Fix from from_numpy import * from import from_numpy\n    from typing import from_numpy from_numpy import from_numpy from_numpy import from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from_numpy from"}
{"task_id": "BigCodeBench/654", "solution": "import matplotlib.pyplot as plt\nimport scipy.optimize as optimize\nimport numpy as np\ndef task_func(array, target_value):\n    # Filter the array to include only rows where the first column matches the target value\n    filtered_array = array[array[:, 0] == target_value]\n    \n    # Extract the indices and values for fitting\n    indices = filtered_array[:, 1]\n    values = filtered_array[:, 2]\n    \n    # Define the exponential decay function\n    def exponential_decay(x, a, b, c):\n        return a * np.exp(-b * x) + c\n    \n    # Perform the curve fitting\n    popt, pcov = optimize.curve_fit(exponential_decay, indices, values)\n    \n    # Create a figure and axis for plotting\n    fig, ax = plt.subplots()\n    \n    # Plot the original data points\n    ax.scatter(indices, values, label='Data')\n    \n    # Plot the fitted curve\n    ax.plot(indices, exponential_decay(indices, *popt), 'r-', label='Fitted curve')\n    \n    # Add labels and legend\n    ax.set_xlabel('Index')\n    ax.set_ylabel('Value')\n    ax.legend()\n    \n    # Return the optimized parameters and the Axes object\n    return popt, ax", "raw_solution": "import matplotlib.pyplot as plt\nimport scipy.optimize as optimize\nimport numpy as np\n\ndef task_func(array, target_value):\n    # Filter the array to include only rows where the first column matches the target value\n    filtered_array = array[array[:, 0] == target_value]\n    \n    # Extract the indices and values for fitting\n    indices = filtered_array[:, 1]\n    values = filtered_array[:, 2]\n    \n    # Define the exponential decay function\n    def exponential_decay(x, a, b, c):\n        return a * np.exp(-b * x) + c\n    \n    # Perform the curve fitting\n    popt, pcov = optimize.curve_fit(exponential_decay, indices, values)\n    \n    # Create a figure and axis for plotting\n    fig, ax = plt.subplots()\n    \n    # Plot the original data points\n    ax.scatter(indices, values, label='Data')\n    \n    # Plot the fitted curve\n    ax.plot(indices, exponential_decay(indices, *popt), 'r-', label='Fitted curve')\n    \n    # Add labels and legend\n    ax.set_xlabel('Index')\n    ax.set_ylabel('Value')\n    ax.legend()\n    \n    # Return the optimized parameters and the Axes object\n    return popt, ax\n\n# Example usage\narray = np.array([[0 from scipy import import *], ['from', 'array from', 'array from scipy import import from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from array from"}
{"task_id": "BigCodeBench/655", "solution": "import re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import import_module\nfrom importlib import *", "raw_solution": "import re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import import_module\nfrom importlib import *\ntask_func_module = type('import_module', (), {'__name__': 'task_func_module'})\nfrom task_func_module import import_module from task_func_module.task_func_module import task_func from task_func_module.task_func_module.task_func_module import task from task_func_module.task_func_module.task_func_module.task_func_module from task_func_module.task_func_module.task_func_module.task_func_module.task_func_module from task_func_module.task_func_module.task_func_module.task_func_module.task_func_module.task_func_module from task_func_module.task_func_module.task_func_module.task_func_module.task_func_module.task_func_module.task_func_module from task_func_module.task_func_module.task_func_module.task_func_module.task_func_module.task_func_module.task_func_module.task_func from task_func_module.task_func_module.task_func_module.task_func_module.task_func_module.task_func_module.task_func_module.task_func from task_func_module.task_func_module.task_func_module from task_func_module from task_func_module from task_func_module from task_func_module from task_func_module from task_func_module from task_func_module from task_func_module from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task"}
{"task_id": "BigCodeBench/657", "solution": "import re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom gensim.models import Word2Vec\nimport gensim\nfrom collections import Counter\nfrom nltk.corpus import stopwords\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize", "raw_solution": "import re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom gensim.models import Word2Vec\nimport gensim\nfrom collections import Counter\nfrom nltk.corpus import stopwords\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import word_tokenize from nltk.corpus.tokenize import word_tokenize from nltk.corpus.tokenize from nltk.tokenize.tokenize from nltk.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize.tokenize"}
{"task_id": "BigCodeBench/678", "solution": "import pandas as pd\nimport json\nimport os", "raw_solution": "import pandas as pd\nimport json\nimport os\nfrom pathlib import import_module as from_module_path from_module_path = from_module_path from_module_path = from_module_path from_module_path = from_module_path from_module_path from_module_path from_module_path from_module_path from_module_path from_module_path from_module_path from_module_path from_module_path from_module_path from_module_path from_module_path from_module_path from_module_path from_module_path from_module_path from_module_path from_module_path from_module_path from_module_path from_module_path from_module_path from_module_path from_module_path from_module_path from_module_path from_module_path from_module_path from_module_path from_module_path from_module_path from_module_path from_module_path from_module_path from_module_path from_module_path from_module from_module_path from_module_path from_module_path from_module_path from_module_path from_module_path from_module_path from_module_path from_module_path from_module_path from_module_path from_module_path from_module_path from_module_path from_module_path from_module_path from_module_path from_module_path from_module_path from_module_path from_module_path from_module_path from_module_path from_module_path from_module_path from_module_path from_module_path from_module_path from_module_path from_module_path from_module_path from_module_path from_module_path from_module_path from_module_path from_module_path from_module_path from_module_path from_module_path from_module_path from_module_path from_module from_module_path from_module_path from_module_path from_module_path from from_module_path from from_module_path from from_module_path from from_module_path from from_module_path from from_module_path from from_module_path from from_module_path from from_module_path from from_module_path from from_module_path from from_module_path from from_module_path from from_module_path from from from_module_path from from from_module_path from from from_module_path from from from_module_path from from from_module_path from from from from_module_path from from from from from_module_path from from from from from from_module_path from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from"}
{"task_id": "BigCodeBench/720", "solution": "import os\nfrom datetime import datetime", "raw_solution": "import os\nfrom datetime import datetime\nfrom task_func_data import task_func_data from from_data import task_func_data from task_func_data from task_func_data from task_func_data from task_func_data from task_func_data from task_func_data from task_func_data from task_func_data from task_func_data from task_func_data from task_func_data from task_func_data from task_func_data from task_func_data from task_func_data from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from"}
{"task_id": "BigCodeBench/723", "solution": "import csv", "raw_solution": "import csv\nfrom bs4 import BeautifulSoup from task_data from import task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task_data from task"}
{"task_id": "BigCodeBench/752", "solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nimport numpy as np\ndef task_func(data, target_column, test_size=0.2, random_state = 0) -> float:\n    if not isinstance(data, pd.DataFrame):\n        raise ValueError(\"Data must be a DataFrame\")\n    if data.empty:\n        raise ValueError(\"Data must not be empty\")\n    if target_column not in data.columns:\n        raise ValueError(f\"Target column '{target_column}' must be a column of data\")\n    if not all(isinstance(x, (int, float)) for x in data.select_dtypes(include=[np.number]).to_numpy().flatten()):\n        from sklearn import get_config\n        from sklearn import set_config\n        from sklearn.exceptions import set_config as _set_config\n        from sklearn.exceptions import get_config as _get_config\n        from sklearn.exceptions import _import_module\n        from sklearn.exceptions import _import_module as _import_module\n        from sklearn.exceptions import _set_module as _set_module\n        from sklearn.exceptions import _get_module as _get_module", "raw_solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nimport numpy as np\n\ndef task_func(data, target_column, test_size=0.2, random_state = 0) -> float:\n    if not isinstance(data, pd.DataFrame):\n        raise ValueError(\"Data must be a DataFrame\")\n    if data.empty:\n        raise ValueError(\"Data must not be empty\")\n    if target_column not in data.columns:\n        raise ValueError(f\"Target column '{target_column}' must be a column of data\")\n    if not all(isinstance(x, (int, float)) for x in data.select_dtypes(include=[np.number]).to_numpy().flatten()):\n        from sklearn import get_config\n        from sklearn import set_config\n        from sklearn.exceptions import set_config as _set_config\n        from sklearn.exceptions import get_config as _get_config\n        from sklearn.exceptions import _import_module\n        from sklearn.exceptions import _import_module as _import_module\n        from sklearn.exceptions import _set_module as _set_module\n        from sklearn.exceptions import _get_module as _get_module\n        from sklearn.exceptions import _set_module as _set_module from sklearn.exceptions import _set_module from sklearn.exceptions import _set_module from sklearn.exceptions import _set_module from sklearn.exceptions import _set_module from sklearn.exceptions import _set_module from sklearn.exceptions import _set_module from sklearn.exceptions import _set_module from sklearn.exceptions from sklearn.exceptions import _set_module from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from sklearn.exceptions from"}
{"task_id": "BigCodeBench/760", "solution": "import pandas as pd\nimport numpy as np\nimport codecs\nimport re\nimport datetime\nfrom io import StringIO", "raw_solution": "import pandas as pd\nimport numpy as np\nimport codecs\nimport re\nimport datetime\nfrom io import StringIO\n\ndef task_func(start_year=1980, end_year=2000, email_domain='example.com',\n           latin_names=['Sopet\u00f3n', 'M\u00e9ndez', 'G\u00f3mez', 'P\u00e9rez', 'Mu\u00f1oz'],\n           other_names=['Smith', 'Johnson', 'Williams', 'Brown', 'Jones'], \n           rng_seed=None):\n    # Import necessary libraries\n    from faker import fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake from fake"}
{"task_id": "BigCodeBench/763", "solution": "import numpy as np\nfrom collections import defaultdict\nfrom importlib import import_module\nimport json\nimport csv", "raw_solution": "import numpy as np\nfrom collections import defaultdict\nfrom importlib import import_module\nimport json\nimport csv\n# Constants\nfrom numpy import task_func as _from_numpy_task_func from task_func from task_func from task_func from task_func from task_func from task from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func"}
{"task_id": "BigCodeBench/765", "solution": "import os", "raw_solution": "import os\nfrom pathlib import import from pathlib import import from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from"}
{"task_id": "BigCodeBench/771", "solution": "import re", "raw_solution": "import re\nimport os from pathlib import from pathlib import *\nfrom pathlib import directory from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from"}
{"task_id": "BigCodeBench/777", "solution": "import re", "raw_solution": "import re\nimport os from zipfile import task_func from from zipfile import task_func from from zipfile import task from from zipfile import task from from zipfile import task from from zipfile import task from from zipfile import task from from zipfile from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from"}
{"task_id": "BigCodeBench/785", "solution": "import subprocess\nimport os", "raw_solution": "import subprocess\nimport os\nfrom os.path import task_func from task_func from task_func from task_func from task_func from task_func from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from"}
{"task_id": "BigCodeBench/800", "solution": "import csv\nfrom collections import Counter", "raw_solution": "import csv\nfrom collections import Counter\nimport os from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from"}
{"task_id": "BigCodeBench/826", "solution": "import re", "raw_solution": "import re\nimport os from shutil import from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from"}
{"task_id": "BigCodeBench/845", "solution": "from collections import Counter\nfrom typing import Tuple\nfrom typing import *\nfrom collections import *\nfrom typing import *", "raw_solution": "from collections import Counter\nfrom typing import Tuple\nfrom typing import *\nfrom collections import *\nfrom typing import *\nfrom typing import Tuple from collections import Counter from typing import Tuple from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from"}
{"task_id": "BigCodeBench/854", "solution": "from functools import reduce\nfrom itertools import permutations\nimport math\ndef task_func(numbers):\n    if not isinstance(numbers, list):\n        raise TypeError(\"Input must be a list of integers\")\n    if not all(isinstance(num, int) for num in numbers):\n        raise TypeError(\"All elements in the list must be integers\")\n    if any(num < 0 for num in numbers):\n        raise ValueError(\"All numbers must be non-negative\")\n\n    factorial_sums = []\n    for perm in permutations(numbers):\n        factorial_sum = reduce(lambda x, y: x + math.factorial(y), perm, 0)\n        factorial_sums.append(factorial_sum)\n\n    return factorial_sums, list(permutations(numbers))", "raw_solution": "from functools import reduce\nfrom itertools import permutations\nimport math\n\ndef task_func(numbers):\n    if not isinstance(numbers, list):\n        raise TypeError(\"Input must be a list of integers\")\n    if not all(isinstance(num, int) for num in numbers):\n        raise TypeError(\"All elements in the list must be integers\")\n    if any(num < 0 for num in numbers):\n        raise ValueError(\"All numbers must be non-negative\")\n\n    factorial_sums = []\n    for perm in permutations(numbers):\n        factorial_sum = reduce(lambda x, y: x + math.factorial(y), perm, 0)\n        factorial_sums.append(factorial_sum)\n\n    return factorial_sums, list(permutations(numbers))\n\n# Test cases\n\n```"}
{"task_id": "BigCodeBench/857", "solution": "import warnings\nfrom importlib import import_module\nimport shutil\nimport time\nfrom importlib._bootstrap import _import_module_from_spec\nimport sys", "raw_solution": "import warnings\nfrom importlib import import_module\nimport shutil\nimport time\nfrom importlib._bootstrap import _import_module_from_spec\nimport sys\nfrom importlib.machinery import _import_module_from_spec as _m from _m import _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _m from _"}
{"task_id": "BigCodeBench/865", "solution": "import pandas as pd\nimport numpy as np\nfrom scipy.stats import zscore\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn import datasets\ndef task_func(data):\n    from sklearn import datasets\n    from sklearn.preprocessing import MinMaxScaler\n    from sklearn.preprocessing import datasets\n            # Fix from sklearn import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets", "raw_solution": "import pandas as pd\nimport numpy as np\nfrom scipy.stats import zscore\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn import datasets\n\ndef task_func(data):\n    from sklearn import datasets\n    from sklearn.preprocessing import MinMaxScaler\n    from sklearn.preprocessing import datasets\n            # Fix from sklearn import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets from sklearn.datasets import datasets"}
{"task_id": "BigCodeBench/870", "solution": "import pandas as pd\nimport numpy as np\nfrom collections import defaultdict\nfrom itertools import chain\nfrom importlib import import_module\nimport itertools", "raw_solution": "import pandas as pd\nimport numpy as np\nfrom collections import defaultdict\nfrom itertools import chain\nfrom importlib import import_module\n\n# Fixing the import error for itertools.chain from itertools\nimport itertools\n\ndef task_func(data_list=[('a', 1, 1 from itertools import import_module from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from"}
{"task_id": "BigCodeBench/879", "solution": "import pandas as pd\nimport numpy as np\nfrom scipy.stats import chi2_contingency\ndef task_func(data, col1, col2):\n    # Check if 'data' is empty\n    if data.empty:\n        raise ValueError(\"The DataFrame is empty.\")\n    \n    # Check if 'col1' and 'col2' are in 'data'\n    if col1 not in data.columns or col2 not in data.columns:\n        raise ValueError(f\"One or both of the columns ({col1}, {col2}) are not in the DataFrame.\")\n    \n    # Check if 'col1' and 'col2' contain non-categorical data\n    if not data[col1].dtype == 'object' or not data[col2].dtype == 'object':\n        raise TypeError(\"One or both of the columns contain non-categorical data.\")\n    \n    # Check if one or both of the columns do not have multiple categories\n    if len(data[col1].unique()) < 2 or len(data[col2].unique()) < 2:\n        raise ValueError(\"One or both of the columns do not have multiple categories.\")\n    \n    # Check if some categories have less than 5 observations\n    contingency_table = pd.crosstab(data[col1], data[col2])\n    if (contingency_table < 5).any().any():\n        raise ValueError(\"Some categories have less than 5 observations.\")\n    \n    # Perform the chi-square test of independence\n    chi2, p, dof, expected = chi2_contingency(contingency_table)\n    \n    return p\ndata = pd.DataFrame({\n    'a': np.random.choice(['A', 'B'], size=100),\n    'b': np.random.choice(['X', 'Y'], size=100)\n})", "raw_solution": "import pandas as pd\nimport numpy as np\nfrom scipy.stats import chi2_contingency\n\ndef task_func(data, col1, col2):\n    # Check if 'data' is empty\n    if data.empty:\n        raise ValueError(\"The DataFrame is empty.\")\n    \n    # Check if 'col1' and 'col2' are in 'data'\n    if col1 not in data.columns or col2 not in data.columns:\n        raise ValueError(f\"One or both of the columns ({col1}, {col2}) are not in the DataFrame.\")\n    \n    # Check if 'col1' and 'col2' contain non-categorical data\n    if not data[col1].dtype == 'object' or not data[col2].dtype == 'object':\n        raise TypeError(\"One or both of the columns contain non-categorical data.\")\n    \n    # Check if one or both of the columns do not have multiple categories\n    if len(data[col1].unique()) < 2 or len(data[col2].unique()) < 2:\n        raise ValueError(\"One or both of the columns do not have multiple categories.\")\n    \n    # Check if some categories have less than 5 observations\n    contingency_table = pd.crosstab(data[col1], data[col2])\n    if (contingency_table < 5).any().any():\n        raise ValueError(\"Some categories have less than 5 observations.\")\n    \n    # Perform the chi-square test of independence\n    chi2, p, dof, expected = chi2_contingency(contingency_table)\n    \n    return p\n\n# Test the function with the provided example\nnp.random.seed(42)\ndata = pd.DataFrame({\n    'a': np.random.choice(['A', 'B'], size=100),\n    'b': np.random.choice(['X', 'Y'], size=100)\n})\n"}
{"task_id": "BigCodeBench/897", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport random\nNUMBERS = list(range(1, 7))\ndef task_func(rolls, seed=None):\n    if seed is not None:\n        random.seed(seed)\n    \n    # Simulate dice rolls\n    results = [random.choice(NUMBERS) for _ in range(rolls)]\n    \n    # Calculate frequency of each outcome", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport random\n\n# Constants\nNUMBERS = list(range(1, 7))  # Adjusting for dice rolls (1 to 6)\n\ndef task_func(rolls, seed=None):\n    if seed is not None:\n        random.seed(seed)\n    \n    # Simulate dice rolls\n    results = [random.choice(NUMBERS) for _ in range(rolls)]\n    \n    # Calculate frequency of each outcome\n    frequency = np.array([from_numpy import from_numpy from numpy import import numpy as np\n    from numpy import import numpy as from_numpy from from_numpy import task_func as from_numpy.task_numpy from_numpy import task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy.task_numpy from_numpy"}
{"task_id": "BigCodeBench/906", "solution": "import zipfile", "raw_solution": "import zipfile\nimport os from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from"}
{"task_id": "BigCodeBench/914", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\ndef task_func(df):\n    # Convert the 'timestamp' column to datetime\n    df['timestamp'] = pd.to_datetime(df['timestamp'])\n    \n    # Create a new column 'time_in_seconds' to represent time in seconds since the start\n    df['time_in_seconds'] = (df['timestamp'] - df['timestamp'].min()).dt.total_seconds()\n    \n    # Extract the 'time_in_seconds' and 'close' columns for the regression model\n    X = df[['time_in_seconds']]\n    y = df['close']\n    \n    # Create and fit the linear regression model\n    model = LinearRegression()\n    model.fit(X, y)\n    \n    # Generate future timestamps for the next 7 days\n    future_timestamps = pd.date_range(start=df['timestamp'].max(), periods=8, freq='D')\n    future_timestamps = future_timestamps[1:]  # Exclude the first timestamp which is the same as the last one in the original data\n    \n    # Convert future timestamps to seconds since the start\n    future_time_in_seconds = (future_timestamps - df['timestamp'].min()).dt.total_seconds()\n    \n    # Predict the closing prices for the next 7 days\n    future_prices = model.predict(future_time_in_seconds.values.reshape(-1, 1))\n    \n    # Plot the original data and the predicted prices\n    fig, ax = plt.subplots()\n    ax.plot(df['timestamp'], df['close'], label='Original Data')\n    ax.plot(future_timestamps, future_prices, label='Predicted Prices', linestyle='--')\n    ax.set_xlabel('Timestamp')\n    ax.set_ylabel('Closing Price')\n    ax.set_title('Stock Closing Prices Prediction')\n    ax.legend()\n    \n    return future_prices.tolist(), ax\ndata = {\n    'timestamp': pd.to_datetime(['2023-01-01 00:00:00', '2023-01-02 00:00:00', '2023-01-03 00:00:00', '2023-01-04 00:00:00', '2023-01-05 00:00:00']),\n    'close': [100, 102, 101, 103, 104]\n}\ndf = pd.DataFrame(data)", "raw_solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n\ndef task_func(df):\n    # Convert the 'timestamp' column to datetime\n    df['timestamp'] = pd.to_datetime(df['timestamp'])\n    \n    # Create a new column 'time_in_seconds' to represent time in seconds since the start\n    df['time_in_seconds'] = (df['timestamp'] - df['timestamp'].min()).dt.total_seconds()\n    \n    # Extract the 'time_in_seconds' and 'close' columns for the regression model\n    X = df[['time_in_seconds']]\n    y = df['close']\n    \n    # Create and fit the linear regression model\n    model = LinearRegression()\n    model.fit(X, y)\n    \n    # Generate future timestamps for the next 7 days\n    future_timestamps = pd.date_range(start=df['timestamp'].max(), periods=8, freq='D')\n    future_timestamps = future_timestamps[1:]  # Exclude the first timestamp which is the same as the last one in the original data\n    \n    # Convert future timestamps to seconds since the start\n    future_time_in_seconds = (future_timestamps - df['timestamp'].min()).dt.total_seconds()\n    \n    # Predict the closing prices for the next 7 days\n    future_prices = model.predict(future_time_in_seconds.values.reshape(-1, 1))\n    \n    # Plot the original data and the predicted prices\n    fig, ax = plt.subplots()\n    ax.plot(df['timestamp'], df['close'], label='Original Data')\n    ax.plot(future_timestamps, future_prices, label='Predicted Prices', linestyle='--')\n    ax.set_xlabel('Timestamp')\n    ax.set_ylabel('Closing Price')\n    ax.set_title('Stock Closing Prices Prediction')\n    ax.legend()\n    \n    return future_prices.tolist(), ax\n\n# Example usage\ndata = {\n    'timestamp': pd.to_datetime(['2023-01-01 00:00:00', '2023-01-02 00:00:00', '2023-01-03 00:00:00', '2023-01-04 00:00:00', '2023-01-05 00:00:00']),\n    'close': [100, 102, 101, 103, 104]\n}\ndf = pd.DataFrame(data)\n\nfuture_prices, ax = task_func(df)"}
{"task_id": "BigCodeBench/915", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import zscore\nimport pandas as pd\ndef task_func(df, z_threshold=2):\n    # Calculate the Z-Score for the 'closing_price' column\n    df['z_score'] = zscore(df['closing_price'])\n    \n    # Identify outliers based on the Z-Score threshold\n    outliers = df[df['z_score'].abs() > z_threshold]\n    \n    # Plot the outliers\n    fig, ax = plt.subplots()\n    ax.plot(df.index, df['closing_price'], label='Closing Price')\n    ax.scatter(outliers.index, outliers['closing_price'], color='red', label='Outliers')\n    ax.set_xlabel('Index')\n    ax.set_ylabel('Closing Price')\n    ax.set_title('Outliers in Closing Prices')\n    ax.legend()\n    \n    return outliers, ax", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import zscore\nimport pandas as pd\n\ndef task_func(df, z_threshold=2):\n    # Calculate the Z-Score for the 'closing_price' column\n    df['z_score'] = zscore(df['closing_price'])\n    \n    # Identify outliers based on the Z-Score threshold\n    outliers = df[df['z_score'].abs() > z_threshold]\n    \n    # Plot the outliers\n    fig, ax = plt.subplots()\n    ax.plot(df.index, df['closing_price'], label='Closing Price')\n    ax.scatter(outliers.index, outliers['closing_price'], color='red', label='Outliers')\n    ax.set_xlabel('Index')\n    ax.set_ylabel('Closing Price')\n    ax.set_title('Outliers in Closing Prices')\n    ax.legend()\n    \n    return outliers, ax\n\n# Example usage\ndf2 = pd.DataFrame({\n    'closing_price': [10, 20, 30, 40, 50, 100]\n})\n\noutliers2, plot2 = task_func(df2, z_threshold=1.5)\n\n```"}
{"task_id": "BigCodeBench/916", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ndef task_func(df: pd.DataFrame) -> tuple:\n    # Create a figure with two subplots\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n    \n    # Plot the box plot\n    sns.boxplot(x=df['closing_price'], ax=ax1)\n    ax1.set_title('Box Plot of Closing Prices')\n    \n    # Plot the histogram\n    sns.histplot(df['closing_price'], ax=ax2, kde=True)\n    ax2.set_title('Histogram of Closing Prices')\n    \n    # Return the axes objects\n    return ax1, ax2", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef task_func(df: pd.DataFrame) -> tuple:\n    # Create a figure with two subplots\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n    \n    # Plot the box plot\n    sns.boxplot(x=df['closing_price'], ax=ax1)\n    ax1.set_title('Box Plot of Closing Prices')\n    \n    # Plot the histogram\n    sns.histplot(df['closing_price'], ax=ax2, kde=True)\n    ax2.set_title('Histogram of Closing Prices')\n    \n    # Return the axes objects\n    return ax1, ax2\n\n# Example usage\n# Assuming 'df' is a pandas DataFrame with a column 'closing_price'\n# df = pd.DataFrame({'closing_price': [100, 105, 110, 115, 120, 125, 130, 135, 140, 145]})\n# ax1, ax2 = task_func(df)\n\n```"}
{"task_id": "BigCodeBench/917", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.axes import Axes\nfrom statsmodels.tsa.arima.model import ARIMA\nfrom typing import List, Tuple\ndef task_func(df: pd.DataFrame) -> Tuple[List[float], Axes]:\n    # Ensure the input DataFrame has a datetime index\n    df.set_index('date', inplace=True)\n    \n    # Fit the ARIMA model\n    model = ARIMA(df['price'], order=(5,1,0))\n    model_fit = model.fit()\n    \n    # Forecast the next 7 days\n    forecast = model_fit.forecast(steps=7)\n    \n    # Plot the forecast\n    fig, ax = plt.subplots()\n    ax.plot(df.index, df['price'], label='Historical Prices')\n    ax.plot(pd.date_range(start=df.index[-1], periods=8, closed='right'), forecast, label='Forecasted Prices', linestyle='--')\n    ax.legend()\n    \n    return forecast.tolist(), ax", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.axes import Axes\nfrom statsmodels.tsa.arima.model import ARIMA\nfrom typing import List, Tuple\n\ndef task_func(df: pd.DataFrame) -> Tuple[List[float], Axes]:\n    # Ensure the input DataFrame has a datetime index\n    df.set_index('date', inplace=True)\n    \n    # Fit the ARIMA model\n    model = ARIMA(df['price'], order=(5,1,0))\n    model_fit = model.fit()\n    \n    # Forecast the next 7 days\n    forecast = model_fit.forecast(steps=7)\n    \n    # Plot the forecast\n    fig, ax = plt.subplots()\n    ax.plot(df.index, df['price'], label='Historical Prices')\n    ax.plot(pd.date_range(start=df.index[-1], periods=8, closed='right'), forecast, label='Forecasted Prices', linestyle='--')\n    ax.legend()\n    \n    return forecast.tolist(), ax\n\n# Example usage\n# Assuming 'df' is a DataFrame with 'date' and 'price' columns\n# df = pd.read_csv('your_data.csv', parse_dates=['date'])\n# forecast, ax = task_func(df)\n\n```"}
{"task_id": "BigCodeBench/928", "solution": "from collections import Counter\nimport itertools\nimport string\ndef task_func(word: str) -> dict:\n    # Generate all possible two-letter combinations of the lowercase English alphabets\n    alphabet_combinations = [''.join(pair) for pair in itertools.product(string.ascii_lowercase, repeat=2)]\n    \n    # Initialize a dictionary to store the frequency of each combination\n    combination_frequency = {combo: 0 for combo in alphabet_combinations}\n    \n    # Count the frequency of each combination in the given word\n    for combo in alphabet_combinations:\n        combination_frequency[combo] = word.count(combo)\n    \n    return combination_frequency\nword = \"hello\"", "raw_solution": "from collections import Counter\nimport itertools\nimport string\n\ndef task_func(word: str) -> dict:\n    # Generate all possible two-letter combinations of the lowercase English alphabets\n    alphabet_combinations = [''.join(pair) for pair in itertools.product(string.ascii_lowercase, repeat=2)]\n    \n    # Initialize a dictionary to store the frequency of each combination\n    combination_frequency = {combo: 0 for combo in alphabet_combinations}\n    \n    # Count the frequency of each combination in the given word\n    for combo in alphabet_combinations:\n        combination_frequency[combo] = word.count(combo)\n    \n    return combination_frequency\n\n# Test the function with a sample word\nword = \"hello\""}
{"task_id": "BigCodeBench/942", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nSTART_DATE = '2016-01-01'\nPERIODS = 13\nFREQ = 'WOM-2FRI'\nCATEGORIES = ['Electronics', 'Fashion', 'Home & Kitchen', 'Automotive', 'Sports']\ndef task_func(start_date=START_DATE, periods=PERIODS, freq=FREQ, categories=CATEGORIES):\n    # Create a date range\n    date_range = pd.date_range(start=start_date, periods=periods, freq=freq)\n    \n    # Create a DataFrame with random sales data\n    sales_data = pd.DataFrame({\n        'Date': date_range,\n        'Category': np.random.choice(categories, size=periods),\n        'Sales': np.random.randint(100, 1000, size=periods)\n    })\n    \n    # Import necessary library for numpy\n    import numpy as np\n    \n    # Plot the sales data\n    fig, ax = plt.subplots()\n    for category in categories:\n        category_data = sales_data[sales_data['Category'] == category]\n        ax.plot(category_data['Date'], category_data['Sales'], label=category)\n    \n    ax.set_xlabel('Date')\n    ax.set_ylabel('Sales')\n    ax.set_title('Sales Report by Category')\n    ax.legend()\n    \n    return sales_data, ax", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n# Constants\nSTART_DATE = '2016-01-01'\nPERIODS = 13\nFREQ = 'WOM-2FRI'\nCATEGORIES = ['Electronics', 'Fashion', 'Home & Kitchen', 'Automotive', 'Sports']\ndef task_func(start_date=START_DATE, periods=PERIODS, freq=FREQ, categories=CATEGORIES):\n    # Create a date range\n    date_range = pd.date_range(start=start_date, periods=periods, freq=freq)\n    \n    # Create a DataFrame with random sales data\n    sales_data = pd.DataFrame({\n        'Date': date_range,\n        'Category': np.random.choice(categories, size=periods),\n        'Sales': np.random.randint(100, 1000, size=periods)\n    })\n    \n    # Import necessary library for numpy\n    import numpy as np\n    \n    # Plot the sales data\n    fig, ax = plt.subplots()\n    for category in categories:\n        category_data = sales_data[sales_data['Category'] == category]\n        ax.plot(category_data['Date'], category_data['Sales'], label=category)\n    \n    ax.set_xlabel('Date')\n    ax.set_ylabel('Sales')\n    ax.set_title('Sales Report by Category')\n    ax.legend()\n    \n    return sales_data, ax\n\n# Example usage\nsales_data, ax = task_func()"}
{"task_id": "BigCodeBench/945", "solution": "import pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\ndef task_func(start_date='2016-01-01', periods=13, freq='WOM-2FRI', sales_data=None):\n    # If no sales data is provided, generate a sample dataset\n    if sales_data is None:\n        # Create a date range\n        date_range = pd.date_range(start=start_date, periods=periods, freq=freq)\n        # Generate random sales data\n        sales_data = np.random.randint(100, 500, size=periods)\n    \n    # Convert sales data to a pandas DataFrame\n    sales_df = pd.DataFrame(sales_data, index=date_range, columns=['Sales'])\n    \n    # Prepare the data for linear regression\n    X = np.arange(len(sales_data)).reshape(-1, 1)\n    y = sales_data\n    \n    # Fit the linear regression model\n    model = LinearRegression()\n    model.fit(X, y)\n    \n    # Predict future sales\n    future_X = np.arange(len(sales_data), len(sales_data) + periods).reshape(-1, 1)\n    future_sales = model.predict(future_X)\n    \n    return future_sales", "raw_solution": "import pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef task_func(start_date='2016-01-01', periods=13, freq='WOM-2FRI', sales_data=None):\n    # If no sales data is provided, generate a sample dataset\n    if sales_data is None:\n        # Create a date range\n        date_range = pd.date_range(start=start_date, periods=periods, freq=freq)\n        # Generate random sales data\n        sales_data = np.random.randint(100, 500, size=periods)\n    \n    # Convert sales data to a pandas DataFrame\n    sales_df = pd.DataFrame(sales_data, index=date_range, columns=['Sales'])\n    \n    # Prepare the data for linear regression\n    X = np.arange(len(sales_data)).reshape(-1, 1)\n    y = sales_data\n    \n    # Fit the linear regression model\n    model = LinearRegression()\n    model.fit(X, y)\n    \n    # Predict future sales\n    future_X = np.arange(len(sales_data), len(sales_data) + periods).reshape(-1, 1)\n    future_sales = model.predict(future_X)\n    \n    return future_sales\n\n# Example usage\nfuture_sales = task_func()"}
{"task_id": "BigCodeBench/952", "solution": "import pandas as pd\nimport random\nfrom datetime import datetime\ndef task_func(\n    task_list,\n    n_tasks,\n    employees=[\"John Doe\", \"Jane Smith\", \"James Brown\", \"Mary Johnson\", \"Robert Davis\"],\n    seed=None,\n):\n    if n_tasks < 0:\n        raise ValueError(\"n_tasks must be a non-negative integer\")\n    \n    if seed is not None:\n        random.seed(seed)\n    \n    tasks = task_list.copy()\n    random.shuffle(tasks)\n    \n    assigned_tasks = tasks[:n_tasks]\n    assigned_tasks = [task.replace(\" \", \"_\") for task in assigned_tasks]\n    \n    assigned_to = random.choices(employees, k=n_tasks)\n    due_date = datetime.now().strftime(\"%Y-%m-%d\")\n    \n    df = pd.DataFrame({\n        \"Task Name\": assigned_tasks,\n        \"Assigned To\": assigned_to,\n        \"Due Date\": due_date\n    })\n    \n    return df\ntask_list = [\"Task 1\", \"Task 2\", \"Task 3\", \"Task 4\", \"Task 5\"]\nn_tasks = 3", "raw_solution": "import pandas as pd\nimport random\nfrom datetime import datetime\n\ndef task_func(\n    task_list,\n    n_tasks,\n    employees=[\"John Doe\", \"Jane Smith\", \"James Brown\", \"Mary Johnson\", \"Robert Davis\"],\n    seed=None,\n):\n    if n_tasks < 0:\n        raise ValueError(\"n_tasks must be a non-negative integer\")\n    \n    if seed is not None:\n        random.seed(seed)\n    \n    tasks = task_list.copy()\n    random.shuffle(tasks)\n    \n    assigned_tasks = tasks[:n_tasks]\n    assigned_tasks = [task.replace(\" \", \"_\") for task in assigned_tasks]\n    \n    assigned_to = random.choices(employees, k=n_tasks)\n    due_date = datetime.now().strftime(\"%Y-%m-%d\")\n    \n    df = pd.DataFrame({\n        \"Task Name\": assigned_tasks,\n        \"Assigned To\": assigned_to,\n        \"Due Date\": due_date\n    })\n    \n    return df\n\n# Example usage\ntask_list = [\"Task 1\", \"Task 2\", \"Task 3\", \"Task 4\", \"Task 5\"]\nn_tasks = 3\ndf = task_func(task_list, n_tasks)"}
{"task_id": "BigCodeBench/955", "solution": "import numpy as np\nfrom matplotlib import pyplot as plt\nfrom collections import Counter\nfrom importlib import import_module\nimport importlib", "raw_solution": "import numpy as np\nfrom matplotlib import pyplot as plt\nfrom collections import Counter\nfrom importlib import import_module\nimport importlib\ntask_func = import_module.from_object('matplotlib._import_module', import_module) = from_object from 'matplotlib._task_func from from_module from collections from task_func from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from"}
{"task_id": "BigCodeBench/963", "solution": "import os\nfrom pathlib import Path\nimport zipfile\nfrom importlib import import_module", "raw_solution": "import os\nfrom pathlib import Path\nimport zipfile\nfrom importlib import import_module\n\ndef task_func(source_directory, target_directory, zip_name):\n    from import_module import import_module from task_func from task_func import task_func from task_func from task_func from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from"}
{"task_id": "BigCodeBench/964", "solution": "import os\nfrom pathlib import Path\nimport pandas as pd", "raw_solution": "import os\nfrom pathlib import Path\nimport pandas as pd\nfrom docx import docx from task_func from docx import task_func from task_func from task_func from task_func from task_func from task_func from task_func from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task"}
{"task_id": "BigCodeBench/969", "solution": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\nimport pandas as pd", "raw_solution": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\nimport pandas as pd\n\ndef task_func(df: pd.DataFrame) from from_ import task_func from from_.task_func from from_.task_func from from_.task_func from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_.task from from_."}
{"task_id": "BigCodeBench/971", "solution": "import os\nfrom pathlib import Path\nfrom datetime import datetime, timezone\nimport importlib\nimport os\ndef task_func(directory_path: str):\n    # Check if the directory exists\n    if not os.path.exists(directory_path):\n        raise ValueError(\"The provided directory does not exist.\")\n    \n    # Initialize an empty list to store the results\n    result = []\n    \n    # Iterate over each file in the directory\n    for file in os.listdir(directory_path):\n        # Construct the full file path\n        file_path = os.path.join(directory_path, file)\n        \n        # Get the file size\n        file_size = os.path.getsize(file_path)\n        \n        # Get the creation time and convert it to ISO format\n        creation_time = datetime.fromtimestamp(os.path.getctime(file_path), timezone.utc).isoformat()\n        \n        # Get the modification time and convert it to ISO format\n        modification_time = datetime.fromtimestamp(os.path.getmtime(file_path), timezone.utc).isoformat()\n        \n        # Append the file information as a tuple to the result list\n        result.append((file, file_size, creation_time, modification_time))\n    \n    return result", "raw_solution": "import os\nfrom pathlib import Path\nfrom datetime import datetime, timezone\nimport importlib\n\n# Test if importlib is already imported\nimportlib.reload(os)\n\n# Add import statement for os module\nimport os\n\ndef task_func(directory_path: str):\n    # Check if the directory exists\n    if not os.path.exists(directory_path):\n        raise ValueError(\"The provided directory does not exist.\")\n    \n    # Initialize an empty list to store the results\n    result = []\n    \n    # Iterate over each file in the directory\n    for file in os.listdir(directory_path):\n        # Construct the full file path\n        file_path = os.path.join(directory_path, file)\n        \n        # Get the file size\n        file_size = os.path.getsize(file_path)\n        \n        # Get the creation time and convert it to ISO format\n        creation_time = datetime.fromtimestamp(os.path.getctime(file_path), timezone.utc).isoformat()\n        \n        # Get the modification time and convert it to ISO format\n        modification_time = datetime.fromtimestamp(os.path.getmtime(file_path), timezone.utc).isoformat()\n        \n        # Append the file information as a tuple to the result list\n        result.append((file, file_size, creation_time, modification_time))\n    \n    return result\n\n# Test the function with the provided test case\n\n```"}
{"task_id": "BigCodeBench/985", "solution": "import pandas as pd\nimport json\nimport math\nimport os", "raw_solution": "import pandas as pd\nimport json\nimport math\nimport os\n\nfrom task_module import task_func from task_module import task_func from task_module import task from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task_module from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from"}
{"task_id": "BigCodeBench/988", "solution": "import os\nfrom pathlib import Path\nfrom importlib import import_module", "raw_solution": "import os\nfrom pathlib import Path\nfrom importlib import import_module\nfrom os import task from task import task from task import task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task"}
{"task_id": "BigCodeBench/990", "solution": "import binascii\nimport base64\nimport urllib.parse\nimport codecs\ndef task_func(hex_string):\n    # Convert hexadecimal string to bytes\n    bytes_data = bytes.fromhex(hex_string)\n    \n    # Convert bytes to UTF-8 string\n    utf8_string = bytes_data.decode('utf-8')\n    \n    # Encode UTF-8 string into different formats\n    encoded_dict = {\n        'hex': hex_string,\n        'base64': base64.b64encode(bytes_data).decode('utf-8'),\n        'utf-8': utf8_string,\n        'utf-16': utf8_string.encode('utf-16').decode('utf-8'),\n        'utf-32': utf8_string.encode('utf-32').decode('utf-8'),\n        'ASCII': utf8_string if utf8_string.isascii() else 'Not representable in ASCII',\n        'URL': urllib.parse.quote(utf8_string),\n        'ROT13': ''.join([chr(ord(c) + 13) if 'a' <= c <= 'z' else chr(ord(c) + 13 - 26) if 'A' <= c <= 'Z' else c for c in utf8_string])\n    }\n    \n    return encoded_dict", "raw_solution": "import binascii\nimport base64\nimport urllib.parse\nimport codecs\ndef task_func(hex_string):\n    # Convert hexadecimal string to bytes\n    bytes_data = bytes.fromhex(hex_string)\n    \n    # Convert bytes to UTF-8 string\n    utf8_string = bytes_data.decode('utf-8')\n    \n    # Encode UTF-8 string into different formats\n    encoded_dict = {\n        'hex': hex_string,\n        'base64': base64.b64encode(bytes_data).decode('utf-8'),\n        'utf-8': utf8_string,\n        'utf-16': utf8_string.encode('utf-16').decode('utf-8'),\n        'utf-32': utf8_string.encode('utf-32').decode('utf-8'),\n        'ASCII': utf8_string if utf8_string.isascii() else 'Not representable in ASCII',\n        'URL': urllib.parse.quote(utf8_string),\n        'ROT13': ''.join([chr(ord(c) + 13) if 'a' <= c <= 'z' else chr(ord(c) + 13 - 26) if 'A' <= c <= 'Z' else c for c in utf8_string])\n    }\n    \n    return encoded_dict\n\n# Test the function with the provided example\n\n```"}
{"task_id": "BigCodeBench/998", "solution": "import urllib.request\nimport hashlib\nimport tarfile", "raw_solution": "import urllib.request\nimport hashlib\nimport tarfile\nimport os from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from"}
{"task_id": "BigCodeBench/999", "solution": "import urllib.request\nimport csv\nimport collections", "raw_solution": "import urllib.request\nimport csv\nimport collections\nimport os from collections import collections from collections import collections from collections import collections from collections import collections from collections import collections from collections import collections from collections import collections from collections import collections from collections import collections from collections import collections from collections import collections from collections import collections from collections import collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections from collections"}
{"task_id": "BigCodeBench/1003", "solution": "import urllib.request\nfrom lxml import etree\nimport pandas as pd\ndef task_func(url):\n    try:\n        response = urllib.request.urlopen(url)\n        xml_data = response.read()\n    except Exception as e:\n        raise ValueError(f\"Failed to fetch XML file from URL: {e}\")\n\n    try:\n        root = etree.fromstring(xml_data)\n    except etree.XMLSyntaxError as e:\n        raise ValueError(f\"Invalid XML syntax: {e}\")\n\n    items = root.findall('.//item')\n    if not items:\n        raise ValueError(\"No 'item' elements found in the XML file\")\n\n    data = []\n    for item in items:\n        item_data = {}\n        for child in item:\n            item_data[child.tag] = child.text\n        data.append(item_data)\n\n    return pd.DataFrame(data)", "raw_solution": "import urllib.request\nfrom lxml import etree\nimport pandas as pd\n\ndef task_func(url):\n    try:\n        response = urllib.request.urlopen(url)\n        xml_data = response.read()\n    except Exception as e:\n        raise ValueError(f\"Failed to fetch XML file from URL: {e}\")\n\n    try:\n        root = etree.fromstring(xml_data)\n    except etree.XMLSyntaxError as e:\n        raise ValueError(f\"Invalid XML syntax: {e}\")\n\n    items = root.findall('.//item')\n    if not items:\n        raise ValueError(\"No 'item' elements found in the XML file\")\n\n    data = []\n    for item in items:\n        item_data = {}\n        for child in item:\n            item_data[child.tag] = child.text\n        data.append(item_data)\n\n    return pd.DataFrame(data)\n\n# Example usage\n# df = task_func('http://example.com/valid_structure.xml')\n# print(df)\n\n```"}
{"task_id": "BigCodeBench/1004", "solution": "import urllib.request\nimport re\nfrom collections import Counter\nimport matplotlib.pyplot as plt\ndef task_func(url):\n    # Download the text file from the specified URL\n    response = urllib.request.urlopen(url)\n    text = response.read().decode('utf-8')\n\n    # Use regular expression to find all words in the text\n    words = re.findall(r'\\b\\w+\\b', text)\n\n    # Count the frequency of each word\n    word_counts = Counter(words)\n\n    # Get the ten most common words\n    most_common_words = word_counts.most_common(10)\n\n    # Create a bar chart of the ten most common words\n    fig, ax = plt.subplots()\n    ax.bar([word for word, count in most_common_words], [count for word, count in most_common_words])\n\n    # Return the word counts and the Axes object\n    return word_counts, ax\nurl = 'https://raw.githubusercontent.com/AlibabaCloud/aliyun-python-sdk-core/master/README.md'", "raw_solution": "import urllib.request\nimport re\nfrom collections import Counter\nimport matplotlib.pyplot as plt\n\ndef task_func(url):\n    # Download the text file from the specified URL\n    response = urllib.request.urlopen(url)\n    text = response.read().decode('utf-8')\n\n    # Use regular expression to find all words in the text\n    words = re.findall(r'\\b\\w+\\b', text)\n\n    # Count the frequency of each word\n    word_counts = Counter(words)\n\n    # Get the ten most common words\n    most_common_words = word_counts.most_common(10)\n\n    # Create a bar chart of the ten most common words\n    fig, ax = plt.subplots()\n    ax.bar([word for word, count in most_common_words], [count for word, count in most_common_words])\n\n    # Return the word counts and the Axes object\n    return word_counts, ax\n\n# Example usage\nurl = 'https://raw.githubusercontent.com/AlibabaCloud/aliyun-python-sdk-core/master/README.md'\nword_counts, ax = task_func(url)\n\n# Print the word counts"}
{"task_id": "BigCodeBench/1006", "solution": "import os", "raw_solution": "import os from task_func from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from"}
{"task_id": "BigCodeBench/1008", "solution": "from bs4 import BeautifulSoup\nfrom pandas import DataFrame\nfrom pandas.core import pd\nfrom pandas.core import DataFrame\nfrom pandas.core import pd\nfrom pandas.core import DataFrame\nfrom pandas.core import pd\nfrom pandas.core import DataFrame", "raw_solution": "from bs4 import BeautifulSoup from pandas import DataFrame from pandas.core import pd from pandas.core import DataFrame from pandas.core import pd from pandas.core import DataFrame from pandas.core import pd from pandas.core import DataFrame from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas.core from pandas"}
{"task_id": "BigCodeBench/1012", "solution": "import requests\nfrom pathlib import Path\nimport zipfile\nDOWNLOAD_DIR = Path(\"downloads\")\nZIP_DIR = Path(\"unzipped_files\")\ndef task_func(url, filename):\n    # Create download directory if it doesn't exist\n    DOWNLOAD_DIR.mkdir(parents=True, exist_ok=True)\n    # Create unzipped files directory if it doesn't exist\n    ZIP_DIR.mkdir(parents=True, exist_ok=True)\n    # Download the zip file\n    try:\n        response = requests.get(url)\n        response.raise_for_status()  # Raise an exception for 4xx or 5xx status codes\n    except requests.exceptions.RequestException as e:\n        return (\"Error: Network-related exception occurred\", [])\n    # Save the zip file to the download directory\n    zip_path = DOWNLOAD_DIR / filename\n    with open(zip_path, 'wb') as f:\n        f.write(response.content)\n    # Extract the zip file\n    try:\n        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n            zip_ref.extractall(ZIP_DIR)\n    except zipfile.BadZipFile as e:\n        return (\"Error: File-related exception occurred\", [])\n    # Get the list of filenames in the unzipped directory\n    filenames = [f.name for f in ZIP_DIR.iterdir()]\n    return (\"Success\", filenames)", "raw_solution": "import requests\nfrom pathlib import Path\nimport zipfile\n# Constants\nDOWNLOAD_DIR = Path(\"downloads\")\nZIP_DIR = Path(\"unzipped_files\")\ndef task_func(url, filename):\n    # Create download directory if it doesn't exist\n    DOWNLOAD_DIR.mkdir(parents=True, exist_ok=True)\n    # Create unzipped files directory if it doesn't exist\n    ZIP_DIR.mkdir(parents=True, exist_ok=True)\n    # Download the zip file\n    try:\n        response = requests.get(url)\n        response.raise_for_status()  # Raise an exception for 4xx or 5xx status codes\n    except requests.exceptions.RequestException as e:\n        return (\"Error: Network-related exception occurred\", [])\n    # Save the zip file to the download directory\n    zip_path = DOWNLOAD_DIR / filename\n    with open(zip_path, 'wb') as f:\n        f.write(response.content)\n    # Extract the zip file\n    try:\n        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n            zip_ref.extractall(ZIP_DIR)\n    except zipfile.BadZipFile as e:\n        return (\"Error: File-related exception occurred\", [])\n    # Get the list of filenames in the unzipped directory\n    filenames = [f.name for f in ZIP_DIR.iterdir()]\n    return (\"Success\", filenames)\n\n```"}
{"task_id": "BigCodeBench/1013", "solution": "from urllib.parse import urljoin", "raw_solution": "from urllib.parse import urljoin\nfrom bs4 import BeautifulSoup from from_task from import task_func from from_task import BeautifulSoup from from_task import urljoin from from_task from import BeautifulSoup from from_task from from_task from from_task from from_task from from_task from BeautifulSoup from from_task from BeautifulSoup from from_task BeautifulSoup from BeautifulSoup from from_task BeautifulSoup from from_task BeautifulSoup from BeautifulSoup from from_task BeautifulSoup from BeautifulSoup from from_task BeautifulSoup from BeautifulSoup from from_task BeautifulSoup from BeautifulSoup from BeautifulSoup from from_task BeautifulSoup from from_task BeautifulSoup from BeautifulSoup from BeautifulSoup from from_task BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from from_task BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup"}
{"task_id": "BigCodeBench/1015", "solution": "import requests\nfrom lxml import html\nimport pandas as pd\nimport sqlite3\nimport pandas as pd\ndef task_func(webpage_url: str, database_name: str = \"my_database.db\") -> int:\n    try:\n        # Fetch the HTML content from the URL\n        response = requests.get(webpage_url)\n        response.raise_for_status()  # Raise an exception for 4xx or 5xx status codes\n\n        # Parse the HTML content\n        tree = html.fromstring(response.text)\n        table = tree.xpath('//table')[0]  # Assuming the first table is the one we want\n\n        # Extract the headers and rows from the table\n        headers = [header.text for header in table.xpath('.//th')]\n        rows = []\n        for row in table.xpath('.//tr'):\n            row_data = [cell.text for cell in row.xpath('.//td')]\n            if row_data:\n                rows.append(row_data)\n\n        # Create a DataFrame from the extracted data\n        df = pd.DataFrame(rows, columns=headers)\n\n        # Connect to the SQLite database\n        conn = sqlite3.connect(database_name)\n\n        # Replace the existing table with the new data\n        df.to_sql('my_table', conn, if_exists='replace', index=False)\n\n        # Close the database connection\n        conn.close()\n\n        # Return the number of rows in the parsed HTML table\n        return len(rows)\n\n    except requests.RequestException as e:\n        print(f\"Error fetching the webpage: {e}\")\n        return 0\n    except sqlite3.DatabaseError as e:\n        print(f\"Error connecting to or writing to the database: {e}\")\n        return 0\n    except Exception as e:\n        print(f\"An unexpected error occurred: {e}\")\n        return 0", "raw_solution": "import requests\nfrom lxml import html\nimport pandas as pd\nimport sqlite3\n\ndef task_func(webpage_url: str, database_name: str = \"my_database.db\") -> int:\n    try:\n        # Fetch the HTML content from the URL\n        response = requests.get(webpage_url)\n        response.raise_for_status()  # Raise an exception for 4xx or 5xx status codes\n\n        # Parse the HTML content\n        tree = html.fromstring(response.text)\n        table = tree.xpath('//table')[0]  # Assuming the first table is the one we want\n\n        # Extract the headers and rows from the table\n        headers = [header.text for header in table.xpath('.//th')]\n        rows = []\n        for row in table.xpath('.//tr'):\n            row_data = [cell.text for cell in row.xpath('.//td')]\n            if row_data:\n                rows.append(row_data)\n\n        # Create a DataFrame from the extracted data\n        df = pd.DataFrame(rows, columns=headers)\n\n        # Connect to the SQLite database\n        conn = sqlite3.connect(database_name)\n\n        # Replace the existing table with the new data\n        df.to_sql('my_table', conn, if_exists='replace', index=False)\n\n        # Close the database connection\n        conn.close()\n\n        # Return the number of rows in the parsed HTML table\n        return len(rows)\n\n    except requests.RequestException as e:\n        print(f\"Error fetching the webpage: {e}\")\n        return 0\n    except sqlite3.DatabaseError as e:\n        print(f\"Error connecting to or writing to the database: {e}\")\n        return 0\n    except Exception as e:\n        print(f\"An unexpected error occurred: {e}\")\n        return 0\n\n# Example usage\nimport pandas as pd\n# Assuming you have pandas installed, you can use the following code to test the function\n# task_func(\"http://example.com\", \"my_database.db\")\n\n```"}
{"task_id": "BigCodeBench/1019", "solution": "from PIL import Image\nimport codecs\nimport pytesseract\nIMAGE_PATH = \"image.png\"\ndef task_func(filename=IMAGE_PATH, from_encoding=\"cp1251\", to_encoding=\"utf8\"):\n    try:\n        from PIL import Image\n        import pytesseract\n    except ImportError:\n        raise ImportError(\"Pillow and pytesseract are required for this function to work.\")\n\n    try:\n        from pytesseract import Output\n    except ImportError:\n        from pytesseract.pytesseract import Output\n\n    try:\n        from PIL import Image\n    except ImportError:\n        raise ImportError(\"Pillow is required for this function to work.\")\n\n    try:\n        from pytesseract import pytesseract\n    except ImportError:\n        raise ImportError(\"pytesseract is required for this function to work.\")\n\n    try:\n        from PIL import Image\n    except ImportError:\n        raise ImportError(\"Pillow is required for this function to work.\")\n\n    try:\n        from pytesseract import pytesseract\n    except ImportError:\n        raise ImportError(\"pytesseract is required for this function to work.\")\n\n    try:\n        from PIL import Image\n    except ImportError:\n        raise ImportError(\"Pillow is required for this function to work.\")\n\n    try:\n        from pytesseract import pytesseract\n    except ImportError:\n        raise ImportError(\"pytesseract is required for this function to work.\")\n\n    try:\n        from PIL import Image\n    except ImportError:\n        from PIL import Image\n        import pytesseract\n        from PIL import Image\n        from pytesseract import Output\n        from PIL import Image\n        from pytesseract import pytesseract\n        from PIL import Image\n        from pytesseract import Output\n        from PIL import Image\n        from pytesseract import pytesseract\n        from PIL import Image\n        from pytesseract import Output\n        from PIL import Image\n        from pytesseract import pytesseract\n        from PIL import Image\n        from pytesseract import Output\n        from PIL import Image\n        from pytesseract import pytesseract\n        from PIL import Image\n        from pytesseract import Output\n        from PIL import Image\n        from pytesseract import pytesseract\n        from PIL import Image\n        from pytesseract import Output\n        from PIL import Image\n        from pytesseract import pytesseract\n        from PIL import Image\n        from pytesseract import Output\n        from PIL import Image\n        from pytesseract import pytesseract\n        from PIL import Image\n        from pytesseract import Output\n        from PIL import Image\n        from pytesseract import pytesseract\n        from PIL import Image\n        from pytesseract import Output\n        from PIL import Image\n        from pytesseract import pytesseract\n        from PIL import Image\n        from pytesseract import Output\n        from PIL import Image\n        from pytesseract import pytesseract\n        from PIL import Image\n        from pytesseract import Output\n        from PIL import Image\n        from pytesseract import pytesseract\n        from PIL import Image\n        from pytesseract import Output\n        from PIL import Image\n        from pytesseract import pytesseract\n        from PIL import Image\n        from pytesseract import Output\n        from PIL import Image\n        from pytesseract import pytesseract\n        from PIL import Image\n        from pytesseract import Output\n        from PIL import Image\n        from pytesseract import pytesseract\n        from PIL import Image\n        from pytesseract import Output\n        from PIL import Image\n        from pytesseract import pytesseract\n        from PIL import Image\n        from pytesseract import Output\n        from PIL import Image\n        from pytesseract import pytesseract\n        from PIL import Image\n        from pytesseract import Output\n        from PIL import Image\n        from pytesseract import pytesseract\n        from PIL import Image\n        from pytesseract import Output\n        from PIL import Image\n        from pytesseract import pytesseract\n        from PIL import Image\n        from pytesseract import Output\n        from PIL import Image\n        from pytesseract import pytesseract\n        from PIL import Image\n        from pytesseract import Output\n        from PIL import Image\n        from pytesseract import pytesseract\n        from PIL import Image\n        from pytesseract import Output\n        from PIL import Image\n        from pytesseract import pytesseract\n        from PIL import Image\n        from pytesseract import Output\n        from PIL import Image\n        from pytesseract import pytesseract\n        from PIL import Image\n        from pytesseract import Output\n        from PIL import Image\n        from pytesseract import pytesseract\n        from PIL import Image\n        from pytesseract import Output\n        from PIL import Image\n        from pytesseract import pytesseract\n        from PIL import Image\n        from pytesseract import Output\n        from PIL import Image\n        from pytesseract import pytesseract\n        from PIL import Image\n        from pytesseract import Output\n        from PIL import Image\n        from pytesseract import pytesseract\n        from PIL import Image\n        from pytesseract import Output\n        from PIL import Image\n        from pytesseract import pytesseract\n        from PIL import Image\n        from pytesseract import Output\n        from PIL import Image\n        from pytesseract import pytesseract", "raw_solution": "from PIL import Image\nimport codecs\nimport pytesseract\n\nIMAGE_PATH = \"image.png\"\n\ndef task_func(filename=IMAGE_PATH, from_encoding=\"cp1251\", to_encoding=\"utf8\"):\n    try:\n        from PIL import Image\n        import pytesseract\n    except ImportError:\n        raise ImportError(\"Pillow and pytesseract are required for this function to work.\")\n\n    try:\n        from pytesseract import Output\n    except ImportError:\n        from pytesseract.pytesseract import Output\n\n    try:\n        from PIL import Image\n    except ImportError:\n        raise ImportError(\"Pillow is required for this function to work.\")\n\n    try:\n        from pytesseract import pytesseract\n    except ImportError:\n        raise ImportError(\"pytesseract is required for this function to work.\")\n\n    try:\n        from PIL import Image\n    except ImportError:\n        raise ImportError(\"Pillow is required for this function to work.\")\n\n    try:\n        from pytesseract import pytesseract\n    except ImportError:\n        raise ImportError(\"pytesseract is required for this function to work.\")\n\n    try:\n        from PIL import Image\n    except ImportError:\n        raise ImportError(\"Pillow is required for this function to work.\")\n\n    try:\n        from pytesseract import pytesseract\n    except ImportError:\n        raise ImportError(\"pytesseract is required for this function to work.\")\n\n    try:\n        from PIL import Image\n    except ImportError:\n        from PIL import Image\n        import pytesseract\n        from PIL import Image\n        from pytesseract import Output\n        from PIL import Image\n        from pytesseract import pytesseract\n        from PIL import Image\n        from pytesseract import Output\n        from PIL import Image\n        from pytesseract import pytesseract\n        from PIL import Image\n        from pytesseract import Output\n        from PIL import Image\n        from pytesseract import pytesseract\n        from PIL import Image\n        from pytesseract import Output\n        from PIL import Image\n        from pytesseract import pytesseract\n        from PIL import Image\n        from pytesseract import Output\n        from PIL import Image\n        from pytesseract import pytesseract\n        from PIL import Image\n        from pytesseract import Output\n        from PIL import Image\n        from pytesseract import pytesseract\n        from PIL import Image\n        from pytesseract import Output\n        from PIL import Image\n        from pytesseract import pytesseract\n        from PIL import Image\n        from pytesseract import Output\n        from PIL import Image\n        from pytesseract import pytesseract\n        from PIL import Image\n        from pytesseract import Output\n        from PIL import Image\n        from pytesseract import pytesseract\n        from PIL import Image\n        from pytesseract import Output\n        from PIL import Image\n        from pytesseract import pytesseract\n        from PIL import Image\n        from pytesseract import Output\n        from PIL import Image\n        from pytesseract import pytesseract\n        from PIL import Image\n        from pytesseract import Output\n        from PIL import Image\n        from pytesseract import pytesseract\n        from PIL import Image\n        from pytesseract import Output\n        from PIL import Image\n        from pytesseract import pytesseract\n        from PIL import Image\n        from pytesseract import Output\n        from PIL import Image\n        from pytesseract import pytesseract\n        from PIL import Image\n        from pytesseract import Output\n        from PIL import Image\n        from pytesseract import pytesseract\n        from PIL import Image\n        from pytesseract import Output\n        from PIL import Image\n        from pytesseract import pytesseract\n        from PIL import Image\n        from pytesseract import Output\n        from PIL import Image\n        from pytesseract import pytesseract\n        from PIL import Image\n        from pytesseract import Output\n        from PIL import Image\n        from pytesseract import pytesseract\n        from PIL import Image\n        from pytesseract import Output\n        from PIL import Image\n        from pytesseract import pytesseract\n        from PIL import Image\n        from pytesseract import Output\n        from PIL import Image\n        from pytesseract import pytesseract\n        from PIL import Image\n        from pytesseract import Output\n        from PIL import Image\n        from pytesseract import pytesseract\n        from PIL import Image\n        from pytesseract import Output\n        from PIL import Image\n        from pytesseract import pytesseract\n        from PIL import Image\n        from pytesseract import Output\n        from PIL import Image\n        from pytesseract import pytesseract\n        from PIL import Image\n        from pytesseract import Output\n        from PIL import Image\n        from pytesseract import pytesseract\n        from PIL import Image\n        from pytesseract import Output\n        from PIL import Image\n        from pytesseract import pytesseract\n        from PIL import Image\n        from pytesseract import Output\n        from PIL import Image\n        from pytesseract import pytesseract\n        from PIL import Image\n        from pytesseract import Output\n        from PIL import Image\n        from pytesseract import pytesseract\n        from PIL import Image\n        from pytesseract import Output\n        from PIL import Image\n        from pytesseract import pytesseract\n        from PIL import"}
{"task_id": "BigCodeBench/1020", "solution": "import json\nimport requests\nfrom importlib import import_module\nimport sys\nimport importlib\nfrom importlib._bootstrap import module_from_spec\nfrom importlib.machinery import ModuleSpec\nimport sys\nfrom importlib._bootstrap_external import _module_from_spec", "raw_solution": "import json\nimport requests\nfrom importlib import import_module\nimport sys\nimport importlib\nfrom importlib._bootstrap import module_from_spec\nfrom importlib.machinery import ModuleSpec\nimport sys\nfrom importlib._bootstrap_external import _module_from_spec\nfrom importlib._bootstrap_external from_module_from_spec = from_module_from_spec from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module from_module_from_module"}
{"task_id": "BigCodeBench/1022", "solution": "import pandas as pd\nfrom datetime import datetime\nfrom pandas.errors import EmptyDataError\nimport os", "raw_solution": "import pandas as pd\nfrom datetime import datetime\nfrom pandas.errors import EmptyDataError\nimport os\n\n# Test from datetime import datetime from os import task from task import task_func from task import EmptyDataError from task import FileNotFoundError from task import ValueError from task import from task import from task import from task import from task import from task from task import from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task from task"}
{"task_id": "BigCodeBench/1039", "solution": "import ssl\nimport hashlib", "raw_solution": "import ssl\nimport hashlib\nimport os from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from from"}
{"task_id": "BigCodeBench/1040", "solution": "import socket\nimport select\nimport queue\nfrom datetime import datetime, timedelta\ndef task_func(\n    server_address=\"localhost\", server_port=12345, buffer_size=1024, run_duration=5\n):\n    # Create a TCP/IP socket\n    server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    server_socket.setblocking(False)\n\n    # Bind the socket to the server address and port\n    server_socket.bind((server_address, server_port))\n\n    # Listen for incoming connections\n    server_socket.listen(5)\n\n    # Create a list to keep track of client sockets\n    client_sockets = []\n\n    # Create a queue to store incoming data\n    data_queue = queue.Queue()\n\n    # Start the server\n    start_time = datetime.now()\n    while (datetime.now() - start_time).total_seconds() < run_duration:\n        # Check for incoming connections\n        readable, writable, exceptional = select.select(\n            [server_socket] + client_sockets, client_sockets, client_sockets\n        )\n\n        for s in readable:\n            if s is server_socket:\n                # Accept a new connection\n                client_socket, client_address = s.accept()\n                client_socket.setblocking(False)\n                client_sockets.append(client_socket)\n            else:\n                # Receive data from the client\n                data = s.recv(buffer_size)\n                if data:\n                    data_queue.put((s, data))\n                else:\n                    # Client disconnected\n                    client_sockets.remove(s)\n                    s.close()\n\n        for s in writable:\n            # Send data to the client\n            if not data_queue.empty():\n                client_socket, data = data_queue.get()\n                current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n                response = data.decode() + \" \" + current_time\n                client_socket.sendall(response.encode())\n\n        for s in exceptional:\n            # Handle exceptional conditions\n            client_sockets.remove(s)\n            s.close()\n\n    # Close the server socket\n    server_socket.close()\n\n    # Return a status message\n    return f\"Server ran for {run_duration} seconds\"", "raw_solution": "import socket\nimport select\nimport queue\nfrom datetime import datetime, timedelta\n\ndef task_func(\n    server_address=\"localhost\", server_port=12345, buffer_size=1024, run_duration=5\n):\n    # Create a TCP/IP socket\n    server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    server_socket.setblocking(False)\n\n    # Bind the socket to the server address and port\n    server_socket.bind((server_address, server_port))\n\n    # Listen for incoming connections\n    server_socket.listen(5)\n\n    # Create a list to keep track of client sockets\n    client_sockets = []\n\n    # Create a queue to store incoming data\n    data_queue = queue.Queue()\n\n    # Start the server\n    start_time = datetime.now()\n    while (datetime.now() - start_time).total_seconds() < run_duration:\n        # Check for incoming connections\n        readable, writable, exceptional = select.select(\n            [server_socket] + client_sockets, client_sockets, client_sockets\n        )\n\n        for s in readable:\n            if s is server_socket:\n                # Accept a new connection\n                client_socket, client_address = s.accept()\n                client_socket.setblocking(False)\n                client_sockets.append(client_socket)\n            else:\n                # Receive data from the client\n                data = s.recv(buffer_size)\n                if data:\n                    data_queue.put((s, data))\n                else:\n                    # Client disconnected\n                    client_sockets.remove(s)\n                    s.close()\n\n        for s in writable:\n            # Send data to the client\n            if not data_queue.empty():\n                client_socket, data = data_queue.get()\n                current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n                response = data.decode() + \" \" + current_time\n                client_socket.sendall(response.encode())\n\n        for s in exceptional:\n            # Handle exceptional conditions\n            client_sockets.remove(s)\n            s.close()\n\n    # Close the server socket\n    server_socket.close()\n\n    # Return a status message\n    return f\"Server ran for {run_duration} seconds\"\n\n```"}
{"task_id": "BigCodeBench/1042", "solution": "import smtplib\nfrom email.message import EmailMessage\nimport getpass\nBUFFER_SIZE = 1024\nSMTP_SERVER = \"smtp.gmail.com\"\nSMTP_PORT = 587\ndef task_func(client_socket):\n    sender_email = input(\"Enter sender's email: \")\n    recipient_email = input(\"Enter recipient's email: \")\n    sender_password = getpass.getpass(\"Enter sender's email password: \")\n    message = client_socket.recv(BUFFER_SIZE).decode()\n    msg = EmailMessage()\n    msg.set_content(message)\n    msg['Subject'] = 'Message from client'\n    msg['From'] = sender_email\n    msg['To'] = recipient_email\n    try:\n        with smtplib.SMTP(SMTP_SERVER, SMTP_PORT) as server:\n            server.starttls()\n            server.login(sender_email, sender_password)\n            server.send_message(msg)\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n    return None", "raw_solution": "import smtplib\nfrom email.message import EmailMessage\nimport getpass\nSERVER_ADDRESS = \"localhost\"\nSERVER_PORT = 25\nBUFFER_SIZE = 1024\nSMTP_SERVER = \"smtp.gmail.com\"\nSMTP_PORT = 587\ndef task_func(client_socket):\n    sender_email = input(\"Enter sender's email: \")\n    recipient_email = input(\"Enter recipient's email: \")\n    sender_password = getpass.getpass(\"Enter sender's email password: \")\n    message = client_socket.recv(BUFFER_SIZE).decode()\n    msg = EmailMessage()\n    msg.set_content(message)\n    msg['Subject'] = 'Message from client'\n    msg['From'] = sender_email\n    msg['To'] = recipient_email\n    try:\n        with smtplib.SMTP(SMTP_SERVER, SMTP_PORT) as server:\n            server.starttls()\n            server.login(sender_email, sender_password)\n            server.send_message(msg)\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n    return None\n\n```"}
{"task_id": "BigCodeBench/1053", "solution": "import pandas as pd\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport matplotlib.pyplot as plt\nSTOP_WORDS = [\"a\", \"an\", \"the\", \"in\", \"on\", \"at\", \"and\", \"or\"]\ndef task_func(file_path, save_path=None):\n    try:\n        # Load the CSV file\n        data = pd.read_csv(file_path)\n        \n        # Check if the file has a header\n        if 'Text' not in data.columns:\n            data.columns = ['Text']\n        \n        # Combine all text data into a single string\n        text_data = ' '.join(data['Text'].dropna())\n        \n        # Create a CountVectorizer object\n        vectorizer = CountVectorizer(stop_words=STOP_WORDS)\n        \n        # Fit and transform the text data\n        X = vectorizer.fit_transform([text_data])\n        \n        # Get the feature names and their corresponding counts\n        feature_names = vectorizer.get_feature_names_out()\n        counts = X.toarray()[0]\n        \n        # Create a dictionary of word counts\n        word_counts = dict(zip(feature_names, counts))\n        \n        # Sort the word counts in descending order\n        sorted_word_counts = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)\n        \n        # Get the top 10 most common words\n        top_10_words = sorted_word_counts[:10]\n        \n        # Create a bar chart of the top 10 most common words\n        fig, ax = plt.subplots()\n        ax.bar([word for word, count in top_10_words], [count for word, count in top_10_words])\n        ax.set_xlabel('Words')\n        ax.set_ylabel('Counts')\n        ax.set_title('Top 10 Most Common Words')\n        \n        # Save the plot to a file if save_path is provided\n        if save_path:\n            plt.savefig(save_path)\n            return None\n        else:\n            return ax\n    except FileNotFoundError:\n        raise FileNotFoundError(f\"The file {file_path} does not exist.\")\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n        return None", "raw_solution": "import pandas as pd\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport matplotlib.pyplot as plt\n# Constants\nSTOP_WORDS = [\"a\", \"an\", \"the\", \"in\", \"on\", \"at\", \"and\", \"or\"]\n\ndef task_func(file_path, save_path=None):\n    try:\n        # Load the CSV file\n        data = pd.read_csv(file_path)\n        \n        # Check if the file has a header\n        if 'Text' not in data.columns:\n            data.columns = ['Text']\n        \n        # Combine all text data into a single string\n        text_data = ' '.join(data['Text'].dropna())\n        \n        # Create a CountVectorizer object\n        vectorizer = CountVectorizer(stop_words=STOP_WORDS)\n        \n        # Fit and transform the text data\n        X = vectorizer.fit_transform([text_data])\n        \n        # Get the feature names and their corresponding counts\n        feature_names = vectorizer.get_feature_names_out()\n        counts = X.toarray()[0]\n        \n        # Create a dictionary of word counts\n        word_counts = dict(zip(feature_names, counts))\n        \n        # Sort the word counts in descending order\n        sorted_word_counts = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)\n        \n        # Get the top 10 most common words\n        top_10_words = sorted_word_counts[:10]\n        \n        # Create a bar chart of the top 10 most common words\n        fig, ax = plt.subplots()\n        ax.bar([word for word, count in top_10_words], [count for word, count in top_10_words])\n        ax.set_xlabel('Words')\n        ax.set_ylabel('Counts')\n        ax.set_title('Top 10 Most Common Words')\n        \n        # Save the plot to a file if save_path is provided\n        if save_path:\n            plt.savefig(save_path)\n            return None\n        else:\n            return ax\n    except FileNotFoundError:\n        raise FileNotFoundError(f\"The file {file_path} does not exist.\")\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n        return None\n\n```"}
{"task_id": "BigCodeBench/1057", "solution": "import pandas as pd\nimport numpy as np\nfrom itertools import product\ndef task_func(animals=None, foods=None):\n    # Importing required module\n    from pandas import DataFrame\n    \n    # Handling the case where numpy is not imported\n    if foods is None:\n        from numpy import random\n    \n    # Predefined import for numpy\n    from numpy import random\n    \n    # Predefined list for foods if not provided\n    if foods is None:\n        import numpy\n        from importlib import reload\n        import importlib\n        importlib.reload(numpy)\n        from numpy.random import random as random_func", "raw_solution": "import pandas as pd\nimport numpy as np\nfrom itertools import product\n\ndef task_func(animals=None, foods=None):\n    # Importing required module\n    from pandas import DataFrame\n    \n    # Handling the case where numpy is not imported\n    if foods is None:\n        from numpy import random\n    \n    # Predefined import for numpy\n    from numpy import random\n    \n    # Predefined list for foods if not provided\n    if foods is None:\n        import numpy\n        from importlib import reload\n        import importlib\n        importlib.reload(numpy)\n        from numpy.random import random as random_func\n        from random import random_func as random_func from random_func import random_func from random_func import random_func from random_func import random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random_func from random"}
{"task_id": "BigCodeBench/1077", "solution": "from datetime import datetime\nimport pytz\nimport numpy as np\nimport numpy as np\ndef task_func(time_strings, timezone):\n    # Convert timezone import to avoid errors\n    from datetime import datetime\n    import pytz\n    import numpy as np\n    \n    # Convert each timestamp to the specified timezone\n    from datetime import datetime\n    import pytz\n    import numpy as np\n    \n    # Convert timezone import to avoid errors\n    from datetime import datetime\n    import pytz\n    import numpy as np\n    \n    # Convert timezone import to avoid errors\n    from datetime import datetime\n    import pytz\n    from numpy import mean\n    \n    # Convert timezone import to avoid errors\n    from datetime import datetime\n    import pytz\n    \n    # Convert timezone import to avoid errors\n    from datetime import datetime\n    \n    # Convert timezone import to avoid errors\n    from datetime import datetime\n    from numpy import mean\n    \n    # Convert timezone import to avoid errors\n    from datetime import datetime\n    from numpy import mean\n    \n    # Convert timezone import to avoid errors\n    from datetime import datetime\n    from numpy import mean\n    \n    # Convert timezone import to avoid errors\n    from datetime import datetime\n    from numpy import mean\n    \n    # Convert timezone import to avoid errors\n    from numpy import mean\n    \n    # Convert timezone import to avoid errors\n    from datetime import datetime\n    \n    # Convert timezone import to avoid errors\n    from datetime import datetime\n    from importlib import reload\n    \n    # Convert from importlib to import\n    import importlib\n    \n    # Convert from importlib to import\n    from importlib import import_module\n    \n    # Convert from import_module to import\n    from import_module import reload\n    \n    # Fixing the import error from import_module\n    from importlib import reload\n    \n    # Fixing the import error from import_module\n    from import_module import reload\n    \n    # Fixing from from_module import reload from import_module\n    from import_module import reload\n    \n    # Fixing from from_module import reload from import_module\n    from import_module import reload\n    \n    # Fixing from from_module import reload from import_module\n    from import_module import reload\n    \n    # Fixing from from_module import reload from import_module\n    from import_module import reload\n    \n    # Fixing from from_module import reload from import_module\n    from import_module import reload\n    \n    # Fixing from from_module import reload from import_module\n    from import_module import reload\n    \n    # Fixing from from_module import reload from import_module\n    from import_module import reload\n    \n    # Fixing from from_module import reload from import_module\n    from import_module import reload\n    \n    # Fixing from from_module import reload from import_module\n    from import_module import reload\n    \n    # Fixing from from_module import reload from import_module\n    from import_module import reload\n    \n    # Fixing from from_module import reload from import_module\n    from import_module import reload\n    \n    # Fixing from from_module import reload from import_module\n    from import_module import reload\n    \n    # Fixing from from_module import reload from import_module\n    from import_module import reload\n    \n    # Fixing from from_module import reload from import_module\n    from import_module import reload\n    \n    # Fixing from from_module import reload from import_module\n    from import_module import reload\n    \n    # Fixing from from_module import reload from import_module\n    from import_module import reload\n    \n    # Fixing from from_module import reload from import_module\n    from import_module import reload\n    \n    # Fixing from from_module import reload from import_module\n    from import_module import reload\n    \n    # Fixing from from_module import reload from import_module\n    from import_module import reload\n    \n    # Fixing from from_module import reload from import_module\n    from import_module import reload\n    \n    # Fixing from from_module import reload from import_module\n    from import_module import reload\n    \n    # Fixing from from_module import reload from import_module\n    from import_module import reload\n    \n    # Fixing from from_module import reload from import_module\n    from import_module import reload\n    \n    # Fixing from from_module import reload from import_module\n    from import_module import reload\n    \n    # Fixing from from_module import reload from import_module\n    from import_module import reload\n    \n    # Fixing from from_module import reload from import_module\n    from import_module import reload\n    \n    # Fixing from from_module import reload from import_module\n    from import_module import reload\n    \n    # Fixing from from_module import reload from import_module\n    from import_module import reload\n    \n    # Fixing from from_module import reload from import_module\n    from import_module import reload\n    \n    # Fixing from from_module import reload from import_module\n    from import_module import reload\n    \n    # Fixing from from_module import reload from", "raw_solution": "from datetime import datetime\nimport pytz\nimport numpy as np\n\n# Add import statement for numpy\nimport numpy as np\n\ndef task_func(time_strings, timezone):\n    # Convert timezone import to avoid errors\n    from datetime import datetime\n    import pytz\n    import numpy as np\n    \n    # Convert each timestamp to the specified timezone\n    from datetime import datetime\n    import pytz\n    import numpy as np\n    \n    # Convert timezone import to avoid errors\n    from datetime import datetime\n    import pytz\n    import numpy as np\n    \n    # Convert timezone import to avoid errors\n    from datetime import datetime\n    import pytz\n    from numpy import mean\n    \n    # Convert timezone import to avoid errors\n    from datetime import datetime\n    import pytz\n    \n    # Convert timezone import to avoid errors\n    from datetime import datetime\n    \n    # Convert timezone import to avoid errors\n    from datetime import datetime\n    from numpy import mean\n    \n    # Convert timezone import to avoid errors\n    from datetime import datetime\n    from numpy import mean\n    \n    # Convert timezone import to avoid errors\n    from datetime import datetime\n    from numpy import mean\n    \n    # Convert timezone import to avoid errors\n    from datetime import datetime\n    from numpy import mean\n    \n    # Convert timezone import to avoid errors\n    from numpy import mean\n    \n    # Convert timezone import to avoid errors\n    from datetime import datetime\n    \n    # Convert timezone import to avoid errors\n    from datetime import datetime\n    from importlib import reload\n    \n    # Convert from importlib to import\n    import importlib\n    \n    # Convert from importlib to import\n    from importlib import import_module\n    \n    # Convert from import_module to import\n    from import_module import reload\n    \n    # Fixing the import error from import_module\n    from importlib import reload\n    \n    # Fixing the import error from import_module\n    from import_module import reload\n    \n    # Fixing from from_module import reload from import_module\n    from import_module import reload\n    \n    # Fixing from from_module import reload from import_module\n    from import_module import reload\n    \n    # Fixing from from_module import reload from import_module\n    from import_module import reload\n    \n    # Fixing from from_module import reload from import_module\n    from import_module import reload\n    \n    # Fixing from from_module import reload from import_module\n    from import_module import reload\n    \n    # Fixing from from_module import reload from import_module\n    from import_module import reload\n    \n    # Fixing from from_module import reload from import_module\n    from import_module import reload\n    \n    # Fixing from from_module import reload from import_module\n    from import_module import reload\n    \n    # Fixing from from_module import reload from import_module\n    from import_module import reload\n    \n    # Fixing from from_module import reload from import_module\n    from import_module import reload\n    \n    # Fixing from from_module import reload from import_module\n    from import_module import reload\n    \n    # Fixing from from_module import reload from import_module\n    from import_module import reload\n    \n    # Fixing from from_module import reload from import_module\n    from import_module import reload\n    \n    # Fixing from from_module import reload from import_module\n    from import_module import reload\n    \n    # Fixing from from_module import reload from import_module\n    from import_module import reload\n    \n    # Fixing from from_module import reload from import_module\n    from import_module import reload\n    \n    # Fixing from from_module import reload from import_module\n    from import_module import reload\n    \n    # Fixing from from_module import reload from import_module\n    from import_module import reload\n    \n    # Fixing from from_module import reload from import_module\n    from import_module import reload\n    \n    # Fixing from from_module import reload from import_module\n    from import_module import reload\n    \n    # Fixing from from_module import reload from import_module\n    from import_module import reload\n    \n    # Fixing from from_module import reload from import_module\n    from import_module import reload\n    \n    # Fixing from from_module import reload from import_module\n    from import_module import reload\n    \n    # Fixing from from_module import reload from import_module\n    from import_module import reload\n    \n    # Fixing from from_module import reload from import_module\n    from import_module import reload\n    \n    # Fixing from from_module import reload from import_module\n    from import_module import reload\n    \n    # Fixing from from_module import reload from import_module\n    from import_module import reload\n    \n    # Fixing from from_module import reload from import_module\n    from import_module import reload\n    \n    # Fixing from from_module import reload from import_module\n    from import_module import reload\n    \n    # Fixing from from_module import reload from import_module\n    from import_module import reload\n    \n    # Fixing from from_module import reload from"}
{"task_id": "BigCodeBench/1085", "solution": "import re\nfrom collections import Counter\nimport matplotlib.pyplot as plt\ndef task_func(text):\n    # Convert text to lowercase\n    text = text.lower()\n    \n    # Remove punctuation\n    text = re.sub(r'[^\\w\\s]', '', text)\n    \n    # Split text into words\n    words = text.split()\n    \n    # Count word frequencies\n    word_counts = Counter(words)\n    \n    # Get the top 10 most common words\n    top_10_words = word_counts.most_common(10)\n    \n    # Create a bar chart\n    fig, ax = plt.subplots()\n    ax.bar([word for word, count in top_10_words], [count for word, count in top_10_words])\n    ax.set_xlabel('Words')\n    ax.set_ylabel('Counts')\n    ax.set_title('Top 10 Most Common Words')\n    \n    return top_10_words, ax\ntext = \"Hello, world! This is a test. This is only a test.\"", "raw_solution": "import re\nfrom collections import Counter\nimport matplotlib.pyplot as plt\n\ndef task_func(text):\n    # Convert text to lowercase\n    text = text.lower()\n    \n    # Remove punctuation\n    text = re.sub(r'[^\\w\\s]', '', text)\n    \n    # Split text into words\n    words = text.split()\n    \n    # Count word frequencies\n    word_counts = Counter(words)\n    \n    # Get the top 10 most common words\n    top_10_words = word_counts.most_common(10)\n    \n    # Create a bar chart\n    fig, ax = plt.subplots()\n    ax.bar([word for word, count in top_10_words], [count for word, count in top_10_words])\n    ax.set_xlabel('Words')\n    ax.set_ylabel('Counts')\n    ax.set_title('Top 10 Most Common Words')\n    \n    return top_10_words, ax\n\n# Test the function\ntext = \"Hello, world! This is a test. This is only a test.\"\ntop_10_words, ax = task_func(text)"}
{"task_id": "BigCodeBench/1124", "solution": "from urllib.parse import urlparse", "raw_solution": "from urllib.parse import urlparse\nfrom bs4 from BeautifulSoup import BeautifulSoup from requests from BeautifulSoup from requests from BeautifulSoup from requests from BeautifulSoup from requests from BeautifulSoup from requests from BeautifulSoup from requests from BeautifulSoup from requests from BeautifulSoup from requests from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup from BeautifulSoup"}
{"task_id": "BigCodeBench/1129", "solution": "import json\nimport requests", "raw_solution": "import json\nimport requests\nimport os from datetime import datetime from importlib import *\nfrom datetime.datetime import datetime from datetime.datetime import import from datetime import datetime from datetime.datetime import datetime from datetime.datetime.datetime import from datetime.datetime.datetime.datetime import from datetime.datetime.datetime.datetime.datetime import from datetime.datetime.datetime.datetime.datetime.datetime import from datetime.datetime.datetime.datetime.datetime.datetime.datetime from datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime from datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime from datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime.datetime"}
{"task_id": "BigCodeBench/1137", "solution": "from bs4 import BeautifulSoup as task_func from bs4 import BeautifulSoup as BeautifulSoup from requests import BeautifulSoup as BeautifulSoup from task_func import BeautifulSoup from task_func import task_func from task_func import task_func from task_func import task_func from task_func import task_func from task_func import task_func from task_func import task_func from task_func import task_func from task_func import task_func from task_func import task_func from task_func import task_func from task_func import task_func from task_func import task_func from task_func import task_func from task_func import task_func from task_func import task_func from task_func import task_func from task_func import task_func from task_func import task_func from task_func import task_func from task_func import task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from", "raw_solution": "from bs4 import BeautifulSoup as task_func from bs4 import BeautifulSoup as BeautifulSoup from requests import BeautifulSoup as BeautifulSoup from task_func import BeautifulSoup from task_func import task_func from task_func import task_func from task_func import task_func from task_func import task_func from task_func import task_func from task_func import task_func from task_func import task_func from task_func import task_func from task_func import task_func from task_func import task_func from task_func import task_func from task_func import task_func from task_func import task_func from task_func import task_func from task_func import task_func from task_func import task_func from task_func import task_func from task_func import task_func from task_func import task_func from task_func import task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from task_func from"}
